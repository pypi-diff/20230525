# Comparing `tmp/we_factor_quad-0.0.4.1-py3-none-any.whl.zip` & `tmp/we_factor_quad-0.5.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,38 +1,37 @@
-Zip file size: 64201 bytes, number of entries: 36
+Zip file size: 66003 bytes, number of entries: 35
 -rw-rw-rw-  2.0 fat        0 b- defN 23-Mar-06 09:30 we_factor_quad/__init__.py
 -rw-rw-rw-  2.0 fat     4823 b- defN 23-Apr-20 09:06 we_factor_quad/client_local.py
--rw-rw-rw-  2.0 fat    22716 b- defN 23-Apr-23 02:14 we_factor_quad/data_api.py
--rw-rw-rw-  2.0 fat    34389 b- defN 23-Apr-20 08:23 we_factor_quad/factor_quad.py
--rw-rw-rw-  2.0 fat     4446 b- defN 23-Apr-24 06:51 we_factor_quad/test_settings.py
--rw-rw-rw-  2.0 fat    15078 b- defN 23-Apr-20 09:14 we_factor_quad/user_data_api.py
+-rw-rw-rw-  2.0 fat    28110 b- defN 23-May-25 01:36 we_factor_quad/data_api.py
+-rw-rw-rw-  2.0 fat    37731 b- defN 23-May-15 09:33 we_factor_quad/factor_quad.py
+-rw-rw-rw-  2.0 fat     4434 b- defN 23-May-24 07:59 we_factor_quad/factor_quad_settings.py
 -rw-rw-rw-  2.0 fat     1073 b- defN 23-Mar-26 12:36 we_factor_quad/utils.py
+-rw-rw-rw-  2.0 fat     2001 b- defN 23-May-05 09:36 we_factor_quad/workshop.py
 -rw-rw-rw-  2.0 fat        0 b- defN 23-Mar-06 09:30 we_factor_quad/commodity_quad/__init__.py
 -rw-rw-rw-  2.0 fat        0 b- defN 23-Mar-06 09:30 we_factor_quad/commodity_quad/factor_quad_commodity.py
 -rw-rw-rw-  2.0 fat        0 b- defN 23-Mar-06 09:30 we_factor_quad/commodity_quad/factor_portfolio/__init__.py
 -rw-rw-rw-  2.0 fat        0 b- defN 23-Mar-06 09:30 we_factor_quad/commodity_quad/risk_control/__init__.py
 -rw-rw-rw-  2.0 fat        0 b- defN 23-Mar-06 09:30 we_factor_quad/equity_quad/__init__.py
--rw-rw-rw-  2.0 fat    12037 b- defN 23-Apr-24 09:03 we_factor_quad/equity_quad/factor_quad_equity.py
--rw-rw-rw-  2.0 fat     8212 b- defN 23-Apr-20 04:03 we_factor_quad/equity_quad/fix_missing_psi.py
+-rw-rw-rw-  2.0 fat     8966 b- defN 23-May-15 06:02 we_factor_quad/equity_quad/daily_data_update_preprocessing.py
+-rw-rw-rw-  2.0 fat    13976 b- defN 23-May-24 02:34 we_factor_quad/equity_quad/factor_quad_equity.py
+-rw-rw-rw-  2.0 fat     8217 b- defN 23-May-06 07:06 we_factor_quad/equity_quad/fix_missing_psi.py
 -rw-rw-rw-  2.0 fat     2726 b- defN 23-Mar-22 07:32 we_factor_quad/equity_quad/solve_colinear.py
 -rw-rw-rw-  2.0 fat      207 b- defN 23-Mar-06 09:30 we_factor_quad/equity_quad/factor_portfolio/__init__.py
--rw-rw-rw-  2.0 fat    21636 b- defN 23-Apr-20 04:03 we_factor_quad/equity_quad/factor_portfolio/full_factor_mimicking_portfolio.py
--rw-rw-rw-  2.0 fat     2574 b- defN 23-Apr-06 07:49 we_factor_quad/equity_quad/factor_portfolio/universe_helper.py
+-rw-rw-rw-  2.0 fat    22115 b- defN 23-May-06 07:06 we_factor_quad/equity_quad/factor_portfolio/full_factor_mimicking_portfolio.py
+-rw-rw-rw-  2.0 fat     2576 b- defN 23-May-05 08:58 we_factor_quad/equity_quad/factor_portfolio/universe_helper.py
 -rw-rw-rw-  2.0 fat      302 b- defN 23-Mar-06 09:30 we_factor_quad/equity_quad/risk_control/__init__.py
--rw-rw-rw-  2.0 fat     3526 b- defN 23-Apr-19 01:28 we_factor_quad/equity_quad/risk_control/index_risk_control.py
+-rw-rw-rw-  2.0 fat     3540 b- defN 23-May-06 07:06 we_factor_quad/equity_quad/risk_control/index_risk_control.py
 -rw-rw-rw-  2.0 fat        0 b- defN 23-Mar-22 07:32 we_factor_quad/equity_quad/risk_control/portfolio_risk_control.py
--rw-rw-rw-  2.0 fat    28996 b- defN 23-Apr-20 04:03 we_factor_quad/equity_quad/risk_control/stock_risk_control.py
--rw-rw-rw-  2.0 fat    36473 b- defN 23-Apr-24 06:28 we_factor_quad/equity_quad/risk_control/stock_risk_control_daily.py
+-rw-rw-rw-  2.0 fat    32117 b- defN 23-May-06 07:06 we_factor_quad/equity_quad/risk_control/stock_risk_control.py
+-rw-rw-rw-  2.0 fat    41864 b- defN 23-May-18 02:11 we_factor_quad/equity_quad/risk_control/stock_risk_control_daily.py
 -rw-rw-rw-  2.0 fat       23 b- defN 23-Mar-06 09:30 we_factor_quad/factor_validation/__init__.py
 -rw-rw-rw-  2.0 fat        0 b- defN 23-Mar-06 09:30 we_factor_quad/factor_validation/report.py
 -rw-rw-rw-  2.0 fat        0 b- defN 23-Mar-06 09:30 we_factor_quad/fi_quad/__init__.py
 -rw-rw-rw-  2.0 fat     5389 b- defN 23-Apr-20 04:03 we_factor_quad/fi_quad/factor_quand_ns.py
 -rw-rw-rw-  2.0 fat        0 b- defN 23-Mar-06 09:30 we_factor_quad/fi_quad/factor_portfolio/__init__.py
 -rw-rw-rw-  2.0 fat        0 b- defN 23-Mar-06 09:30 we_factor_quad/fi_quad/risk_control/__init__.py
--rw-rw-rw-  2.0 fat        0 b- defN 23-Mar-06 09:30 we_factor_quad/wiserdata/__init__.py
--rw-rw-rw-  2.0 fat     4823 b- defN 23-Apr-20 09:06 we_factor_quad/wiserdata/client_local.py
--rw-rw-rw-  2.0 fat      883 b- defN 23-Apr-24 10:00 we_factor_quad-0.0.4.1.dist-info/METADATA
--rw-rw-rw-  2.0 fat       92 b- defN 23-Apr-24 10:00 we_factor_quad-0.0.4.1.dist-info/WHEEL
--rw-rw-rw-  2.0 fat       15 b- defN 23-Apr-24 09:59 we_factor_quad-0.0.4.1.dist-info/top_level.txt
--rw-rw-rw-  2.0 fat        2 b- defN 23-Apr-07 09:17 we_factor_quad-0.0.4.1.dist-info/zip-safe
-?rw-rw-r--  2.0 fat     3575 b- defN 23-Apr-24 10:00 we_factor_quad-0.0.4.1.dist-info/RECORD
-36 files, 214016 bytes uncompressed, 58207 bytes compressed:  72.8%
+-rw-rw-rw-  2.0 fat      958 b- defN 23-May-25 01:40 we_factor_quad-0.5.0.dist-info/METADATA
+-rw-rw-rw-  2.0 fat       92 b- defN 23-May-25 01:40 we_factor_quad-0.5.0.dist-info/WHEEL
+-rw-rw-rw-  2.0 fat       15 b- defN 23-May-25 01:40 we_factor_quad-0.5.0.dist-info/top_level.txt
+-rw-rw-rw-  2.0 fat        2 b- defN 23-May-08 04:11 we_factor_quad-0.5.0.dist-info/zip-safe
+?rw-rw-r--  2.0 fat     3497 b- defN 23-May-25 01:40 we_factor_quad-0.5.0.dist-info/RECORD
+35 files, 224754 bytes uncompressed, 60131 bytes compressed:  73.2%
```

## zipnote {}

```diff
@@ -6,21 +6,21 @@
 
 Filename: we_factor_quad/data_api.py
 Comment: 
 
 Filename: we_factor_quad/factor_quad.py
 Comment: 
 
-Filename: we_factor_quad/test_settings.py
+Filename: we_factor_quad/factor_quad_settings.py
 Comment: 
 
-Filename: we_factor_quad/user_data_api.py
+Filename: we_factor_quad/utils.py
 Comment: 
 
-Filename: we_factor_quad/utils.py
+Filename: we_factor_quad/workshop.py
 Comment: 
 
 Filename: we_factor_quad/commodity_quad/__init__.py
 Comment: 
 
 Filename: we_factor_quad/commodity_quad/factor_quad_commodity.py
 Comment: 
@@ -30,14 +30,17 @@
 
 Filename: we_factor_quad/commodity_quad/risk_control/__init__.py
 Comment: 
 
 Filename: we_factor_quad/equity_quad/__init__.py
 Comment: 
 
+Filename: we_factor_quad/equity_quad/daily_data_update_preprocessing.py
+Comment: 
+
 Filename: we_factor_quad/equity_quad/factor_quad_equity.py
 Comment: 
 
 Filename: we_factor_quad/equity_quad/fix_missing_psi.py
 Comment: 
 
 Filename: we_factor_quad/equity_quad/solve_colinear.py
@@ -81,29 +84,23 @@
 
 Filename: we_factor_quad/fi_quad/factor_portfolio/__init__.py
 Comment: 
 
 Filename: we_factor_quad/fi_quad/risk_control/__init__.py
 Comment: 
 
-Filename: we_factor_quad/wiserdata/__init__.py
-Comment: 
-
-Filename: we_factor_quad/wiserdata/client_local.py
-Comment: 
-
-Filename: we_factor_quad-0.0.4.1.dist-info/METADATA
+Filename: we_factor_quad-0.5.0.dist-info/METADATA
 Comment: 
 
-Filename: we_factor_quad-0.0.4.1.dist-info/WHEEL
+Filename: we_factor_quad-0.5.0.dist-info/WHEEL
 Comment: 
 
-Filename: we_factor_quad-0.0.4.1.dist-info/top_level.txt
+Filename: we_factor_quad-0.5.0.dist-info/top_level.txt
 Comment: 
 
-Filename: we_factor_quad-0.0.4.1.dist-info/zip-safe
+Filename: we_factor_quad-0.5.0.dist-info/zip-safe
 Comment: 
 
-Filename: we_factor_quad-0.0.4.1.dist-info/RECORD
+Filename: we_factor_quad-0.5.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## we_factor_quad/data_api.py

```diff
@@ -1,29 +1,34 @@
 from typing import Dict, List
 import datetime as datetime
 import pandas as pd
 import numpy as np
 from we_factor_quad.equity_quad.factor_portfolio.universe_helper import fill_notupdated_constituents
 from we_factor_quad.client_local import LocalClient
+from we_factor_quad.factor_quad_settings import StocksOutputReport
+from we_factor_quad.factor_quad_settings import settings
+
 
 def get_stock_return(start,
                      end,
                      sample_stk=[],
                      freq='BM'):
     '''
     从数据库获取stock return
     Args:
         start: start_date 格式为"xxxxxxxx"纯数字字符串！
         end: end_date 格式为"xxxxxxxx"纯数字字符串！
 
     Returns: monthly_ret adn close price
 
     '''
-    import we_dms.wiser_data_api.return_api as return_api
-
+    try:
+        import we_dms.wiser_data_api.return_api as return_api
+    except Exception as e:
+        raise e('捕获异常')
     returns = return_api.load_prerequisite_stk_data(start=start, end=end, if_scale=False, if_clean_suspen=False,
                                                     src='wedata_ths')
     cash_ti = return_api.load_cash_ti(start, end)
 
     returns['CODE_ID'] = returns['CODE_ID'].apply(lambda x: 'CN' + x.split('.')[0])
     returns = returns.drop_duplicates(['TRADE_DT', 'CODE_ID'])
     px_close = returns.pivot(index='TRADE_DT', columns='CODE_ID', values='S_DQ_ADJCLOSE')
@@ -36,14 +41,15 @@
     # make monthly_ex_ret
     monthly_ret = monthly_ret.sub(np.log(cash_ti).asfreq(freq, method='pad').diff(), axis=0)
     if len(sample_stk) > 0:
         monthly_ret = monthly_ret[sample_stk]
     # 为了适应这个函数的使用情景，这里px_close返回的永远是全部股票的，而monthly_ret则可以被universe filter
     return monthly_ret
 
+
 def wiser_download_em_result(case_name: str,
                              which: str,
                              start_date: str,
                              end_date: str,
                              universe: List = [],
                              mode="local",
                              seadrive_localpath: str = None) -> pd.DataFrame:
@@ -102,16 +108,19 @@
 def wiser_data_query_split(param: Dict, years_split: int = 1):
     """
     :param param:
     :param years_split:
     :return:
     """
     # wedata 数据下载有限制，本方法为分时间段（years_split年）下载数据
-    import wiserdata as wedata
-
+    try:
+        import wiserdata as wedata
+        wedata.login('admin', 'admin')
+    except Exception as e:
+        raise e('捕获异常')
     if (datetime.datetime.strptime(param['end_date'], '%Y%m%d') - datetime.datetime.strptime(
             param['start_date'], '%Y%m%d')).days <= years_split * 365:
         tmp_res = wedata.query(param)
     else:
         _param = param.copy()
         tmp_res = pd.DataFrame({})
 
@@ -148,25 +157,34 @@
     Args:
         rename_mapping:
         universe_identifier: 数据库中的指数代码，比如ind422是沪深300， I00275中证500， I06011中证1000
         start_date:
         end_date:
     Returns: 一个wide panel dataframe，里面是所有universe下股票的monthly return
     """
-    import we_dms.wiser_data_api.basic_info_api as basic_info_api
-    import wiserdata as wedata
+    try:
+        import we_dms.wiser_data_api.basic_info_api as basic_info_api
+        import wiserdata as wedata
+    except Exception as e:
+        raise e('捕获异常')
 
     # 数据库中的日期直接用“20100101”这种字符串判断又是会判错边界，改成下面这种形式最保险
     temp_start = pd.to_datetime(start_date, format='%Y%m%d').strftime('%Y-%m-%d %H:%M:%S')
     temp_end = pd.to_datetime(end_date, format='%Y%m%d').strftime('%Y-%m-%d %H:%M:%S')
 
     A_SHARE_CODE_MAP = basic_info_api.basic_sec_info().set_index('SEC_ID')['SEC_CODE'].to_dict()
     # A_SHARE_CODE_MAP缺了这俩股票，补充一下
     A_SHARE_CODE_MAP.update({'SSH601607': '601607', 'SSH600849': '600849'})
 
+    # 如果start_date和end_date离得过近，可能会取不到任何指数，所以需要先往前取一段时间，最后返回值的时候再截断
+    start_end_delta = (pd.Timestamp(end_date) - pd.Timestamp(start_date)).days
+    if start_end_delta < 180:
+        temp_start = (pd.to_datetime(start_date, format='%Y%m%d')
+                      - pd.Timedelta(days=180)).strftime('%Y-%m-%d %H:%M:%S')
+    # date_range = pd.date_range(start=temp_start, end=temp_end)
     if end_date == '':
         range_filter = [f">= '{temp_start}'"]
     else:
         range_filter = [f">= '{temp_start}'", f" <= '{temp_end}'"]
 
     if isinstance(universe_identifier, str):
         universe_identifier = [universe_identifier]
@@ -183,22 +201,25 @@
         'filters': {
             'TD_DATE': range_filter,
             'INDEX_ID': [f"in ('{universe_identifier}')"]
         },
     }
     wedata.login('admin', 'admin')
     all_constituents = wedata.query(param).drop_duplicates(subset=['TD_DATE', 'CONSTITUENT_SEC_ID'])
-    all_constituents = all_constituents.sort_values(by=["TD_DATE", "INDEX_ID", "CONSTITUENT_SEC_ID"]).reset_index(drop=True)
+    all_constituents = all_constituents.sort_values(by=["TD_DATE", "INDEX_ID", "CONSTITUENT_SEC_ID"]).reset_index(
+        drop=True)
     all_constituents.rename(columns={"TD_DATE": 'date', "CONSTITUENT_SEC_ID": 'code'}, inplace=True)
     all_constituents['code'] = all_constituents['code'].map(A_SHARE_CODE_MAP)
     all_constituents['date'] = pd.to_datetime(all_constituents['date'])
     padded_constituents = fill_notupdated_constituents(all_constituents=all_constituents)
     pivoted_constituents = padded_constituents.pivot(index='date', columns='code', values="INDEX_ID")
     pivoted_constituents = ~pd.isnull(pivoted_constituents)
+
     pivoted_constituents = pivoted_constituents.asfreq(freq, method='pad')
+    # pivoted_constituents = pivoted_constituents.reindex(index=date_range).fillna(method='ffill')
     if rename_mapping:
         return pivoted_constituents.rename(columns=rename_mapping)
     else:
         return pivoted_constituents
 
 
 def wiser_fetch_fmp_weights(seadrive_localpath: str,
@@ -211,15 +232,18 @@
         start_date:
         end_date:
         factor_system:
         seadrive_localpath: 本地seadrive的群组资料库地址
 
     Returns:
     """
-    import wiserdata as wedata
+    try:
+        import wiserdata as wedata
+    except Exception as e:
+        raise e('捕获异常')
 
     data_file_dir = f"{seadrive_localpath}\case_{factor_system}"
     client = LocalClient(data_file_dir)
     wedata.login(username='admin', password='admin')
     param = {
         'domain': 'descriptor',
         'phylum': 'characteristic',
@@ -255,27 +279,29 @@
     # import wiserdata as wedata
     data_file_dir = f"{seadrive_localpath}\case_{factor_system}"
     client = LocalClient(data_file_dir)
     # wedata.login(username='admin', password='admin')
     param = {
         'domain': 'descriptor',
         'phylum': 'characteristic',
-        'class': 'factor_return',
+        'class': 'characteristic_return',
         'case': factor_system,
         'start_date': start_date,
         'end_date': end_date,
     }
-    factor_return = client.query(param)[['date', 'factors', 'factor_returns']]
+    factor_return = client.query(param)[['date', 'characteristic', 'return']]
+    factor_return.columns = ['date', 'factors', "factor_returns"]
     factor_return['date'] = pd.to_datetime(factor_return['date'])
     factor_return = factor_return.pivot(index='date', columns='factors', values='factor_returns')
     # factor_return是预测值，延后一月
-    if factor_return.index.min().month == pd.to_datetime(start_date).month:
-        factor_return = factor_return.iloc[1:, :]
+    # if factor_return.index.min().month == pd.to_datetime(start_date).month:
+    #     factor_return = factor_return.iloc[1:, :]
     return factor_return
 
+
 def wiser_query_dwd_data(dwd_list, start, end, pile=False, rename=False, sample_stk=None, split_download=True,
                          years_split=3):
     """
     Grab dwd data from wedata
     :param dwd_list: a list of dwd table name
     :param sample_stk: a list of stock code ,usually use representative old stocks
     :return: a dataframe of query data, index=time, columns=stock id, values= queried data
@@ -286,15 +312,19 @@
     def convert_date_wedata(dt):
         res = pd.to_datetime(dt)
         if res is None:
             return ""
         else:
             return res.strftime("%Y%m%d")
 
-    import wiserdata as wedata
+    try:
+        import wiserdata as wedata
+    except Exception as e:
+        raise e('捕获异常')
+
     res = {}
     if sample_stk is not None:
         col_sample_stk = ['TRADE_DT'] + [''.join(i.split('.')) for i in sample_stk]
     else:
         col_sample_stk = []
 
     wedata.login('admin', 'admin')
@@ -353,23 +383,25 @@
             if rename:
                 df.columns = [TIME_COL_NAME, CODE_COL_NAME, tab.replace('dwd_', '')]
             df[tab.replace('dwd_', '')] = df[tab.replace('dwd_', '')].astype('float')
         res[tab] = df
         print(f' dwd data {tab} loaded!')
     return res
 
+
 # todo yanan :delete get_px_close_old after wedms instead
 def get_px_close_old(start, end):
     px_close = wiser_query_dwd_data(['ths__we_sec_daily_quote_adjust_factor__s_dq_adjclose__forward'],
-                                         start=start, end=end, rename=True, pile=True,
-                                         )['ths__we_sec_daily_quote_adjust_factor__s_dq_adjclose__forward']
+                                    start=start, end=end, rename=True, pile=True,
+                                    )['ths__we_sec_daily_quote_adjust_factor__s_dq_adjclose__forward']
     px_close = px_close.pivot(index='TRADE_DT', columns='CODE_ID',
-                                        values='ths__we_sec_daily_quote_adjust_factor__s_dq_adjclose__forward')
+                              values='ths__we_sec_daily_quote_adjust_factor__s_dq_adjclose__forward')
     return px_close
 
+
 def get_px_close(start, end):
     '''
     use px_close api get stock close price
     Args:
         start: start_date 格式为"xxxxxxxx"纯数字字符串！
         end: end_date 格式为"xxxxxxxx"纯数字字符串！
 
@@ -380,46 +412,52 @@
     2022-12-01  |  13.10    |  7.22    |
     2022-12-02  |  12.90    |  7.23    |
     2022-12-05  |  13.53    |  7.36    |
     2022-12-06  |  13.43    |  7.36    |
     2022-12-07  |  13.15    |  7.34    |
 
     '''
-    import we_dms.wiser_data_api.wedata_api as wedata_api
+    try:
+        import we_dms.wiser_data_api.wedata_api as wedata_api
+    except Exception as e:
+        raise e('请您参考MSG用户文档，提供个股收盘价数据并修改get_px_close函数')
+
     px_close = wedata_api.query_dwd_data(['ths__we_sec_daily_quote_adjust_factor__s_dq_adjclose__forward'],
                                          start=start, end=end, rename=True, pile=True,
                                          )['ths__we_sec_daily_quote_adjust_factor__s_dq_adjclose__forward']
     px_close = px_close.pivot(index='TRADE_DT', columns='CODE_ID',
                               values='ths__we_sec_daily_quote_adjust_factor__s_dq_adjclose__forward')
     return px_close
 
+
 def wiser_get_stock_return(start: str,
                            end: str,
                            seadrive_localpath,
+                           factor_system: str = "HF25_SRAM_DAILY",
                            sample_stk=[],
                            freq='BM'):
     '''
-    use return api get monthly return data and  close
+    use return api get monthly return data and close
     Args:
         freq:
         sample_stk:
         from_seadrive:
         start: start_date 格式为"xxxxxxxx"纯数字字符串！
         end: end_date 格式为"xxxxxxxx"纯数字字符串！
 
     Returns: monthly_ret adn close price
 
     '''
 
-    client = LocalClient(f"{seadrive_localpath}/case_BasicData")
+    client = LocalClient(f"{seadrive_localpath}")
     # wedata.login(username='admin', password='admin')
     param = {
         'domain': 'descriptor',
         'phylum': 'characteristic',
-        'case': 'BasicData',
+        'case': 'HF25_SRAM_DAILY',
         'class': 'daily_excess_return',
         'start_date': start,
         'end_date': end,
     }
     if len(sample_stk) > 0:
         code_filter = {'code': [f"in {tuple(sample_stk)}"]}
         param.update({'filters': {}})
@@ -434,23 +472,23 @@
     else:
         pivoted_daily_returns = (ret.pivot(index='date', columns='code', values='daily_return')).replace(
             np.nan, 0.0)
         pivoted_daily_returns.index = pd.to_datetime(list(pivoted_daily_returns.index))
         return pivoted_daily_returns
 
 
-
 def produce_monthly_return_from_daily(start,
                                       end,
                                       daily_returns: pd.DataFrame) -> pd.DataFrame:
-
-    pivoted_daily_returns = (daily_returns.pivot(index='date', columns='code', values='daily_return')).replace(np.nan, 0.0)
+    pivoted_daily_returns = (daily_returns.pivot(index='date', columns='code', values='daily_return')).replace(np.nan,
+                                                                                                               0.0)
     pivoted_daily_returns.index = pd.to_datetime(list(pivoted_daily_returns.index))
     pivoted_daily_returns.index = pivoted_daily_returns.index.to_period("M")
-    monthly_return = pivoted_daily_returns.groupby(level=0).apply(lambda x: x.cumsum(skipna=True).iloc[-1, :]).replace(0.0, np.nan)
+    monthly_return = pivoted_daily_returns.groupby(level=0).apply(lambda x: x.cumsum(skipna=True).iloc[-1, :]).replace(
+        0.0, np.nan)
     monthly_return = monthly_return.to_timestamp('M')
     monthly_return.index = pd.date_range(start=start, end=end, freq='BM')
     monthly_return.iloc[0, :] = np.nan
     return monthly_return
 
 
 def ths_a_share_code_map(qtype='A股'):
@@ -541,15 +579,87 @@
     res = wiser_download_em_result(case_name='HF25_SRA', start_date='20200101',
                                    which='characteristic_exposure',
                                    end_date='20200401', mode='local',
                                    seadrive_localpath=seadrive_local_path)
     return res
 
 
+def user_fetch_factor_return(start_date=StocksOutputReport.start, end_date=StocksOutputReport.end,
+                             local_path=settings.seadrive_local_path,
+                             msg_factor_case_name=StocksOutputReport.msg_factor_case_name):
+    return wiser_fetch_factor_return(local_path, start_date, end_date, msg_factor_case_name)
+
+# def write_sql(self, df):
+#     import pymysql
+#
+#     # 数据库连接信息
+#     df = df.rename(
+#         columns={'date': 'trade_date', '0': 'values'})
+#     from sqlalchemy import create_engine
+#     from urllib.parse import quote_plus as urlquote
+#
+#     from sqlalchemy.orm import sessionmaker
+#     engine = create_engine(f"mysql+pymysql://root:{urlquote('dev-project@mysql.')}@172.16.127.213:3306/supersetdb")
+#
+#     # session = sessionmaker(engine)()
+#
+#     data = df
+#     data.to_sql('FactorReturn', engine, if_exists='append', chunksize=100000, index=None)
+#     print('存入成功！')
+#
+#     pass
+
+def check_quad_data(start_date='20210101',end_date='20210120'):
+    local_path = r'C:\Users\Administrator\seadrive_root\gorilla\共享资料库'
+    msg_factor_case_name = 'HF25_SRAM_DAILY_Tsinghua_Internal_Usage'
+
+    from we_factor_quad.equity_quad.factor_quad_equity import FactorQuadEQ
+    year_lst = sorted(list(set(pd.date_range(start_date, end_date).year)))
+    # 开始到结束日期之间间隔一年划分
+    truncate_date = [start_date] + [str(i) + '0101' for i in year_lst[1:]] + [end_date]
+
+    for i, j in enumerate(truncate_date[1:]):
+        print(f'checking date :{truncate_date[i]} to {j}')
+        myquad = FactorQuadEQ.create_factor_quad(msg_factor_case_name, truncate_date[i], j, 1, local_path)
+        for date in myquad.date_list:
+            beta_factors = myquad.get_beta(date).columns
+            sigma_factors = myquad.get_sigma(date).columns
+            assert len(set(beta_factors) - set(sigma_factors)) == 0, 'beta factors more than sigma factors'
+            assert len(set(sigma_factors) - set(beta_factors)) == 0, 'sigma factors more than beta factors'
+
+        px_close = get_px_close(truncate_date[i], j)
+        trade_date_lst = list(px_close.index)
+        factor_return = wiser_fetch_factor_return(local_path, start_date, end_date, msg_factor_case_name)
+        # 因子收益数据日期不多不少
+        assert len(set(trade_date_lst) - set(factor_return.index)) == 0, 'factor return less date'
+        assert len(set(factor_return.index) - set(trade_date_lst)) == 0, 'factor return more date'
+        # 因子四元组日期不多不少
+        assert len(set(trade_date_lst) - set(myquad.beta_ts.date)) == 0, 'beta_ts less date'
+        assert len(set(myquad.beta_ts.date) - set(trade_date_lst)) == 0, 'beta_ts more date'
+        assert len(set(trade_date_lst) - set(myquad.psi_ts.date)) == 0, 'psi_ts less date'
+        assert len(set(myquad.psi_ts.date) - set(trade_date_lst)) == 0, 'psi_ts more date'
+        assert len(set(trade_date_lst) - set(myquad.scale_ts.date)) == 0, 'scale_ts less date'
+        assert len(set(myquad.scale_ts.date) - set(trade_date_lst)) == 0, 'scale_ts more date'
+        assert len(set(trade_date_lst) - set(myquad.sigma_ts.date)) == 0, 'sigma_ts less date'
+        assert len(set(myquad.sigma_ts.date) - set(trade_date_lst)) == 0, 'sigma_ts more date'
+    pass
+
 if __name__ == '__main__':
-    start_date = "20200101"
-    end_date = "20221031"
-    wedata.login('admin', 'admin')
+    import warnings
+    warnings.filterwarnings('ignore')
+    check_quad_data(start_date='20130101', end_date='20221231')
+    # local_path = r'C:\Users\Administrator\Seafile'
+    local_path = r'C:\Users\Administrator\seadrive_root\gorilla\共享资料库'
+    msg_factor_case_name = 'HF25_SRAM_DAILY_Tsinghua_Internal_Usage'
+    # msg_factor_case_name = 'HF25_SRAM_DAILY'
+    start_date = "20100701"
+    end_date = "20221231"
     # test_local_mode()
-    get_px_close(start_date, end_date)
+    # user_fetch_factor_return()
+    factor_return = wiser_fetch_factor_return(local_path, start_date, end_date, msg_factor_case_name)
+
+
+    # get_px_close(start_date, end_date)
+
+
     # monthly_return1 = wiser_get_monthly_return(start=start_date, end=end_date, seadrive_localpath='D:\seadrive_cache_folder\zhouly\群组资料库')
     print(1)
```

## we_factor_quad/factor_quad.py

```diff
@@ -1,8 +1,9 @@
 import os.path
+import pathlib as pl
 import pickle
 from typing import Dict, AnyStr, List
 import numpy as np
 import pandas as pd
 from we_factor_quad.data_api import wiser_download_em_result
 
 
@@ -98,14 +99,20 @@
         self.sigma_ts = self.sigma_ts.set_index([self._time_col_name, 'source']).unstack().fillna(0.0).stack()
         cols_beta = self.sigma_ts.columns
         self.sigma_ts = self.sigma_ts.reset_index()
         # Check all the factors are there
         missing_factors = [i for i in np.unique(self.beta_ts['characteristic'])
                            if i not in ([self._time_col_name, self._code_col_name] + list(self.sigma_ts.columns))]
 
+        for date in list(set(self.beta_ts[self._time_col_name])):
+            if '2021-07-29' < str(date)[:10] < '2021-08-05':
+                beta_ts = self.beta_ts[self.beta_ts[self._time_col_name] == date]
+                sigma_ts = self.sigma_ts[self.sigma_ts['date'] == date]
+                self.beta_ts = self.beta_ts.drop(beta_ts[~beta_ts.characteristic.isin(set(sigma_ts.source))].index)
+
         if len(missing_factors) > 0:
             beta_lst = []
             for date in list(set(self.beta_ts[self._time_col_name])):
                 beta_t = self.beta_ts[self.beta_ts[self._time_col_name] == date]
                 zero_factors = beta_t.groupby('characteristic').sum()
                 missing_factors = zero_factors[zero_factors == 0].dropna().index
                 beta_ts = beta_t[~beta_t['characteristic'].isin(missing_factors)]
@@ -425,24 +432,67 @@
         根据要模拟的factor的名称（类别），提取对应的因子四元组数据
         实际需要 Sigma_f, beta_t, scale用于调整beta，Psi
         params local_path: 本地临时文件
         params from_src: from which source， 0表示网络sql，1表示sea_drive, 2表示 local path
         params local_path: if from_src == 1, we need a local path
         Returns: 结果应该是4个对象组成的dict
         """
+        which_objs = [
+            "characteristic_exposure",
+            "characteristic_covariance",
+            "characteristic_idiosyncratic_variance",
+            "characteristic_scale"]
+
         if from_src == 2:  # 从本地导入数据
             assert local_path is not None, "If select from_src = 2 use local pickle file, you must input local path!"
             assert local_path[-4:] == ".pkl", "local path is not a pkl file!"
             raw_data_dic = FactorQuad.load_obj(local_path)
+
+        # 接收csv文件生成四元组,需要local_path参数指示日期文件夹的上层文件夹的位置，比如现在的
+        elif from_src == 3:
+            path_for_dates = os.path.join(local_path, factor_system)
+            repo_list = sorted(os.listdir(path_for_dates))
+            index_end = repo_list.index(end_date)
+            index_start = repo_list.index(start_date)
+            required_repo_list = repo_list[index_start: index_end + 1]
+            required_path_list = [os.path.join(path_for_dates, x) for x in required_repo_list]
+            raw_data_list = [pd.DataFrame([])] * len(which_objs)
+            raw_data_dict = dict(zip(which_objs, raw_data_list))
+            for date_path in required_path_list:
+                for data_name in which_objs:
+                    data_path = f"{os.path.join(date_path, data_name)}.csv"
+                    data_ = pd.read_csv(data_path, index_col=0)
+                    data_['case'] = factor_system
+                    data_.columns = [x.lower() for x in data_.columns]
+                    raw_data_dict[data_name] = pd.concat([raw_data_dict[data_name], data_])
+            for key in raw_data_dict.keys():
+                if key == 'characteristic_exposure':
+                    raw_data_dict[key] = raw_data_dict[key][["case", "date", 'characteristic',
+                                                             'exposure', 'code', "type"]]
+                elif key == "characteristic_covariance":
+                    raw_data_dict[key] = raw_data_dict[key][["case", "date", 'source',
+                                                             'target', 'cov']]
+                elif key == 'characteristic_idiosyncratic_variance':
+                    raw_data_dict[key] = raw_data_dict[key][["case", "date", 'code', 'var']]
+                elif key == 'characteristic_scale':
+                    raw_data_dict[key] = raw_data_dict[key][["case", "date", 'code', 'scale']]
+                else:
+                    raise ValueError(f"{key} is not a valid raw data name..."
+                                     f"it must be characteristic_idiosyncratic_variance, "
+                                     f"characteristic_exposure, characteristic_covariance, or characteristic_scale")
+
+            return raw_data_dict
+
+
         else:  # 0 remote, 1 sea_drive， 不是从本地下载数据
-            which_objs = [
-                "characteristic_exposure",
-                "characteristic_covariance",
-                "characteristic_idiosyncratic_variance",
-                "characteristic_scale"]
+            # which_objs = [
+            #     "characteristic_exposure",
+            #     "characteristic_covariance",
+            #     "characteristic_idiosyncratic_variance",
+            #     "characteristic_scale"]
             raw_data_dic = {}
             if from_src == 1:  # 从sea_drive 下载数据
                 assert local_path is not None, "local_path (seadrive path) should not be None!"
                 for x in which_objs:
                     raw_data_dic[x] = wiser_download_em_result(case_name=factor_system,
                                                                which=x,
                                                                start_date=str(start_date),
@@ -663,8 +713,14 @@
     test_quad_series_and_build_portfolio()
     # test_upload_data()
 
 
 if __name__ == '__main__':
     # pd.set_option('display.max_columns', None)
     # pd.set_option('display.max_rows', None)
-    test_quad_data_obj()
+    quad = FactorQuad.create_factor_quad(start_date="20210727",
+                                         end_date="20210730",
+                                         factor_system="HF25_SRAM_DAILY",
+                                         from_src=1,
+                                         local_path='D:\seadrive_cache_folder\zhouly\群组资料库')
+    print(1)
+    # test_quad_data_obj()
```

## we_factor_quad/equity_quad/factor_quad_equity.py

```diff
@@ -3,15 +3,15 @@
 import os
 
 import numpy as np
 import pandas as pd
 from typing import Dict, Union, List
 from we_factor_quad.equity_quad import solve_colinear
 from we_factor_quad.factor_quad import FactorQuad
-from we_factor_quad.test_settings import StocksOutputReport, settings
+from we_factor_quad.factor_quad_settings import StocksOutputReport, settings
 
 
 class FactorQuadEQ(FactorQuad):
     def __init__(self, factor_system: str, raw_data: Dict,
                  _code_col_name: str = "code",
                  _time_col_name: str = "date"):
         """
@@ -46,14 +46,17 @@
         :param factor_system: 因子系统的名称，对应于数据库中的 case 名称
         :param start_date: 8 digits格式 日期
         :param end_date:
         :param from_src: 0 表示从网络sql提取数据，1表示从sea_drive提取数据，2表示从本地提取数据（2需要对应一个pkl文件）
         :param local_path: 当from_src == 2时，需要一个pkl文件；0表示remote，1表示 seadrive，所以默认为1；
         :return:
         """
+        # 结束日期处于行业调整期，自动将结束日期改为调整后
+        # if '20210805' > end_date > '20210729':
+        #     end_date = '20210806'
         raw_data = FactorQuadEQ.factor_quads_download(factor_system=factor_system,
                                                       start_date=start_date,
                                                       end_date=end_date,
                                                       from_src=from_src,
                                                       local_path=local_path)
         # raw_data = merge("D:/jiaochayuan_files/projects/we_factor_quad_/we_factor_quad/equity_quad/HF25_day_test")
         return FactorQuadEQ(factor_system, raw_data=raw_data)
@@ -180,38 +183,66 @@
         psi_pivoted = self.psi_ts.pivot(index=self._time_col_name, columns=self._code_col_name, values='var')
         psi_cap = (0.0 * psi_pivoted).add(psi_pivoted.median(1) * cap_multiplier, axis=0)
         idx = (psi_pivoted > psi_cap)
         psi_pivoted[idx] = psi_cap[idx]
         # return psi_pivoted.stack().reset_index().rename(columns={0: 'var'})
         self.psi_ts = psi_pivoted.stack().reset_index().rename(columns={0: 'var'})  # 直接内部修正掉，不需要返回了
 
-def load_quad_to_csv():
+
+def load_quad_to_csv(csv_output_path=None):
     """
     将seadrive中的quad数据保存成csv文件，并用quad计算factor
     """
     myquad = FactorQuadEQ.create_factor_quad(factor_system=StocksOutputReport.msg_factor_case_name,
                                              start_date=StocksOutputReport.start,
                                              end_date=StocksOutputReport.end,
                                              from_src=StocksOutputReport.from_local,
                                              local_path=settings.seadrive_local_path)
+    import datetime
+    if pd.to_datetime(StocksOutputReport.end) not in sorted(myquad.date_list):
+        StocksOutputReport.end = datetime.datetime.strftime(pd.to_datetime(sorted(myquad.date_list)[-1]), '%Y%m%d')
+    added_myquad = FactorQuadEQ.create_factor_quad(factor_system=StocksOutputReport.msg_factor_case_name,
+                                                   start_date=StocksOutputReport.end,
+                                                   end_date=datetime.datetime.strftime((pd.to_datetime(
+                                                       StocksOutputReport.end) + datetime.timedelta(days=20)),
+                                                                                       '%Y%m%d'),
+                                                   from_src=StocksOutputReport.from_local,
+                                                   local_path=settings.seadrive_local_path)
+    assert len(added_myquad.date_list) > 0, 'factor return数据不全'
+    if len(added_myquad.date_list) > 1:
+        added_date = added_myquad.date_list[1]
+    else:
+        added_date = added_myquad.date_list[0]
+    from we_factor_quad.data_api import wiser_fetch_factor_return
+
+    if csv_output_path is None:
+        csv_output_path = os.getcwd()
+    wiser_fetch_factor_return(factor_system=StocksOutputReport.msg_factor_case_name,
+                              start_date=StocksOutputReport.start,
+                              end_date=datetime.datetime.strftime(pd.to_datetime(added_date), '%Y%m%d'),
+                              seadrive_localpath=settings.seadrive_local_path).to_csv(
+        os.path.join(csv_output_path, "characteristic_return.csv"))
+
     # 不传入路径默认csv保存到当前文件夹下
-    myquad.save_to_csv()
+    myquad.save_to_csv(csv_output_path)
 
 
 def test_FactorQuadEQ():
     def load_data():
         myquad = FactorQuadEQ.create_factor_quad(factor_system=StocksOutputReport.msg_factor_case_name,
                                                  start_date=StocksOutputReport.start,
                                                  end_date=StocksOutputReport.end,
                                                  from_src=StocksOutputReport.from_local,
                                                  local_path=settings.seadrive_local_path)
         myquad.info("check info")
         print("finish")
+
     load_data()
 
+
 # def merge(file_path):
 #     files =  [
 #         "characteristic_covariance.csv",
 #         "characteristic_exposure.csv",
 #         "characteristic_idiosyncratic_variance.csv",
 #         "characteristic_scale.csv"
 #     ]
@@ -238,8 +269,9 @@
 #
 #     return {"characteristic_covariance": characteristic_covariance[characteristic_covariance['DATE']>=20221101],\
 #            "characteristic_exposure": characteristic_exposure[characteristic_exposure['DATE']>=20221101],\
 #            "characteristic_idiosyncratic_variance": characteristic_idiosyncratic_variance[characteristic_idiosyncratic_variance['DATE']>=20221101],\
 #            "characteristic_scale": characteristic_scale[characteristic_scale['DATE']>=20221101]}
 
 if __name__ == '__main__':
-    test_FactorQuadEQ()
+    # test_FactorQuadEQ()
+    load_quad_to_csv()
```

## we_factor_quad/equity_quad/fix_missing_psi.py

```diff
@@ -1,15 +1,15 @@
 import os
 from copy import copy, deepcopy
 import pandas as pd
 import numpy as np
 from we_factor_quad.equity_quad.factor_quad_equity import FactorQuadEQ
 from we_factor_quad.equity_quad.factor_portfolio.full_factor_mimicking_portfolio import FmpAnalyzer
 import we_factor_quad.data_api as dapi
-from we_factor_quad.test_settings import FmpUniverseConfig, settings
+from we_factor_quad.factor_quad_settings import FmpUniverseConfig, settings
 date = 'date'
 code = 'code'
 
 def get_fixed_psi(quad: FactorQuadEQ,
                   seadrive_localpath='D:\seadrive_cache_folder\zhouly\群组资料库'):
     """
     补上psi中的缺失位，并返回修复后的psi
@@ -68,15 +68,15 @@
     total_return_filter = ((_return == 0.0) + loc_noreturn) >= 1
     factor_return = fmp_obj.construct_factor_return(weights_df=weights, ret=_return)
 
     revive_beta_with_scale(quad=quad, hetero_adj=True)
     _return = revive_stock_ret_with_scale(quad=quad, ret=_return)
     total_return_filter = total_return_filter.replace(True, np.nan).replace(False, 1.0)
     sys_return, res_return = fmp_obj.factor_decompose_asset_return(factor_return=factor_return,
-                                                                   monthly_ret=_return)
+                                                                   stock_ret=_return)
     total_return_filter = total_return_filter.reindex(columns=res_return.columns, index=res_return.index)
     res_return = res_return * total_return_filter
     all_psi = ((res_return ** 2 * 52).ewm(com=0.003).mean()).stack(dropna=False)
 
     filled_nan_psi = all_psi[all_psi.index.isin(need_fill_index.index)]
     filled_nan_psi = filled_nan_psi.replace(0.0, np.nan).dropna()
     filled_nan_psi.index.names = ['date', 'code']
@@ -180,15 +180,15 @@
         raise ValueError("stock code does not exist!")
     return new_code
 
 
 
 
 if __name__ == "__main__":
-    start_date = "20210701"
+    start_date = "20230329"
     end_date = "20230330"
     sram_quad = FactorQuadEQ.create_factor_quad(local_path='D:\seadrive_cache_folder\zhouly\群组资料库',
                                                 factor_system='HF25_SRAM_DAILY',
                                                 start_date=start_date,
                                                 end_date=end_date)
     new_psi = get_fixed_psi(quad=sram_quad)
     save_new_psi("HF25_day_test_newpsi3")
```

## we_factor_quad/equity_quad/factor_portfolio/full_factor_mimicking_portfolio.py

```diff
@@ -8,15 +8,15 @@
 from matplotlib import pyplot as plt, ticker
 from we_report.interface.excel_reporter import ExcelReport as Ereporter
 from we_report.data_type.report_data import PageData, ReportData
 import we_factor_quad.data_api as dapi
 from we_factor_quad.utils import summary_stats
 import we_factor_quad.equity_quad.factor_portfolio.universe_helper as uhelper
 from we_factor_quad.equity_quad.factor_quad_equity import FactorQuadEQ
-from we_factor_quad.test_settings import FmpUniverseConfig, settings
+from we_factor_quad.factor_quad_settings import FmpUniverseConfig, settings
 import pandas as pd
 import numpy as np
 warnings.filterwarnings('ignore')
 
 
 class FmpAnalyzer:
     """
@@ -65,45 +65,49 @@
         repeated_monthly_return = pd.DataFrame(data=np.repeat(_monthly_return.values,
                                                               repeats=factor_num, axis=0),
                                                columns=_monthly_return.columns)
         repeated_monthly_return['factors'] = weights_renamed['factors']
         monthly_return_to_use = repeated_monthly_return.set_index([self.time_col_name, 'factors']).dropna(how='all')
         # 下面等于是shift了weights
         weights_to_use = weights_renamed.set_index([self.time_col_name, 'factors']).shift(factor_num).dropna(how='all')
-        unstacked_factor_return = weights_to_use.groupby(level=[0]) \
-            .apply(lambda x: (x * monthly_return_to_use.loc[x.index]).sum(axis=1)).unstack() \
-            .reset_index(level=1, drop=True)[factor_names_preserved]
+        if len(factor_names_preserved) == weights_to_use.shape[0]:
+            unstacked_factor_return = (weights_to_use * monthly_return_to_use.loc[weights_to_use.index]).sum(axis=1) \
+                .unstack()
+        else:
+            unstacked_factor_return = weights_to_use.groupby(level=[0]) \
+                .apply(lambda x: (x * monthly_return_to_use.loc[x.index]).sum(axis=1)).unstack() \
+                .reset_index(level=1, drop=True)[factor_names_preserved]
 
         return unstacked_factor_return
 
     def factor_decompose_asset_return(self,
                                       factor_return: pd.DataFrame,
-                                      monthly_ret: pd.DataFrame,
+                                      stock_ret: pd.DataFrame,
                                       stock_universe: list = []) -> (pd.DataFrame, pd.DataFrame):
         """
 
         Args:
-            monthly_ret:
+            stock_ret: 可以是任意频率的return
             factor_return:
             stock_universe: 表示需要计算sys和residual的股票代码， 格式是"CNXXXXXX"
 
         Returns:
         """
         sigma_ts_wc, original_beta_withcountry = self.quad.add_country_factor()
         original_beta_withcountry_copy = copy.deepcopy(original_beta_withcountry)
         original_beta_withcountry_copy[self.code_col_name] = ['CN' + x.split(".")[0] for x in
                                                               original_beta_withcountry_copy[self.code_col_name]
                                                               if len(x.split(".")) > 1]
 
         if len(stock_universe) > 0:
-            monthly_return = monthly_ret[stock_universe]
+            monthly_return = stock_ret[stock_universe]
             universe_filtered_beta_ts = original_beta_withcountry_copy[
                 original_beta_withcountry_copy[self.code_col_name].isin(stock_universe)].reset_index(drop=True)
         else:
-            monthly_return = monthly_ret
+            monthly_return = stock_ret
             universe_filtered_beta_ts = original_beta_withcountry_copy
         universe_filtered_beta_ts = universe_filtered_beta_ts.sort_values(
             by=[self.time_col_name, self.code_col_name]).reset_index(drop=True)
         all_stocks = sorted(list(set(universe_filtered_beta_ts[self.code_col_name])))
         all_dates = sorted(list(set(universe_filtered_beta_ts[self.time_col_name])))
         allstock_monthly_return = monthly_return.reindex(index=all_dates, method='pad')
         allstock_monthly_return = allstock_monthly_return.reindex(columns=all_stocks)
@@ -117,18 +121,21 @@
             first_date_length).dropna(how='all')
         if beta_to_use.shape[0] != repeated_factor_return.shape[0]:
             multiindex = allstock_monthly_return.dropna(how='all').stack(dropna=False).index
             beta_to_use = beta_to_use.reindex(index=multiindex)
             beta_to_use.index.names = (self.time_col_name, self.code_col_name)
         repeated_factor_return[self.code_col_name] = beta_to_use.reset_index()[self.code_col_name]
         factor_return_to_use = repeated_factor_return.set_index([self.time_col_name, self.code_col_name])
-
-        sys_return = beta_to_use.groupby(level=[0]) \
-            .apply(lambda x: (x * factor_return_to_use.loc[x.index]).sum(axis=1)).unstack() \
-            .reset_index(level=1, drop=True)
+        beta_to_use = beta_to_use.reindex(columns=factor_return_to_use.columns)
+        if factor_return.shape[0] == 1:
+            sys_return = (beta_to_use * factor_return_to_use).sum(axis=1).unstack()
+        else:
+            sys_return = beta_to_use.groupby(level=[0]) \
+                .apply(lambda x: (x * factor_return_to_use.loc[x.index]).sum(axis=1)).unstack() \
+                .reset_index(level=1, drop=True)
         residual_return = allstock_monthly_return.iloc[1:, :] - sys_return
         return sys_return, residual_return
 
     def construct_all_factor_performances(self,
                                           factor_return: pd.DataFrame) -> dict:
         """
         储存并生成一个excel sheet里面含有单因子的accumulated factor return 的 time series和相应的线图
@@ -292,15 +299,15 @@
         """
 
         monthly_ret = dapi.wiser_get_stock_return(start=self.start_date, end=self.end_date,
                                                     seadrive_localpath=seadrive_localpath)
         weights_df = dapi.wiser_fetch_fmp_weights(start_date=self.start_date, end_date=self.end_date,
                                                   seadrive_localpath=seadrive_localpath)
         factor_return = self.construct_factor_return(ret=monthly_ret, weights_df=weights_df)
-        sys, residual = self.factor_decompose_asset_return(monthly_ret=monthly_ret, factor_return=factor_return)
+        sys, residual = self.factor_decompose_asset_return(stock_ret=monthly_ret, factor_return=factor_return)
         import os
         if dir is None:
             dir = os.path.dirname(__file__)
         factor_return.to_csv(os.path.join(dir, "factor_return.csv"))
         sys.to_csv(os.path.join(dir, "sys_return.csv"))
         residual.to_csv(os.path.join(dir, "residual_return.csv"))
 
@@ -312,30 +319,29 @@
         seadrive_localpath = settings.seadrive_local_path
         quad = FactorQuadEQ.create_factor_quad(start_date=start_date, end_date=end_date, factor_system="HF25_SRAM", local_path=seadrive_localpath)
         analyzer = FmpAnalyzer(quad)
         monthly_ret = dapi.wiser_get_stock_return(start=start_date, end=end_date, seadrive_localpath=seadrive_localpath)
         weights_df = dapi.wiser_fetch_fmp_weights(start_date=start_date, end_date=end_date,
                                                   seadrive_localpath=seadrive_localpath)
         factor_return = analyzer.construct_factor_return(ret=monthly_ret, weights_df=weights_df)
-        sys, residual = analyzer.factor_decompose_asset_return(monthly_ret=monthly_ret, factor_return=factor_return)
-        print(1)
+        sys, residual = analyzer.factor_decompose_asset_return(stock_ret=monthly_ret, factor_return=factor_return)
 
     def test_fmp2():
         start_date = "20130101"
         end_date = "20221031"
         seadrive_localpath = settings.seadrive_local_path
         quad = FactorQuadEQ.create_factor_quad(start_date=start_date, end_date=end_date, factor_system="HF25_SRAM",
                                                local_path=seadrive_localpath)
         analyzer = FmpAnalyzer(quad)
         monthly_ret = dapi.wiser_get_stock_return(start=start_date, end=end_date,
                                                     seadrive_localpath=seadrive_localpath)
         weights_df = dapi.wiser_fetch_fmp_weights(start_date=start_date, end_date=end_date,
                                                   seadrive_localpath=seadrive_localpath)
         factor_return = analyzer.construct_factor_return(ret=monthly_ret, weights_df=weights_df)
-        sys, residual = analyzer.factor_decompose_asset_return(monthly_ret=monthly_ret, factor_return=factor_return)
+        sys, residual = analyzer.factor_decompose_asset_return(stock_ret=monthly_ret, factor_return=factor_return)
         # analyzer.output_report(weights_df=weights_df, monthly_ret=monthly_ret)
 
     def test_fmp3_alternative_universe():
         """
         不用seadrive，用数仓取下来的指数混合生成新的universe。不过由于不能提供给客户数仓，这个test只是用来检验是否可以手工输入一个universe来
         生成fmp weights，进而计算factor return, systematic return, residual return
         """
@@ -348,15 +354,15 @@
         monthly_ret = dapi.wiser_get_stock_return(start=start_date,
                                                   end=end_date,
                                                   seadrive_localpath=seadrive_localpath)
         weights_df = analyzer.get_portfolio_weights(start_date=start_date,
                                                     end_date=end_date,
                                                     universe_conf=FmpUniverseConfig.universe_config['alternative_universe'])
         factor_return = analyzer.construct_factor_return(ret=monthly_ret, weights_df=weights_df)
-        sys, residual = analyzer.factor_decompose_asset_return(monthly_ret=monthly_ret, factor_return=factor_return)
+        sys, residual = analyzer.factor_decompose_asset_return(stock_ret=monthly_ret, factor_return=factor_return)
         # analyzer.output_report(weights_df=weights_df,
         #                        monthly_ret=monthly_ret,
         #                        output_workbook_name="factor_return_alter_universe")
 
     def test_fmp_to_csv():
         """
         将seadrive中的quad数据保存成csv文件，并用quad计算factor return, systematic return, residual return，保存为csv文件
```

## we_factor_quad/equity_quad/factor_portfolio/universe_helper.py

```diff
@@ -26,14 +26,15 @@
         stacked_index_constituents = pivoted_index_constituents.stack(dropna=False).reset_index()
         modified_all_constituents = pd.concat([modified_all_constituents, stacked_index_constituents], axis=0)
     modified_all_constituents = modified_all_constituents.rename(mapper={0: "INDEX_ID"}, axis=1)
     modified_all_constituents = modified_all_constituents.dropna()\
         .drop_duplicates(subset=['date', 'code']).reset_index(drop=True)
     return modified_all_constituents
 
+
 def apply_universe_filter(df: pd.DataFrame,
                           universe: pd.DataFrame,
                           raw_cols,
                           universe_cols=['date', 'code']):
     """
 
     :param df:
```

## we_factor_quad/equity_quad/risk_control/index_risk_control.py

```diff
@@ -1,16 +1,16 @@
 # 核心考察的，是使用指定的因子组，来对指定对象(指定的指数)进行风险控制，考察的内容是3个点
 # 1. 能不能总体上控得住，
 # 2. 能不能一直控得住，
 # 3. 控制下的偏离不能太远
 import pandas as pd
 from we_factor_quad.equity_quad.factor_quad_equity import FactorQuadEQ
 from typing import Union, List, Dict
-from we_factor_quad.test_settings import StocksOutputReport
-from we_factor_quad.test_settings import settings
+from we_factor_quad.factor_quad_settings import StocksOutputReport
+from we_factor_quad.factor_quad_settings import settings
 import we_factor_quad.data_api as data_api
 from we_factor_quad.equity_quad.risk_control.stock_risk_control import RiskDecomposition, CompareReports
 
 
 class CompareReportsPortfolio(CompareReports):
     """
     基于 portfolio 的风险控制报告的生成，继续参照 CompareReports 的报告控制方法
```

## we_factor_quad/equity_quad/risk_control/stock_risk_control.py

```diff
@@ -6,16 +6,16 @@
 import numpy as np
 import pandas as pd
 from we_report.data_type import report_data
 import matplotlib.pyplot as plt
 from copy import deepcopy
 from we_factor_quad.equity_quad.factor_quad_equity import FactorQuadEQ
 from typing import Union, List, Dict
-from we_factor_quad.test_settings import StocksOutputReport
-from we_factor_quad.test_settings import settings
+from we_factor_quad.factor_quad_settings import StocksOutputReport
+from we_factor_quad.factor_quad_settings import settings
 
 
 class RiskDecomposition:
     """基于已经分解到因子体系上的相关数据，实现风险的分解以及可视化
     这个 class 为什么有存在的必要？不能直接用 FactorQuad 吗？
     不能，因为这个类可以在保持原始数据的基础上，针对特定的股票对象进行分析，而 FactorQuad 是针对所有股票的一个简单数据结构
     所以，这个 class，是基于 FactorQuad，做的进一步的分解、分析、可视化等
@@ -272,14 +272,35 @@
         stock_risk_control_w_lst = RiskControlStrategy(total_var_list=self.total_var_list, px_close=self.px_close,
                                                        stock_code=stock_code,
                                                        target_vol=target_vol).stock_risk_control()
         stock_risk_performance_lst = RiskControlStrategy(total_var_list=self.total_var_list, px_close=self.px_close,
                                                          stock_code=stock_code,
                                                          target_vol=target_vol).get_risk_control_performance()
         return stock_risk_control_w_lst, stock_risk_performance_lst
+    def write_sql(self, df):
+        import pymysql
+
+        # 数据库连接信息
+        df=df.reset_index()
+        df = df.rename(
+            columns={'index': 'trade_date', '0Close': 'close', '1msg_Vol': 'msg_Vol', '2msg_iVol': 'msg_iVol',
+                     '3Forward_3M_Vol': 'forward_3m', '4msg_iVol_pct': 'msg_iVol_pct'})
+        from sqlalchemy import create_engine
+        from urllib.parse import quote_plus as urlquote
+
+        from sqlalchemy.orm import sessionmaker
+        engine = create_engine(f"mysql+pymysql://root:{urlquote('dev-project@mysql.')}@172.16.127.213:3306/supersetdb")
+
+        # session = sessionmaker(engine)()
+
+        data = df
+        data.to_sql('StockRiskMonthly', engine, if_exists='append', chunksize=100000, index=None)
+        print('存入成功！')
+
+        pass
 
     def get_reports(self, report_contents: Union[str, List[str]] = "full", output_file: str = 'stock_risk_report.xlsx'):
         """
         输出报告
         :param report_contents: 报告类型，full为完整报告，除了full外，还可以选择sys_idio, factor_vol, rmv_vov, single_stock
         :param output_file: 输出文件地址
         :return:
@@ -322,14 +343,27 @@
             st_name_dic = dict(zip(self.stocks, self.stock_names))
             df_dic = self.get_stock_report()
             for st in df_dic.keys():
                 df_dic[st].index = df_dic[st].index.astype('str')
                 mypage_st = report_data.PageData(text='stock_vol', tables=[
                     pd.concat([round(df_dic[st].iloc[:, 0], 2), df_dic[st].iloc[:, 1:]], axis=1).reset_index()])
                 page_dic[st_name_dic[st]] = mypage_st
+
+        if "all_stock_vol" in report_contents or is_full:
+            assert self.stocks is not None and self.stock_names is not None, "请提供股票代码和股票名称"
+            st_name_dic = dict(zip(self.stocks, self.stock_names))
+            df_dic = self.get_all_stock_report()
+            lst = []
+            for k, v in df_dic.items():
+                v['code'] = k
+                lst.append(v)
+
+            sql_df = pd.concat(lst)
+            # self.write_sql(sql_df)
+
         if "portfolio" in report_contents or is_full:
             assert self.stock_portfolio is not None, "请提供投资组合及权重"
             protfolio_data = self.get_portfolio_report()
             protfolio_data.index = protfolio_data.index.astype('str')
             page_data = report_data.PageData(tables=[protfolio_data.reset_index()])
             page_dic["投资组合"] = page_data
         # 将数据写入excel
@@ -460,14 +494,43 @@
                     'BM').last()
             df = pd.DataFrame(stock_risk_dic).asfreq('BM', method='pad')  # .truncate(before=start) # 就不要截断了
             df.index = pd.to_datetime(df.index.astype('str'))
             df = df[df.columns.sort_values()]
             df_dic[stock] = df
         return df_dic
 
+    def get_all_stock_report(self) -> Dict:
+        """
+        # total_var_list, idio_var_list, px_close, name_list, stocks
+        输入close、return、stock_vol返回 df_dic,提供所有个股风控报告
+        """
+        rolling_vol = (np.log(self.px_close).diff(5).replace(0.0, np.nan)) \
+                          .rolling(window=63, min_periods=21).std().shift(-63) * np.sqrt(52)
+        stocks = set(self.risk_decomp[0].factor_quad.psi_ts['code'])
+        full_df_dic = {}
+        for stock in stocks:
+            try:
+                stock_risk_dic = {'0Close': self.px_close[stock].resample('BM').last(),
+                                  '3Forward 3M Vol': rolling_vol[stock].resample('BM').last(), }
+                for i in range(len(self.decomp_names)):
+                    stock_risk_dic[f'1{self.decomp_names[i]} Vol'] = np.sqrt(self.total_var_list[i])[stock].resample(
+                        'BM').last()
+                    stock_risk_dic[f'2{self.decomp_names[i]} iVol'] = np.sqrt(self.idio_var_list[i])[stock].resample(
+                        'BM').last()
+                    stock_risk_dic[f'4{self.decomp_names[i]}_iVol_pct'] = (np.sqrt(self.idio_var_list[i])[stock] / \
+                                                                           np.sqrt(self.total_var_list[i])[
+                                                                               stock]).resample('BM').last()
+                df = pd.DataFrame(stock_risk_dic)
+                df.index = pd.to_datetime(df.index.astype('str'))
+                df = df[df.columns.sort_values()]
+                full_df_dic[stock] = df
+            except Exception as e:
+                print('stcok ' + stock + ' haven`t ipo')
+        return full_df_dic
+
     def get_portfolio_report(self) -> Dict:
         """
         # total_var_list, idio_var_list, px_close, name_list, stocks
         输入close、return、stock_vol返回 df_dic,提供个股风控报告
         """
         protfolio_w, risk_managed_performance = self._get_portfolio_risk_control_result(target_vol=0.1)
         for i in range(len(protfolio_w)):
```

## we_factor_quad/equity_quad/risk_control/stock_risk_control_daily.py

```diff
@@ -6,16 +6,16 @@
 import numpy as np
 import pandas as pd
 from we_report.data_type import report_data
 import matplotlib.pyplot as plt
 from copy import deepcopy
 from we_factor_quad.equity_quad.factor_quad_equity import FactorQuadEQ
 from typing import Union, List, Dict
-from we_factor_quad.test_settings import StocksOutputReport
-from we_factor_quad.test_settings import settings
+from we_factor_quad.factor_quad_settings import StocksOutputReport
+from we_factor_quad.factor_quad_settings import settings
 
 
 class RiskDecomposition:
     """基于已经分解到因子体系上的相关数据，实现风险的分解以及可视化
     这个 class 为什么有存在的必要？不能直接用 FactorQuad 吗？
     不能，因为这个类可以在保持原始数据的基础上，针对特定的股票对象进行分析，而 FactorQuad 是针对所有股票的一个简单数据结构
     所以，这个 class，是基于 FactorQuad，做的进一步的分解、分析、可视化等
@@ -281,23 +281,45 @@
                                                        stock_code=stock_code,
                                                        target_vol=target_vol).stock_risk_control()
         stock_risk_performance_lst = RiskControlStrategy(total_var_list=self.total_var_list, px_close=self.px_close,
                                                          stock_code=stock_code,
                                                          target_vol=target_vol).get_risk_control_performance()
         return stock_risk_control_w_lst, stock_risk_performance_lst
 
+    def write_sql(self, df):
+        import pymysql
+
+        # 数据库连接信息
+        df = df.reset_index()
+        df = df.rename(
+            columns={'index': 'trade_date', '0Close': 'close', '1msg_Vol': 'msg_Vol', '2msg_iVol': 'msg_iVol',
+                     '3Forward_3M_Vol': 'forward_3m', '4msg_iVol_pct': 'msg_iVol_pct'})
+        from sqlalchemy import create_engine
+        from urllib.parse import quote_plus as urlquote
+
+        from sqlalchemy.orm import sessionmaker
+        engine = create_engine(f"mysql+pymysql://root:{urlquote('dev-project@mysql.')}@172.16.127.213:3306/supersetdb")
+
+        # session = sessionmaker(engine)()
+
+        data = df
+        data.to_sql('StockRisk', engine, if_exists='append', chunksize=100000, index=None)
+        print('存入成功！')
+
+        pass
+
     def get_reports(self, report_contents: str = "full", output_file: str = 'stock_risk_report.xlsx'):
         """
         输出报告
         :param report_contents: 报告类型，full为完整报告，除了full外，还可以选择sys_idio, factor_vol, rmv_vov, single_stock
         :param output_file: 输出文件地址
         :return:
         """
         full_contents = ["full", "sys_idio", "factor_vol", "volatility", "rmv_vov", "stock_vol",
-                         "portfolio", "pure_portfolio"]  # 能够处理的所有功能
+                         "portfolio", "pure_portfolio", "all_stock_vol"]  # 能够处理的所有功能
         if isinstance(report_contents, str):
             report_contents = [report_contents]  # 先全部转为list
         assert set(report_contents).issubset(set(full_contents)), f"report_contents contains sth not in full_contents"
         if "full" in report_contents:
             is_full = True
         else:
             is_full = False
@@ -330,14 +352,25 @@
             st_name_dic = dict(zip(self.stocks, self.stock_names))
             df_dic = self.get_stock_report()
             for st in df_dic.keys():
                 df_dic[st].index = df_dic[st].index.astype('str')
                 mypage_st = report_data.PageData(text='stock_vol', tables=[
                     pd.concat([round(df_dic[st].iloc[:, 0], 2), df_dic[st].iloc[:, 1:]], axis=1).reset_index()])
                 page_dic[st_name_dic[st]] = mypage_st
+        if "all_stock_vol" in report_contents or is_full:
+            assert self.stocks is not None and self.stock_names is not None, "请提供股票代码和股票名称"
+            st_name_dic = dict(zip(self.stocks, self.stock_names))
+            df_dic = self.get_all_stock_report()
+            lst = []
+            for k, v in df_dic.items():
+                v['code'] = k
+                lst.append(v)
+
+            sql_df = pd.concat(lst)
+            # self.write_sql(sql_df)
         if "portfolio" in report_contents or is_full:
             assert self.stock_portfolio is not None, "请提供投资组合及权重"
             protfolio_data = self.get_portfolio_report()
             protfolio_data.index = protfolio_data.index.astype('str')
             page_data = report_data.PageData(tables=[protfolio_data.reset_index()])
             page_dic["投资组合"] = page_data
         if "pure_portfolio" in report_contents or is_full:
@@ -476,15 +509,14 @@
                 # stock_risk_dic[f'5{self.decomp_names[i]}_Wgt'] = stock_w[i]
                 #
                 # stock_risk_dic[f'6{self.decomp_names[i]}_Pfm'] = risk_managed_performance[i]
                 # stock_risk_dic[f'7{self.decomp_names[i]}_M_Ret'] = ((stock_w[i]*self.px_close[stock]).pct_change(5)+1).cumprod()
                 # stock_risk_dic[f'8{self.decomp_names[i]}_F_Ret'] = (self.px_close[stock].pct_change()+1).cumprod()
                 # stock_risk_dic[f'9{self.decomp_names[i]}_C_Ret'] = (stock_w[i].mean()*(self.px_close[stock].pct_change())+1).cumprod()
 
-
             df = pd.DataFrame(stock_risk_dic)
             df.index = pd.to_datetime(df.index.astype('str'))
             df = df[df.columns.sort_values()]
             df_dic[stock] = df
         # for stock in self.stocks:
         #     stock_risk_dic = {'0Close': self.px_close[stock].resample('BM').last(),
         #                       '3Forward 3M Vol': rolling_vol[stock].resample('BM').last(), }
@@ -500,14 +532,41 @@
         #             'BM').last()
         #     df = pd.DataFrame(stock_risk_dic).asfreq('BM', method='pad')  # .truncate(before=start) # 就不要截断了
         #     df.index = pd.to_datetime(df.index.astype('str'))
         #     df = df[df.columns.sort_values()]
         #     df_dic[stock] = df
         return df_dic
 
+    def get_all_stock_report(self) -> Dict:
+        """
+        # total_var_list, idio_var_list, px_close, name_list, stocks
+        输入close、return、stock_vol返回 df_dic,提供所有个股风控报告
+        """
+        rolling_vol = (np.log(self.px_close).diff(5).replace(0.0, np.nan)) \
+                          .rolling(window=63, min_periods=21).std().shift(-63) * np.sqrt(52)
+        stocks = set(self.risk_decomp[0].factor_quad.psi_ts['code'])
+        full_df_dic = {}
+        for stock in stocks:
+            try:
+
+                stock_risk_dic = {'0Close': self.px_close[stock],
+                                  '3Forward_3M_Vol': rolling_vol[stock]}
+                for i in range(len(self.decomp_names)):
+                    stock_risk_dic[f'1{self.decomp_names[i]}_Vol'] = np.sqrt(self.total_var_list[i])[stock]
+                    stock_risk_dic[f'2{self.decomp_names[i]}_iVol'] = np.sqrt(self.idio_var_list[i])[stock]
+                    stock_risk_dic[f'4{self.decomp_names[i]}_iVol_pct'] = np.sqrt(self.idio_var_list[i])[stock] / \
+                                                                          np.sqrt(self.total_var_list[i])[stock]
+                df = pd.DataFrame(stock_risk_dic)
+                df.index = pd.to_datetime(df.index.astype('str'))
+                df = df[df.columns.sort_values()]
+                full_df_dic[stock] = df
+            except:
+                print('stcok ' + stock + ' haven`t ipo')
+        return full_df_dic
+
     def get_portfolio_report(self) -> pd.DataFrame:
         """
         # total_var_list, idio_var_list, px_close, name_list, stocks
         输入close、return、stock_vol返回 df_dic,提供个股风控报告
         """
         protfolio_w, risk_managed_performance = self._get_portfolio_risk_control_result(target_vol=0.1)
         for i in range(len(protfolio_w)):
@@ -533,14 +592,53 @@
         调整报告数据输出格式
         """
         df.index = df.index.astype('str')
         df = df.reset_index()
         return df
 
 
+def get_risk_report(report_output_path=None):
+    """
+    提供给客户，风控报告输出
+    """
+    model_list = StocksOutputReport.compare_model  # 目前的数值为 ['we']
+    start = StocksOutputReport.start
+    end = StocksOutputReport.end
+    risk_decomp_list = []  # 先开一个空的list，用来存储所有的结果
+    for model in model_list:  # 生成 decompose 对象
+        myquad = FactorQuadEQ.create_factor_quad(factor_system=eval(f'StocksOutputReport.{model}_factor_case_name'),
+                                                 start_date=StocksOutputReport.start,
+                                                 end_date=StocksOutputReport.end,
+                                                 from_src=StocksOutputReport.from_local,
+                                                 local_path=settings.seadrive_local_path)
+        myquad.capped_psi_adjustment()
+        from we_factor_quad.data_api import get_px_close
+        # 基本测试信息的导入
+        # 客户购买wiserdata数据api或使用自己数据获取px_close，通过data_api获取数据
+        px_close = get_px_close(start, end)
+        # 确保px_close数据格式类型正确
+        assert (px_close.dtypes == float).all(), 'get_px_close获取到的数据包含非float类型的列，请检查该函数返回结果'
+        mydecomp = RiskDecomposition(factor_quad=myquad, stock_ret_df=px_close)  # 在这里就应该指定和选择了
+        risk_decomp_list.append(mydecomp)
+
+    stocks = list(StocksOutputReport.report_stock_codes)
+    stock_portfolio = StocksOutputReport.risk_control_portfolio
+    stock_names = list(StocksOutputReport.report_stock_names)
+
+    px_close = get_px_close(start, end)
+    if report_output_path is None:
+        report_output_path = StocksOutputReport.report_path
+    my_compare_report = CompareReports(decomp_names=model_list, risk_decomp=risk_decomp_list, px_close=px_close,
+                                       stocks=stocks, stock_names=stock_names, stock_portfolio=stock_portfolio)
+    # 由这个report来负责生成仅需要因子数据的各种报告
+    import os
+    my_compare_report.get_reports(report_contents="stock_vol",
+                                  output_file=os.path.join(report_output_path, "stock_risk_report.xlsx"))
+
+
 # ----------------------
 # 各种测试样例
 def test_RiskControl():
     """
     测试风控报告输出
     """
 
@@ -555,15 +653,15 @@
         # 提取所有quad by quad_name, 这是为了测试对象准备样例数据
         risk_decomp_list = []  # 先开一个空的list，用来存储所有的结果
         for model in model_list:  # 生成 decompose 对象
             myquad = FactorQuadEQ.create_factor_quad(factor_system=eval(f'StocksOutputReport.{model}_factor_case_name'),
                                                      start_date=StocksOutputReport.start,
                                                      end_date=StocksOutputReport.end,
                                                      from_src=StocksOutputReport.from_local,
-                                                     local_path=local_path)
+                                                     local_path=settings.seadrive_local_path)
             myquad.capped_psi_adjustment()
             from we_factor_quad.data_api import get_px_close
 
             # 基本测试信息的导入
             # 客户购买wiserdata数据api或使用自己数据获取px_close，通过data_api获取数据
             start = StocksOutputReport.start
             end = StocksOutputReport.end
@@ -583,31 +681,33 @@
         px_close = get_px_close(start, end)
         report_path = StocksOutputReport.report_path
         my_compare_report = CompareReports(decomp_names=model_list, risk_decomp=risk_decomp_list, px_close=px_close,
                                            stocks=stocks, stock_names=stock_names, stock_portfolio=stock_portfolio)
         # 由这个report来负责生成仅需要因子数据的各种报告
         import os
         my_compare_report.get_reports(report_contents="stock_vol",
-                                      output_file=os.path.join(report_path, "stock_risk_report5.xlsx"))
-        # my_compare_report.get_reports(report_contents="sys_idio",
-        #                               output_file=os.path.join(report_path, "stock_risk_report1.xlsx"))
-        # my_compare_report.get_reports(report_contents="factor_vol",
-        #                               output_file=os.path.join(report_path, "stock_risk_report2.xlsx"))
-        # my_compare_report.get_reports(report_contents="volatility",
-        #                               output_file=os.path.join(report_path, "stock_risk_report3.xlsx"))
-        # my_compare_report.get_reports(report_contents="rmv_vov",
-        #                               output_file=os.path.join(report_path, "stock_risk_report4.xlsx"))
-        # my_compare_report.get_reports(report_contents=["rmv_vov", "stock_vol"],
-        #                               output_file=os.path.join(report_path, "stock_risk_report6.xlsx"))
-        # my_compare_report.get_reports(report_contents="pure_portfolio",
-        #                               output_file=os.path.join(report_path, "portfolio_risk_report.xlsx"))
-        # my_compare_report.get_reports(report_contents="portfolio",
-        #                               output_file=os.path.join(report_path, "full_portfolio_risk_report.xlsx"))
-        # my_compare_report.get_reports(report_contents="full",
-        #                               output_file=os.path.join(report_path, "stock_risk_report.xlsx"))
+                                      output_file=os.path.join(report_path, "stock_risk_report.xlsx"))
+        my_compare_report.get_reports(report_contents="all_stock_vol",
+                                      output_file=os.path.join(report_path, "all_stock_report.xlsx"))
+        my_compare_report.get_reports(report_contents="sys_idio",
+                                      output_file=os.path.join(report_path, "stock_risk_report1.xlsx"))
+        my_compare_report.get_reports(report_contents="factor_vol",
+                                      output_file=os.path.join(report_path, "stock_risk_report2.xlsx"))
+        my_compare_report.get_reports(report_contents="volatility",
+                                      output_file=os.path.join(report_path, "stock_risk_report3.xlsx"))
+        my_compare_report.get_reports(report_contents="rmv_vov",
+                                      output_file=os.path.join(report_path, "stock_risk_report4.xlsx"))
+        my_compare_report.get_reports(report_contents=["rmv_vov", "stock_vol"],
+                                      output_file=os.path.join(report_path, "stock_risk_report6.xlsx"))
+        my_compare_report.get_reports(report_contents="pure_portfolio",
+                                      output_file=os.path.join(report_path, "portfolio_risk_report.xlsx"))
+        my_compare_report.get_reports(report_contents="portfolio",
+                                      output_file=os.path.join(report_path, "full_portfolio_risk_report.xlsx"))
+        my_compare_report.get_reports(report_contents="full",
+                                      output_file=os.path.join(report_path, "full_stock_risk_report.xlsx"))
 
     def test_output_on_one_quad():
         # 只有一个quad 的报告生成
         pass
 
     def test_on_some_stocks_multiple_quads():
         # 多个quad，多个指定的股票的报告生成
@@ -678,9 +778,10 @@
 
     # --------------------
     # 正常情况的测试
     test_get_simple_report(model_list=model_list)  # 多个quad，所有股票，都有数据
 
 
 if __name__ == '__main__':
-    test_RiskControl()
-    test_pure_RiskControl()
+    # test_RiskControl()
+    get_risk_report()
+    # test_pure_RiskControl()
```

## Comparing `we_factor_quad/test_settings.py` & `we_factor_quad/factor_quad_settings.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,24 +1,25 @@
 import pandas as pd
+import os
 
 
 class settings:
     # 这部分参数，用于生成报告
-    # 报告统计时间区间
-    report_start_date = '20210701'
-    report_end_date = '20210711'
+    # 因子四元组时间区间
+    start_date = '20200701'
+    end_date = '20210710'
     # 四元组数据来源，local是读本地pkl文件，remote为从wiserdata下载数据
     quad_from_local = 1
-    # seadrive_local_path = r"D:\zhouly\群组资料库"
-    seadrive_local_path = r'C:\Users\Administrator\seadrive_root\yangyn\群组资料库'
-    # seadrive_local_path = r'C:\Users\Administrator\seadrive_root\trial\case_HF25_SRAM'
+    # seadrive_local_path = r"D:\seadrive_cache_folder\zhouly\群组资料库"
+    seadrive_local_path = r'C:\Users\Administrator\seadrive_root\gorilla\共享资料库'
+    # seadrive_local_path = r'C:\Users\Administrator\Seafile'
     # seadrive_local_path = "D:/seadrive_files/xiazeyu/Shared with groups/"
     # we因子模型与要对比的barra模型 case名
-    msg_factor_case_name = 'HF25_SRAM_DAILY_TRIAL'
-    # msg_factor_case_name = 'HF25_SRAM'
+    # msg_factor_case_name = 'HF25_SRAM_DAILY'
+    msg_factor_case_name = 'HF25_SRAM_DAILY_Tsinghua_Internal_Usage'
     cufm_factor_case_name = '202211_PRE_BARRA'
     # we模型与barra模型风格因子名
     msg_factors_name = ['beta', 'ceg', 'dtop', 'etop', 'gpm', 'log_bp', 'log_markcap', 'log_st_mean', 'log_std', 'mbs',
                         'reversal_short', 'roe', 'rstr', 'tagr']
     cufm_factors_name = ['Beta', 'Book-to-Price', 'Dividend Yield', 'Earnings Quality', 'Earnings Variability',
                          'Earnings Yield', 'Growth', 'Investment Quality', 'Leverage', 'Liquidity',
                          'Long-Term Reversal',
@@ -33,20 +34,19 @@
     # report_stock_names = ['605020.SH', '300834.SZ', '301068.SZ', '万科', '工商银行', '獐子岛', '复星医药', '赣锋锂业', '茅台', '康美药业',
     #                       '乐视']
     report_stock_codes = ['000002.SZ','601398.SH', '002069.SZ','600196.SH','002460.SZ', '600519.SH']
     report_stock_names = ['万科','工商银行', '獐子岛','复星医药','赣锋锂业', '茅台']
     # 传入dataframe表示投资组合权重随时间变化
     risk_control_portfolio = pd.DataFrame({'000001.SZ': [0.2, 0.3], '000002.SZ': [0.8, 0.7]},
                                           index=pd.to_datetime(['2012-01-01', '2023-02-01']))
-    import os
     report_path = os.getcwd()
 
     # Factor Summary report
     factor_summary_start_date = '20210701'
-    factor_summary_end_date = '20210711'
+    factor_summary_end_date = '20230101'
     factor_model = 'model_202209'
     factor_group = 'volatility'
 
     factor_group_start_date = '20220601'
     factor_group_end_date = '20221031'
 
     compare_model = ['msg']
@@ -57,16 +57,16 @@
         'ind427': '000905.SH',
         'ind377': '000016.SH',
         'I06011': '000852.SH'
     }
 
 
 class StocksOutputReport:
-    start = settings.report_start_date
-    end = settings.report_end_date
+    start = settings.start_date
+    end = settings.end_date
     from_local = settings.quad_from_local
     msg_factor_case_name = settings.msg_factor_case_name
     cufm_factor_case_name = settings.cufm_factor_case_name
     msg_factors_name = settings.msg_factors_name
     cufm_factors_name = settings.cufm_factors_name
     report_stock_codes = list(settings.report_stock_codes)
     report_stock_names = list(settings.report_stock_names)
@@ -87,11 +87,11 @@
     weight_file = settings.index_weight_file
 
 
 class FmpUniverseConfig:
     """
     设定所有可用的universe，由多个指数叠加
     """
-    universe_config = {'default_universe': ("ind422", "I06011", "I00275"),  # 沪深三百，中证500 + 中证 1000
+    universe_config = {'default_universe': ("ind422", "I06011", "I00275"),  # 沪深300，中证500 + 中证 1000
                        'alternative_universe': ("ind422",),
                        'all_universe': ("ind249", "I02551", "55000008", "I00127",)
                        }
```

## Comparing `we_factor_quad-0.0.4.1.dist-info/METADATA` & `we_factor_quad-0.5.0.dist-info/METADATA`

 * *Files 18% similar despite different names*

```diff
@@ -1,31 +1,34 @@
 Metadata-Version: 2.1
 Name: we-factor-quad
-Version: 0.0.4.1
+Version: 0.5.0
 Summary: Factor Quad, a data structure for factor analysis
 Home-page: http://192.168.1.7:10600/xiazeyu/we_factor_quad.git
 Author: Xia Zeyu
 Author-email: xiazeyu@wealthengine.cn
 License: UNKNOWN
 Platform: UNKNOWN
 Classifier: Programming Language :: Python :: 3
 Classifier: License :: OSI Approved :: MIT License
 Classifier: Operating System :: OS Independent
 Description-Content-Type: text/markdown
 Requires-Dist: numpy
-Requires-Dist: pandas
+Requires-Dist: pandas (<2.0.0)
 Requires-Dist: arrow
 Requires-Dist: sqlalchemy
 Requires-Dist: scikit-learn
 Requires-Dist: scipy
+Requires-Dist: pyarrow
 Requires-Dist: statsmodels
 Requires-Dist: six
 Requires-Dist: sshtunnel
 Requires-Dist: openpyxl
 Requires-Dist: numba
 Requires-Dist: pymysql
-Requires-Dist: we-report (>0.0.1.8)
+Requires-Dist: tqdm
+Requires-Dist: prettytable
+Requires-Dist: we-report (>0.1.8)
 
 # we_factor_quad
 
 因子分析的标准化数据结构，所有的因子框架都必须要嵌入这个结构
```

## Comparing `we_factor_quad-0.0.4.1.dist-info/RECORD` & `we_factor_quad-0.5.0.dist-info/RECORD`

 * *Files 8% similar despite different names*

```diff
@@ -1,36 +1,35 @@
 we_factor_quad/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 we_factor_quad/client_local.py,sha256=Bbx2lUHle3Onc9jjm4ZGLkZ4iGUq3g895KaULHQbJ0k,4823
-we_factor_quad/data_api.py,sha256=Kt4XFW7HVloyTDiqzOCtIcIOdPOjlTT68t0K-qpNT8Y,22716
-we_factor_quad/factor_quad.py,sha256=3xhEU8SI0bxG1YDVI25GHzX0FiSzFm9XNzeP-TeJwRA,34389
-we_factor_quad/test_settings.py,sha256=GqsqRwg9TDRbEX2w6dZ7oY7US2IDiCLW98i0SZ0nRgM,4446
-we_factor_quad/user_data_api.py,sha256=PDsECE33G9XjksDc-b9cvp-rYIb_TtWmezmxzLaonAQ,15078
+we_factor_quad/data_api.py,sha256=RmOmbLYkE5YPDv0E-6ySA9oB98flWkLqtnPTHqLlEgo,28110
+we_factor_quad/factor_quad.py,sha256=NB8k2cIu2l9-nr-5dkkKGHnx8VTj2eD5wk78gGMHxJQ,37731
+we_factor_quad/factor_quad_settings.py,sha256=Mfhr_XsCvsiRGU-XNVR5lge3e_FasMXR26PYp06jfyc,4434
 we_factor_quad/utils.py,sha256=sBKjvK18jCrxUWDE_na6lvMroScZj7dDc0GV8GBUMZ4,1073
+we_factor_quad/workshop.py,sha256=hyawzmEOoQ2OnME32DXQh4TQ_o2IuzvtUtaV5cHOKKk,2001
 we_factor_quad/commodity_quad/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 we_factor_quad/commodity_quad/factor_quad_commodity.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 we_factor_quad/commodity_quad/factor_portfolio/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 we_factor_quad/commodity_quad/risk_control/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 we_factor_quad/equity_quad/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-we_factor_quad/equity_quad/factor_quad_equity.py,sha256=03FdwPsT--8nMZQ52YO6FkTMMbVtgcLqGXsBt8ALfCE,12037
-we_factor_quad/equity_quad/fix_missing_psi.py,sha256=YuWuxixOu7hY18w5e0xnFpcZg1H7qHRacFFBwys-tTE,8212
+we_factor_quad/equity_quad/daily_data_update_preprocessing.py,sha256=QWNzo2qcyA5BuQcfdxCzGIAuhotIyMLvHS1ZsgsLHe8,8966
+we_factor_quad/equity_quad/factor_quad_equity.py,sha256=rbnu-5Cmqk5vUOgXnaodNNd5iwVVtBs3ngyBU632-5M,13976
+we_factor_quad/equity_quad/fix_missing_psi.py,sha256=wAPbMeeWN4ncrNECcFl7-SW_FSVOWK2Io34CGzF6v-I,8217
 we_factor_quad/equity_quad/solve_colinear.py,sha256=ca3NdGfry_8TMA6SkNdEncduFI-WLNxSjUuV_D5DeYM,2726
 we_factor_quad/equity_quad/factor_portfolio/__init__.py,sha256=3jZk1Nh2ob9GG1oGA28Be3ltdJY4oFQxvkkV3y3gNIk,207
-we_factor_quad/equity_quad/factor_portfolio/full_factor_mimicking_portfolio.py,sha256=y0SkJx3mBian7PhZng2LAZo7_7zqeFpLnm_u_Acss8Q,21636
-we_factor_quad/equity_quad/factor_portfolio/universe_helper.py,sha256=-DxO5uBDxtQ0WDpFHxskHIZHwWv83CyBD-2Qe8Wnwdw,2574
+we_factor_quad/equity_quad/factor_portfolio/full_factor_mimicking_portfolio.py,sha256=sa8iVQ1GmrZ56bq5cGEQyQzGKCjkV0sMAX0UbpQM0o4,22115
+we_factor_quad/equity_quad/factor_portfolio/universe_helper.py,sha256=sZp4cM5mVD7V_5uEnCDhxVcDSPz1Z2-93XY89ompnhE,2576
 we_factor_quad/equity_quad/risk_control/__init__.py,sha256=oNCU7oXHWPdQEvBM31jhwpaKzrqNNN5sy_aOR7TfHsQ,302
-we_factor_quad/equity_quad/risk_control/index_risk_control.py,sha256=yCE7mqewo2R2QwHfF4_Mab_NKQulLmkVvs3Dl2zjICs,3526
+we_factor_quad/equity_quad/risk_control/index_risk_control.py,sha256=Ak0lIRZ9v06uTDNX4Pm80lQjvAeOiWIUUji0grFnPKQ,3540
 we_factor_quad/equity_quad/risk_control/portfolio_risk_control.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-we_factor_quad/equity_quad/risk_control/stock_risk_control.py,sha256=AUrtu72GFciIL3gP-tHU8nPz6ZYWpjfjLML6Wg3Q40o,28996
-we_factor_quad/equity_quad/risk_control/stock_risk_control_daily.py,sha256=bvushaJAvT0fEZpIcB7j4q97b4tqpwvh70Yx7ticodo,36473
+we_factor_quad/equity_quad/risk_control/stock_risk_control.py,sha256=RwNjMu1Ecg7KG_Y_jZd2jGGB3-TXjGQw9F8TsQOs0fc,32117
+we_factor_quad/equity_quad/risk_control/stock_risk_control_daily.py,sha256=GeztB6Osa2wtf5Te7V63zWV9vkZxqCWA_c_bHpIlqeE,41864
 we_factor_quad/factor_validation/__init__.py,sha256=VAcwuEyuiG6aL7jSRf0SHTZs6QuDtY1WadI1DfBcVWk,23
 we_factor_quad/factor_validation/report.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 we_factor_quad/fi_quad/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 we_factor_quad/fi_quad/factor_quand_ns.py,sha256=cTC_lYMVo7KzM8dtYpmddkROOoXcjGcxD3JT5lCqJdE,5389
 we_factor_quad/fi_quad/factor_portfolio/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 we_factor_quad/fi_quad/risk_control/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-we_factor_quad/wiserdata/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-we_factor_quad/wiserdata/client_local.py,sha256=Bbx2lUHle3Onc9jjm4ZGLkZ4iGUq3g895KaULHQbJ0k,4823
-we_factor_quad-0.0.4.1.dist-info/METADATA,sha256=5haWVMSq5ESlShEl6uTSNGpuezUzohoBSDxbkEmt0MI,883
-we_factor_quad-0.0.4.1.dist-info/WHEEL,sha256=ewwEueio1C2XeHTvT17n8dZUJgOvyCWCt0WVNLClP9o,92
-we_factor_quad-0.0.4.1.dist-info/top_level.txt,sha256=LHk0l2twnsApkDjjnTePxFDP1sAXScUcremfwfl7HT8,15
-we_factor_quad-0.0.4.1.dist-info/zip-safe,sha256=frcCV1k9oG9oKj3dpUqdJg1PxRT2RSN_XKdLCPjaYaY,2
-we_factor_quad-0.0.4.1.dist-info/RECORD,,
+we_factor_quad-0.5.0.dist-info/METADATA,sha256=9x4MnOiWk9fuUyO4AxU8KyM7r3C-gOXb23sYr6wy0RA,958
+we_factor_quad-0.5.0.dist-info/WHEEL,sha256=ewwEueio1C2XeHTvT17n8dZUJgOvyCWCt0WVNLClP9o,92
+we_factor_quad-0.5.0.dist-info/top_level.txt,sha256=LHk0l2twnsApkDjjnTePxFDP1sAXScUcremfwfl7HT8,15
+we_factor_quad-0.5.0.dist-info/zip-safe,sha256=frcCV1k9oG9oKj3dpUqdJg1PxRT2RSN_XKdLCPjaYaY,2
+we_factor_quad-0.5.0.dist-info/RECORD,,
```

