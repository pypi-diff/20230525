# Comparing `tmp/k1lib-1.3.9.2-py3-none-any.whl.zip` & `tmp/k1lib-1.3.9.3-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,8 +1,8 @@
-Zip file size: 2545979 bytes, number of entries: 84
+Zip file size: 2547757 bytes, number of entries: 84
 -rw-rw-r--  2.0 unx     1435 b- defN 23-Feb-08 00:13 k1lib/__init__.py
 -rw-rw-r--  2.0 unx    53798 b- defN 23-May-23 10:44 k1lib/_baseClasses.py
 -rw-rw-r--  2.0 unx    13494 b- defN 23-May-05 13:41 k1lib/_basics.py
 -rw-rw-r--  2.0 unx     4908 b- defN 23-May-08 18:53 k1lib/_context.py
 -rw-rw-r--  2.0 unx     2866 b- defN 22-Jul-20 04:30 k1lib/_higher.py
 -rw-rw-r--  2.0 unx      948 b- defN 22-Sep-21 23:54 k1lib/_k1a.py
 -rw-rw-r--  2.0 unx    11646 b- defN 23-Jan-14 15:37 k1lib/_learner.py
@@ -43,27 +43,27 @@
 -rw-rw-r--  2.0 unx     3465 b- defN 22-Nov-27 08:16 k1lib/callbacks/lossFunctions/shorts.py
 -rw-rw-r--  2.0 unx       45 b- defN 21-Aug-11 18:19 k1lib/callbacks/profilers/__init__.py
 -rw-rw-r--  2.0 unx     5054 b- defN 22-May-15 09:01 k1lib/callbacks/profilers/computation.py
 -rw-rw-r--  2.0 unx     2319 b- defN 22-May-15 08:59 k1lib/callbacks/profilers/io.py
 -rw-rw-r--  2.0 unx     4419 b- defN 22-May-15 09:00 k1lib/callbacks/profilers/memory.py
 -rw-rw-r--  2.0 unx     4215 b- defN 22-May-15 09:03 k1lib/callbacks/profilers/time.py
 -rw-rw-r--  2.0 unx      925 b- defN 22-Nov-16 09:22 k1lib/cli/__init__.py
--rw-rw-r--  2.0 unx    18925 b- defN 23-May-24 23:16 k1lib/cli/_applyCl.py
+-rw-rw-r--  2.0 unx    19106 b- defN 23-May-25 01:34 k1lib/cli/_applyCl.py
 -rw-rw-r--  2.0 unx     8308 b- defN 22-Nov-27 07:16 k1lib/cli/bio.py
 -rw-rw-r--  2.0 unx     4033 b- defN 23-Jan-25 02:02 k1lib/cli/cif.py
 -rw-rw-r--  2.0 unx    19321 b- defN 23-May-17 19:01 k1lib/cli/conv.py
--rw-rw-r--  2.0 unx    24071 b- defN 23-May-17 03:12 k1lib/cli/filt.py
+-rw-rw-r--  2.0 unx    28497 b- defN 23-May-25 15:35 k1lib/cli/filt.py
 -rw-rw-r--  2.0 unx     6672 b- defN 23-Jan-25 02:02 k1lib/cli/gb.py
 -rw-rw-r--  2.0 unx     6348 b- defN 23-Apr-05 15:10 k1lib/cli/grep.py
--rw-rw-r--  2.0 unx    18351 b- defN 23-May-12 23:10 k1lib/cli/init.py
--rw-rw-r--  2.0 unx    32027 b- defN 23-May-24 23:12 k1lib/cli/inp.py
+-rw-rw-r--  2.0 unx    19260 b- defN 23-May-25 12:08 k1lib/cli/init.py
+-rw-rw-r--  2.0 unx    32645 b- defN 23-May-25 00:37 k1lib/cli/inp.py
 -rw-rw-r--  2.0 unx      623 b- defN 22-Jun-22 10:43 k1lib/cli/kcsv.py
 -rw-rw-r--  2.0 unx     4819 b- defN 22-Aug-11 20:44 k1lib/cli/kxml.py
 -rw-rw-r--  2.0 unx     1915 b- defN 21-Nov-12 16:48 k1lib/cli/mgi.py
--rw-rw-r--  2.0 unx    64305 b- defN 23-May-24 23:18 k1lib/cli/modifier.py
+-rw-rw-r--  2.0 unx    64661 b- defN 23-May-25 01:34 k1lib/cli/modifier.py
 -rw-rw-r--  2.0 unx      694 b- defN 22-Nov-27 07:17 k1lib/cli/mol.py
 -rw-rw-r--  2.0 unx     4038 b- defN 23-May-09 15:53 k1lib/cli/nb.py
 -rw-rw-r--  2.0 unx     3530 b- defN 22-Aug-16 15:08 k1lib/cli/optimizations.py
 -rw-rw-r--  2.0 unx    12118 b- defN 23-May-22 17:09 k1lib/cli/output.py
 -rw-rw-r--  2.0 unx     2394 b- defN 23-Jan-25 02:03 k1lib/cli/sam.py
 -rw-rw-r--  2.0 unx    49390 b- defN 23-May-19 19:21 k1lib/cli/structural.py
 -rw-rw-r--  2.0 unx    10399 b- defN 22-Aug-05 01:15 k1lib/cli/trace.py
@@ -71,16 +71,16 @@
 -rw-rw-r--  2.0 unx    21101 b- defN 23-May-17 16:57 k1lib/cli/utils.py
 -rw-rw-r--  2.0 unx       20 b- defN 23-Jan-19 22:00 k1lib/k1ui/__init__.py
 -rw-rw-r--  2.0 unx    61803 b- defN 23-Feb-10 12:10 k1lib/k1ui/main.py
 -rw-rw-r--  2.0 unx       20 b- defN 22-Sep-16 01:12 k1lib/serve/__init__.py
 -rw-rw-r--  2.0 unx    10361 b- defN 23-May-05 16:49 k1lib/serve/main.py
 -rw-rw-r--  2.0 unx      153 b- defN 23-May-05 16:00 k1lib/serve/suffix-dash.py
 -rw-rw-r--  2.0 unx      642 b- defN 23-Feb-13 19:00 k1lib/serve/suffix.py
--rw-rw-r--  2.0 unx  2453826 b- defN 23-Jan-19 22:50 k1lib-1.3.9.2.data/data/k1lib/k1ui/256.model.state_dict.pth
--rw-rw-r--  2.0 unx   304735 b- defN 23-Jan-17 19:16 k1lib-1.3.9.2.data/data/k1lib/k1ui/mouseKey.pth
--rw-rw-r--  2.0 unx    20544 b- defN 23-Mar-19 11:14 k1lib-1.3.9.2.data/data/k1lib/serve/main.html
--rw-rw-r--  2.0 unx     1049 b- defN 23-May-24 23:19 k1lib-1.3.9.2.dist-info/LICENSE
--rw-rw-r--  2.0 unx     3890 b- defN 23-May-24 23:19 k1lib-1.3.9.2.dist-info/METADATA
--rw-rw-r--  2.0 unx       92 b- defN 23-May-24 23:19 k1lib-1.3.9.2.dist-info/WHEEL
--rw-rw-r--  2.0 unx        6 b- defN 23-May-24 23:19 k1lib-1.3.9.2.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     6704 b- defN 23-May-24 23:19 k1lib-1.3.9.2.dist-info/RECORD
-84 files, 3524732 bytes uncompressed, 2535639 bytes compressed:  28.1%
+-rw-rw-r--  2.0 unx  2453826 b- defN 23-Jan-19 22:50 k1lib-1.3.9.3.data/data/k1lib/k1ui/256.model.state_dict.pth
+-rw-rw-r--  2.0 unx   304735 b- defN 23-Jan-17 19:16 k1lib-1.3.9.3.data/data/k1lib/k1ui/mouseKey.pth
+-rw-rw-r--  2.0 unx    20544 b- defN 23-Mar-19 11:14 k1lib-1.3.9.3.data/data/k1lib/serve/main.html
+-rw-rw-r--  2.0 unx     1049 b- defN 23-May-25 15:36 k1lib-1.3.9.3.dist-info/LICENSE
+-rw-rw-r--  2.0 unx     3890 b- defN 23-May-25 15:36 k1lib-1.3.9.3.dist-info/METADATA
+-rw-rw-r--  2.0 unx       92 b- defN 23-May-25 15:36 k1lib-1.3.9.3.dist-info/WHEEL
+-rw-rw-r--  2.0 unx        6 b- defN 23-May-25 15:36 k1lib-1.3.9.3.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     6704 b- defN 23-May-25 15:36 k1lib-1.3.9.3.dist-info/RECORD
+84 files, 3531222 bytes uncompressed, 2537417 bytes compressed:  28.1%
```

## zipnote {}

```diff
@@ -222,32 +222,32 @@
 
 Filename: k1lib/serve/suffix-dash.py
 Comment: 
 
 Filename: k1lib/serve/suffix.py
 Comment: 
 
-Filename: k1lib-1.3.9.2.data/data/k1lib/k1ui/256.model.state_dict.pth
+Filename: k1lib-1.3.9.3.data/data/k1lib/k1ui/256.model.state_dict.pth
 Comment: 
 
-Filename: k1lib-1.3.9.2.data/data/k1lib/k1ui/mouseKey.pth
+Filename: k1lib-1.3.9.3.data/data/k1lib/k1ui/mouseKey.pth
 Comment: 
 
-Filename: k1lib-1.3.9.2.data/data/k1lib/serve/main.html
+Filename: k1lib-1.3.9.3.data/data/k1lib/serve/main.html
 Comment: 
 
-Filename: k1lib-1.3.9.2.dist-info/LICENSE
+Filename: k1lib-1.3.9.3.dist-info/LICENSE
 Comment: 
 
-Filename: k1lib-1.3.9.2.dist-info/METADATA
+Filename: k1lib-1.3.9.3.dist-info/METADATA
 Comment: 
 
-Filename: k1lib-1.3.9.2.dist-info/WHEEL
+Filename: k1lib-1.3.9.3.dist-info/WHEEL
 Comment: 
 
-Filename: k1lib-1.3.9.2.dist-info/top_level.txt
+Filename: k1lib-1.3.9.3.dist-info/top_level.txt
 Comment: 
 
-Filename: k1lib-1.3.9.2.dist-info/RECORD
+Filename: k1lib-1.3.9.3.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## k1lib/cli/_applyCl.py

```diff
@@ -28,14 +28,15 @@
 the requested operation might be unbalanced on the cluster (some
 nodes finish before others, wasting computational time). Would you
 like to perform a load test now? Should take 1-2 minutes. Y/n: """)
         if ans.lower()[0] == "y": loadTest()
     data = None | applyCl.aS(lambda: [cpuHash(), os.cpu_count()]) | apply(wrapList(), 0) | joinStreams().all() | deref() # List[nodeId, cpu hash, #cpus]
     obj = {**data | cut(1, 2) | apply("1", 1) | toDict(), **load_loadTest()}
     return data | lookup(obj, 1) | ~apply(lambda nodeId,mul,cpu: [nodeId, mul*cpu | (aS(round) if rounded else iden())]) | toDict()
+def balancedNodeIds(): a = loadTestGuard().items(); return a | ~apply(lambda x,y: [x]*y) | joinStreams() | randomize(None) | repeatFrom() | randomize(a | cut(1) | toSum() | op()*2)
 from k1lib.imports import *
 getFolderSize = ls() | filt(os.path.isdir).split() | apply(lambda x: x | (tryout(0) | getFolderSize)) + apply(os.path.getsize) | toSum().all() | toSum() | deref()
 getFilesInFolder = aS(os.walk) | cut(0, 2) | ungroup() | join(os.sep).all()
 def getIr(base): return None | applyCl.aS(lambda: ls(base) | iden() & apply(lambda x: x | (tryout(0) | (aS(os.path.getsize) if os.path.isfile(x) else getFolderSize))) | transpose() | deref()) | ungroup(False) | insertIdColumn(True) | deref()
 def normalize(d):
     d = d | deref(); s = d | cut(1) | toSum()
     return d | apply(op()/s, 1) | sort(0, False) | deref()
```

## k1lib/cli/filt.py

```diff
@@ -502,42 +502,129 @@
     torch.tensor(range(5)) | mask([True, True, False, True, False])"""
         super().__init__(); self.mask = mask
     def __ror__(self, it):
         if isinstance(it, settings.arrayTypes):
             return it[list(self.mask)]
         return (e for e, m in zip(it, self.mask) if m)
 class tryout(BaseCli):
-    end = object()
-    def __init__(self, result=None):
-        """Wraps every cli operation after this in a try-catch block, returning ``result``.
-This can be a little finicky. Example::
+    def __init__(self, result=None, retries=0):
+        """Wraps every cli operation after this in a try-catch block, returning ``result``
+if the operation fails. Example::
 
     # returns 9
     3 | (tryout("failed") | op()**2)
     # returns "failed", instead of raising an exception
     "3" | (tryout("failed") | op()**2)
     # returns "unsupported operand type(s) for ** or pow(): 'str' and 'int'"
-    "3" | (tryout(Exception) | op()**2)
+    "3" | (tryout(str) | op()**2)
 
 By default, this ``tryout()`` object will gobble up all clis behind it and wrap
 them inside a try-catch block. This might be undesirable, so you can stop it early::
 
     # returns "failed"
     3 | (tryout("failed") | op()**2 | aS(str) | op()**2)
     # raises an exception, because it does not errors after `tryout.end`
-    3 | (tryout("failed") | op()**2 | tryout.end | aS(str) | op()**2)
+    3 | (tryout("failed") | op()**2) | aS(str) | op()**2
+
+In the first example, :class:`tryout` will catch any errors happening within ``op()``,
+``aS(str)`` or the second ``op()**2``. In the second example, :class:`tryout` will only
+catch errors happening within the first ``op()**2``.
+
+.. admonition:: Array mode
+
+    The above works well for atomic operations and not looping operations. Let's
+    say we have this function::
+
+        counter = 0
+        def f(x):
+            global counter
+            if x > 5:
+                counter += 1
+                if counter < 3: raise Exception(f"random error: {x}")
+            return x**2
+    
+    This code will throw an error if x is greater than 5 for the first and second
+    time (but runs smoothly after that. It's a really nasty function I know).
+    Capturing like this will work::
+    
+        counter = 0 # line below returns [0, 1, 4, 9, 16, 25, 'failed', 'failed', 64, 81]
+        range(10) | apply(tryout("failed") | aS(f)) | deref()
+    
+    But capturing like this won't work::
+    
+        counter = 0 # line below throws an exception
+        range(10) | (tryout("failed") | apply(f)) | deref()
+    
+    The reason being, :class:`tryout` will only capture errors when the data is passed
+    into ``apply(f)``, and won't capture it later on. However, when data is passed to
+    ``apply(f)``, it hasn't executed anything yet (remember these things are lazily
+    executed). So the exception actually happens when you're trying to ``deref()`` it,
+    which lies outside of :class:`tryout`'s reach. You can just put a tilde in front
+    to tell it to capture errors for individual elements in the iterator::
+    
+        counter = 0 # line belows returns [0, 1, 4, 9, 16, 25, 'failed', 'failed', 64, 81]
+        range(10) | (~tryout("failed") | apply(f)) | deref()
+
+    This mode has a weird quirk that requires that there has to be a 1-to-1 correspondence
+    between the input and output for the block of code that it wraps around. Meaning this is okay::
+    
+        def g(x):
+            global counter
+            if 40 > x[0] >= 30:
+                counter += 1
+                if counter < 5: raise Exception("random error")
+            return x
+        counter = 0 # returns 50, corrects errors as if it's not even there!
+        range(50) | (~tryout(None, 6) | batched(10, True) | apply(g) | joinStreams()) | deref() | shape(0)
+    
+    This is okay because going in, there're 50 elements, and it's expected that 50 elements
+    goes out of :class:`tryout`. The input can be of infinite length, but there has to be a
+    1-to-1 relationship between the input and output. While this is not okay::
+
+        counter = 0 # returns 75, data structure corrupted
+        range(50) | (~tryout(None, 6) | batched(10, True) | apply(g) | joinStreams() | batched(2, True)) | joinStreams() | deref() | shape(0)
+
+    It's not okay because it's expected that 25 pairs of elements goes out of :class:`tryout`
+
+.. admonition:: Retrying
+
+    There's also the ``retries`` parameter, which specifies how many times should this
+    class retry the operation until actually returning the predefined result::
+    
+        counter = 0 # line below returns [0, 1, 4, 9, 16, 25, None, None, 64, 81]
+        range(10) | (~tryout(retries=0) | apply(f)) | deref()
+        counter = 0 # line below returns [0, 1, 4, 9, 16, 25, None, 49, 64, 81]
+        range(10) | (~tryout(retries=1) | apply(f)) | deref()
+        counter = 0 # line below returns [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]
+        range(10) | (~tryout(retries=2) | apply(f)) | deref()
 
 :param result: result to return if there is an exception. If passed in the class
-    `Exception`, then will return the exception's string instead"""
-        self.clis = []; self.ser = None; self.result = result; self.absorbing = True
-    def __or__(self, it):
-        if it is tryout.end: self.absorbing = False; return self
-        if isinstance(it, BaseCli):
-            if self.absorbing: self.clis.append(it); self.ser = None; return self
-            else: return super().__or__(it)
-        else: raise Exception("Can't pipe tryout() to a non-cli tool");
+    `str`, then will return the exception's string instead
+:param retries: how many time to retry before giving up?"""
+        super().__init__(capture=True); self.result = result; self.inverted = False; self.retries = retries
     def __ror__(self, it):
-        if self.ser is None:
-            self.ser = cli.serial(*self.clis)
-            if len(self.clis) == 0: raise Exception("tryout() currently does not wrap around any other cli. You may need to change `data | tryout() | cli1() | cli2()` into `data | (tryout() | cli1() | cli2())`")
-        try: return it | self.ser
-        except Exception as e: return str(e) if self.result is Exception else self.result
+        retries = self.retries
+        if len(self.capturedClis) == 0: raise Exception("tryout() currently does not wrap around any other cli. You may need to change `data | tryout() | cli1() | cli2()` into `data | (tryout() | cli1() | cli2())`")
+        if not self.inverted:
+            while True:
+                try: return it | self.capturedSerial
+                except Exception as e:
+                    if retries <= 0: return str(e) if self.result is str else self.result
+                    retries -= 1
+        else:
+            def gen(it):
+                patience = retries; savedInputs = k1lib.Wrapper(deque())
+                def interceptIt(it):
+                    for e in it: savedInputs().append(e); yield e
+                it = iter(it); ogIt = it; it = interceptIt(it); outIt = it | self.capturedSerial
+                while True:
+                    try: e = next(outIt); yield e; savedInputs().popleft(); patience = retries
+                    except StopIteration: break
+                    except Exception as e:
+                        if patience <= 0: savedInputs().popleft(); patience = retries
+                        else: patience -= 1
+                        # restart the loop
+                        it = interceptIt([list(savedInputs()), ogIt] | cli.joinStreams())
+                        savedInputs.value = deque(); outIt = it | self.capturedSerial
+                        if patience == retries: yield str(e) if self.result is str else self.result
+            return gen(it)
+    def __invert__(self): self.inverted = not self.inverted; return self
```

## k1lib/cli/init.py

```diff
@@ -73,15 +73,15 @@
     """A base class for all the cli stuff. You can definitely create new cli tools that
 have the same feel without extending from this class, but advanced stream operations
 (like ``+``, ``&``, ``.all()``, ``|``) won't work.
 
 At the moment, you don't have to call super().__init__() and super().__ror__(),
 as __init__'s only job right now is to solidify any :class:`~k1lib.cli.modifier.op`
 passed to it, and __ror__ does nothing."""
-    def __init__(self, fs:list=[]):
+    def __init__(self, fs:list=[], capture=False):
         """Not expected to be instantiated by the end user.
 
 **fs param**
 
 Expected to use it like this::
 
     class A(BaseCli):
@@ -90,19 +90,34 @@
 
 Where ``f`` is some (potentially exotic) function. This will replace f with a "normal"
 function that's executable. See source code of :class:`~k1lib.cli.filt.filt` for an
 example of why this is useful. Currently, it will:
 
 - Replace with last recorded ``4 in op()``, if ``f`` is :data:`True`, because Python does
   not allow returning complex objects from __contains__ method
-- Solidifies every :class:`~k1lib.cli.modifier.op`."""
+- Solidifies every :class:`~k1lib.cli.modifier.op`.
+
+:param capture: whether to capture all clis to the right of it and make it accessible under capturedClis and capturedSerial properties"""
         if isinstance(fs, tuple): raise AttributeError("`fs` should not be a tuple. Use a list instead, so that new functions can be returned")
         _k1_init_l = []
         for _k1_init_f in fs: cli.op.solidify(_k1_init_f); _k1_init_l.append(_k1_init_f)
         fs.clear(); fs.extend(_k1_init_l);
+        self.capture = capture; self._capturedClis = []; self._capturedSerial = None
+    @property
+    def capturedClis(self):
+        if isinstance(self._capturedClis, list):
+            ans = []
+            for e in self._capturedClis: ans.append(cli.op.solidify(e))
+            self._capturedClis = tuple(ans)
+        return self._capturedClis
+    @property
+    def capturedSerial(self):
+        if not self.capture: return None
+        if self._capturedSerial is None: self._capturedSerial = serial(*self.capturedClis)
+        return self._capturedSerial
     def hint(self, _hint:"cli.typehint.tBase"):
         """Specifies output type hint."""
         self._hint = _hint; return self
     @property
     def hasHint(self): return "_hint" in self.__dict__ and self._hint is not None
     def _typehint(self, inp:"cli.typehint.tBase"=None) -> "cli.typehint.tBase": return cli.typehint.tAny() if "_hint" not in self.__dict__ else self._hint
     def __and__(self, cli:"BaseCli") -> "oneToMany":
@@ -137,21 +152,23 @@
     torch.randn(3, 4, 5) | toMean().all(2) | shape()
 
 :param n: how many times should I chain ``.all()``?"""
         if n < 0: raise AttributeError(f"Does not make sense for `n` to be \"{n}\"")
         s = self
         for i in range(n): s = cli.apply(s)
         return s
-    def __or__(self, cli) -> "serial":
+    def __or__(self, cli) -> "serial": # cli is guaranteed (by typical usage, not law) that it's a BaseCli
         """Joins clis end-to-end.
 Example::
 
     c = apply(op() ** 2) | deref()
     # returns [0, 1, 4, 9, 16]
     range(5) | c"""
+        if not hasattr(self, "capture"): self.capture = False
+        if self.capture: self._capturedClis.append(cli); return self
         if isinstance(self, serial): return self._copy()._after(cli)
         if isinstance(cli, serial): return cli._copy()._before(self)
         return serial(self, cli)
     def __ror__(self, it): return NotImplemented
     def f(self) -> Table[Table[int]]:
         """Creates a normal function :math:`f(x)` which is equivalent to
 ``x | self``."""
```

## k1lib/cli/inp.py

```diff
@@ -8,53 +8,55 @@
 from contextlib import contextmanager
 requests = k1lib.dep("requests")
 try: import minio; hasMinio = True
 except: hasMinio = False
 __all__ = ["cat", "splitSeek", "refineSeek", "wget", "ls", "cmd", "walk", "requireCli", "urlPath"]
 settings = k1lib.settings.cli
 class NoPartialContent(Exception): pass
-def getChunk(url:str, sB:int, eB:int, timeout:float) -> bytes: # start and end inclusive!!! Normally for everything else, it's start inclusive and end exclusive
-    for i in range(10):
-        try: res = requests.get(url, headers={"Range": f"bytes={sB}-{eB}"}, timeout=timeout)
+def getChunk(url:str, sB:int, eB:int, timeout:float, retries:int) -> bytes: # start inclusive, end exclusive
+    for i in range(retries):
+        try: res = requests.get(url, headers={"Range": f"bytes={sB}-{eB-1}"}, timeout=timeout)
         except Exception as e:
-            if i == 9: raise Exception(f"Can't get file chunk")
+            if i >= retries-1: raise Exception(f"Can't get file chunk")
             continue
         if res.status_code != 206: raise NoPartialContent(f"Server doesn't allow partial downloads at this particular url. Status code: {res.status_code}")
         return res.content
-def getChunks(url:str, sB:int, eB:int, chunkSize=None, chunkTimeout:float=10) -> List[bytes]:
+def getChunks(url:str, sB:int, eB:int, chunkSize=None, chunkTimeout:float=10, chunkRetries:int=10) -> List[bytes]:
     """Grabs bytes from sB to eB in chunks"""
     chunkSize = chunkSize or settings.cli.cat.chunkSize
-    return range(sB, eB+1) | cli.batched(chunkSize, True) | cli.apply(lambda r: getChunk(url, r.start, r.stop-1, chunkTimeout))
+    return range(sB, eB+1) | cli.batched(chunkSize, True) | cli.apply(lambda r: getChunk(url, r.start, r.stop-1, chunkTimeout, chunkRetries))
 catSettings = k1lib.Settings().add("chunkSize", 100000, "file reading chunk size for binary+chunk mode. Decrease it to avoid wasting memory and increase it to avoid disk latency")
 catSettings.add("every", k1lib.Settings().add("text", 1000, "for text mode, will print every n lines").add("binary", 10, "for binary mode, will print every n 100000-byte blocks"), "profiler print frequency")
 settings.add("cat", catSettings, "inp.cat() settings")
 
 rfS = k1lib.Settings()
 settings.add("RemoteFile", rfS, "inp.RemoteFile() settings, used in cat(), splitSeek() and the like")
 rfS.add("memoryLimit", 100_000_000, "if the internal cache exceeds this limit (in bytes), and randomAccess is False, then old downloaded chunks will be deleted")
-def noPartial(url):
-    try: return len(getChunk(url, 0, 10, 10)) != 11
+rfS.add("timeout", 10, "seconds before terminating the remote request and retrying")
+rfS.add("retries", 10, "how many times to retry sending the request before giving up")
+def noPartial(url, *args):
+    try: return len(getChunk(url, 0, 10, *args)) != 10
     except NoPartialContent: return True
 class RemoteFile:
-    def __init__(self, url, randomAccess=True, blockSize=None, noPartialConfirm=False):
+    def __init__(self, url, randomAccess=True, blockSize=None, noPartialConfirm=False, timeout:float=None, retries:int=None):
         """
 :param url: url of the remote file
 :param randomAccess: is random accessing parts of the file expected? If
     True, then keeps all of the reads in ram internally, else free them
     as soon as possible
 :param blockSize: all reads will fetch roughly this amount of bytes"""
         self.url = url; self.randomAccess = randomAccess; self.blockSize = blockSize or settings.cat.chunkSize
         self.noPartialConfirm = noPartialConfirm; self.size = None; self.domain = k1lib.Domain()
         self.seekPos = 0; self.reads = deque() # List[sB, eB, content]
-        self._totalReadSize = 0; self.noPartial = noPartial(url)
-        self._confirmMsgShown = False
-    def _fetch(self, sB:int, eB:int): # fetches from start to end byte and dumps to internal memory. Inclusive start byte, exclusive end byte
+        self._confirmMsgShown = False; self.timeout = timeout or rfS.timeout; self.retries = retries or rfS.retries
+        self._totalReadSize = 0; self.noPartial = noPartial(url, self.timeout, self.retries)
+    def _fetch(self, sB:int, eB:int): # fetches from start to end byte and dumps to internal memory. Inclusive start and end byte
         if not self.noPartial:
             eB = max(eB, min(sB+self.blockSize, len(self)))
-            chunk = getChunk(self.url, sB, eB, 10)
+            chunk = getChunk(self.url, sB, eB, self.timeout, self.retries)
         else:
             if self.noPartialConfirm and not self._confirmMsgShown:
                 ans = input(f"""Remote file '{self.url}' don't support partial downloads.
 Therefore the entire file will be loaded into RAM, which
 could be undesireable. Do you want to continue? Y/n: """)
                 self._confirmMsgShown = True
                 if ans.lower()[0] != "y": self.reads.append([0, 0, b""]); return
@@ -65,15 +67,15 @@
             sB, eB, chunk = self.reads.popleft()
             self._totalReadSize -= len(chunk)
     def _ensureRange(self, sB, eB): # makes sure that all ranges between sB and eB are available
         missingDomain = k1lib.Domain([max(sB-30, 0), min(eB+30, len(self))]) & -self.domain
         for sB, eB in missingDomain.ranges: self._fetch(sB, eB)
     def _readChunks(self, sB, eB): # read from sB to eB, but in chunks, to be optimized. inclusive sB, exclusive eB
         sB = max(min(sB, len(self)), 0); eB = max(min(eB, len(self)), 0); self._ensureRange(sB, eB)
-        return self.reads | cli.filt(~cli.aS(lambda s,e,chunk: e>=sB and s<=eB)) | cli.sort() | ~cli.apply(lambda s,e,chunk: chunk[max(sB-s, 0):len(chunk)+min(eB-e, 0)])
+        return self.reads | cli.filt(~cli.aS(lambda s,e,chunk: e>=sB and s<=eB)) | cli.sort() | ~cli.apply(lambda s,e,chunk: chunk[max(sB-s, 0):len(chunk)+min(eB-e, 0)]) | cli.filt(len)
     def seek(self, cookie, whence=0):
         if whence == 0: self.seekPos = cookie
         elif whence == 1: self.seekPos += cookie
         elif whence == 2: self.seekPos = len(self) + cookie
         else: raise Exception("Invalid whence")
         return self.seekPos
     def read(self, size, join=True):
@@ -86,27 +88,27 @@
                 for chunk in self.read(self.blockSize, False):
                     if len(chunk) == 0: raise SyntaxError()
                     ans.append(chunk)
                     if b"\n" in chunk: raise SyntaxError()
         except SyntaxError: pass
         ans = b"".join(ans)
         try: n = ans.index(b"\n")
-        except ValueError: n = len(ans)
+        except ValueError: n = len(ans) # only happens at end of file
         self.seekPos = seekPos + n+1; return (ans[:n+1] if newLine else ans[:n]).decode()
     def readlines(self, newLine=True):
         while True:
-            chunk = self.readline(newLine); yield chunk
-            if self.seekPos > len(self): break
+            yield self.readline(newLine)
+            if self.seekPos >= len(self): break
     def tell(self): return self.seekPos
     def _getSize(self):
         if self.noPartial: self._fetch(0, 10); return self.reads[0][1]
-        for i in range(10):
-            try: return requests.head(self.url, timeout=3).headers.items() | cli.apply(cli.op().lower(), 0) | cli.toDict() | cli.op()["content-length"].ab_int()
+        for i in range(self.retries):
+            try: return requests.head(self.url, timeout=self.timeout).headers.items() | cli.apply(cli.op().lower(), 0) | cli.toDict() | cli.op()["content-length"].ab_int()
             except Exception as e:
-                if i == 9: raise Exception(f"Can't get size of remote file: {e}")
+                if i >= self.retries: raise Exception(f"Can't get size of remote file: {e}")
     def __len__(self):
         if self.size is None: self.size = self._getSize()
         return self.size
     def __repr__(self): return f"<RemoteFile url={self.url} size={k1lib.fmt.size(len(self))}>"
 @contextmanager
 def openFile(fn, text, noPartialConfirm=False): # can be actual file or url
     if os.path.exists(fn):
@@ -197,22 +199,27 @@
     # returns ['3456', '8']
     cat("test/catTest.pth", sB=2, eB=8) | deref()
     
     settings.cat.context.chunkSize=3 # just for demonstration, don't do it normally
     # returns [b'123', b'456', b'\\n8']
     cat("test/catTest.pth", text=False, chunks=True, eB=8) | deref()
 
-You can also read from urls directly, like this::
+.. admonition:: Remote files
 
-    cat("https://k1lib.com/latest/") | deref()
+    You can also read from urls directly, like this::
 
-For remote files like this, there are extra settings at :data:`~k1lib.settings`.cli.RemoteFile.
-This will also read the file chunk by chunk if required. If the website doesn't support
-partial downloads, then all of it will be downloaded and stored into ram, which may not be
-desireable.
+        cat("https://k1lib.com/latest/") | deref()
+
+    For remote files like this, there are extra settings at :data:`~k1lib.settings`.cli.RemoteFile.
+    This will also read the file chunk by chunk if required. If the website doesn't support
+    partial downloads, then all of it will be downloaded and stored into ram, which may not be
+    desireable. The available settings are:
+    
+    - timeout: seconds before killing the existing request
+    - retries: try to resend the request for this much before giving up
 
 If you are working with large files and would like to read 1 file from multiple
 threads/processes, then you can use this cli in conjunction with :class:`splitSeek`.
 
 If you are dumping multiple pickled objects into a single file, you can read all
 of them using :meth:`cat.pickle`.
```

## k1lib/cli/modifier.py

```diff
@@ -866,14 +866,24 @@
 Make sure to only scan folders that you store data in, or else it'll take a long time to return.
 
 :param folder: the folder to scan through
 :param raw: whether to return raw data or display it out nicely"""
         from k1lib.cli._applyCl import diskScan4, diskScan5
         if raw: return diskScan4(folder)
         else: return diskScan5(folder)
+    @staticmethod
+    def balancedNodeIds():
+        """Returns a stream of node ids that's balanced based on cpu count/performance.
+Example::
+
+    # returns list of 10 node ids: ["abc...", "def...", "abc...", ...]
+    applyCl.balancedNodeIds() | head() | deref()
+"""
+        from k1lib.cli._applyCl import balancedNodeIds
+        return balancedNodeIds()
 thEmptySentinel = object()
 class applyTh(BaseCli):
     def __init__(self, f, prefetch:int=None, timeout:float=5, bs:int=1, **kwargs):
         """Kinda like the same as :class:`applyMp`, but executes ``f`` on multiple
 threads, instead of on multiple processes. Advantages:
 
 - Relatively low overhead for thread creation
```

## Comparing `k1lib-1.3.9.2.data/data/k1lib/k1ui/256.model.state_dict.pth` & `k1lib-1.3.9.3.data/data/k1lib/k1ui/256.model.state_dict.pth`

 * *Files identical despite different names*

## Comparing `k1lib-1.3.9.2.data/data/k1lib/k1ui/mouseKey.pth` & `k1lib-1.3.9.3.data/data/k1lib/k1ui/mouseKey.pth`

 * *Files identical despite different names*

## Comparing `k1lib-1.3.9.2.data/data/k1lib/serve/main.html` & `k1lib-1.3.9.3.data/data/k1lib/serve/main.html`

 * *Files identical despite different names*

## Comparing `k1lib-1.3.9.2.dist-info/LICENSE` & `k1lib-1.3.9.3.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `k1lib-1.3.9.2.dist-info/METADATA` & `k1lib-1.3.9.3.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: k1lib
-Version: 1.3.9.2
+Version: 1.3.9.3
 Summary: Some nice ML overhaul
 Home-page: https://k1lib.com
 Author: Quang Ho
 Author-email: 157239q@gmail.com
 License: MIT
 Requires-Python: >=3.7
 Description-Content-Type: text/markdown
```

## Comparing `k1lib-1.3.9.2.dist-info/RECORD` & `k1lib-1.3.9.3.dist-info/RECORD`

 * *Files 4% similar despite different names*

```diff
@@ -42,27 +42,27 @@
 k1lib/callbacks/lossFunctions/shorts.py,sha256=wXeUSgGDIdu_nsiAvn4pKs3fQrcO2FwpNXKcBCFvGzY,3465
 k1lib/callbacks/profilers/__init__.py,sha256=Gp5IvLRABYAg1J0ilTT2v72gfDbyTvUUHUEpvlSo1Lc,45
 k1lib/callbacks/profilers/computation.py,sha256=gPNsoioghh4PI5w8s2p8qYOrR7XObslqCLH5EkNOPSI,5054
 k1lib/callbacks/profilers/io.py,sha256=H8E0YzmLWRD9T2_RyDG2eXvbQQnJgzEnEyx8PqfQ4wY,2319
 k1lib/callbacks/profilers/memory.py,sha256=L0F5pc5LB0dtSnRot8ReR-amZn1uIXv0py0XmGS166U,4419
 k1lib/callbacks/profilers/time.py,sha256=R2-2ZooDwLQIeyonLp2Zz5E_uXzdy6mWUgw6uavQbpE,4215
 k1lib/cli/__init__.py,sha256=hF0ODhL20OSM9o1j68VhcIVflibgSpPuqeyYlsh8oow,925
-k1lib/cli/_applyCl.py,sha256=KaCVvwcZNGmUYJZD03w6wIUuv-ZlFq8emWUYMJb14CE,18925
+k1lib/cli/_applyCl.py,sha256=XBY1cLaAinaapC37_SXT0XKK3c974kSdIT9-I_Yy76w,19106
 k1lib/cli/bio.py,sha256=PhGvy-fDA-wrUzzEDpuRe4x-Kbylx0sNmoXCEZfE_FA,8308
 k1lib/cli/cif.py,sha256=77FX83m1FRYEeZkdXJ8MiVapqCSzZ-1xOQ8ZLeHfhf8,4033
 k1lib/cli/conv.py,sha256=KcwSs9mD54XA5BC7ajxPF_1CZsu54i6dH6DtEv_fbv0,19321
-k1lib/cli/filt.py,sha256=c-bueTrH_5KAgRTtNiK4t4jfCy6xu-d0rYEUVF9KKGA,24071
+k1lib/cli/filt.py,sha256=50P2-BXGm7qQZ6xr2TUU1CyaNU3h3AiC32p12L01FJo,28497
 k1lib/cli/gb.py,sha256=xxjuNYgWrrElRckon3gP0sj-dShYnKs3jmHAb1U0kVI,6672
 k1lib/cli/grep.py,sha256=Lu4PFOe2pkaqd-UfJe_HhHCUFTUifE6Bh96_k80sQDA,6348
-k1lib/cli/init.py,sha256=2FaWeRqZnb--XWV4Xpo0z4ANDdyWpNQlHKkALtOGHKQ,18351
-k1lib/cli/inp.py,sha256=FMpMQfnye0LV7woSfZIXA76NKG137JtskaxyeWNhDRw,32027
+k1lib/cli/init.py,sha256=-Nec097qUalPW1_d85dp5mgvGT_qUJoIaBF4Ro_dZOg,19260
+k1lib/cli/inp.py,sha256=LuM-RPkFIXB9MwDdlniDxlog_faeBSn_I8iPIoJKus8,32645
 k1lib/cli/kcsv.py,sha256=YGUVVLTZGGujokhxtj5MfjU9t1jRGqp23d58JK8lhq0,623
 k1lib/cli/kxml.py,sha256=YQGutvKNm0_xAi_NhCNtuGey7fx3zZSmSo33kS--54c,4819
 k1lib/cli/mgi.py,sha256=aLke90nG89tgWLPwyKmTj3kM8yJnIBCJSrPS1jT8mUk,1915
-k1lib/cli/modifier.py,sha256=cqXnZha1kH3PY3F8GJOXMYQxOPXXgt8flYubE8WdRxE,64305
+k1lib/cli/modifier.py,sha256=ZV7p_odSVPkiViSqJwjl-8PMg7D0awiSQcuZAiODar4,64661
 k1lib/cli/mol.py,sha256=wNFuCPXtdEcH4DRBbmYaLAWxtDzjN2MOKFX7ynJhaJs,694
 k1lib/cli/nb.py,sha256=LsNN7OFJ6KzAYKvZpm4fj9WRpsX6Srx6D_xpSTCV328,4038
 k1lib/cli/optimizations.py,sha256=iZ73DwLqZCxRm0sECVZ7A2nDxf5D4rsoSGzrKTgzGaI,3530
 k1lib/cli/output.py,sha256=sGk7Z_kiJ0A_wwRtlJZZgvfqvbl1K-XmNsGih0PlqeA,12118
 k1lib/cli/sam.py,sha256=_ersEPP2ue0Oa3AyftNjQu2PABpH4L7iFBbRJDOkeug,2394
 k1lib/cli/structural.py,sha256=Ugn0Fb-0n0ardjjAvlfsfhRehLeUAszjvkW1odv6ZDU,49390
 k1lib/cli/trace.py,sha256=nzZgOyXqFJYkQfbpR0lpX0Nnp0bQHXPjk8sDUBIe2hk,10399
@@ -70,15 +70,15 @@
 k1lib/cli/utils.py,sha256=XF-H1Ce5ssOw6Dp3htiosHce7xxTgxptrlUsMYxI7uE,21101
 k1lib/k1ui/__init__.py,sha256=8D5a8oKgqd6WA1RUkiKCn4l_PVemtyuckxQut0vDHXM,20
 k1lib/k1ui/main.py,sha256=PnmdOhkjYgRSZnDyGYNMYtQ5Nvcb1NhQ9yjfP_3QORI,61803
 k1lib/serve/__init__.py,sha256=8D5a8oKgqd6WA1RUkiKCn4l_PVemtyuckxQut0vDHXM,20
 k1lib/serve/main.py,sha256=Xh2SzgABfsBp2dRLUJRMftsG_We8ReVHYqXLi3ntMVA,10361
 k1lib/serve/suffix-dash.py,sha256=HMNJvB4d-PTHXDRDQTdYUKtzgirJ0LVnqqAkXxO0B4w,153
 k1lib/serve/suffix.py,sha256=UH3ITN6O2vzoha2f6v4bcQG3_Boav7VA7EC8wf8r9f8,642
-k1lib-1.3.9.2.data/data/k1lib/k1ui/256.model.state_dict.pth,sha256=Ga-UXlAJfUPNOZsvP_c1-1cfB2Hp_-oQ4ghdouX1d7g,2453826
-k1lib-1.3.9.2.data/data/k1lib/k1ui/mouseKey.pth,sha256=KULhK_gdK2Ppju9gQnv1zV2kf_A0K-vX2W7trY6DIg8,304735
-k1lib-1.3.9.2.data/data/k1lib/serve/main.html,sha256=gHFNqzE9JKb4eCwCJN-Du45jj75lDRED4Ico91T-b4g,20544
-k1lib-1.3.9.2.dist-info/LICENSE,sha256=psuy2wnTg9zacuCQ0dXfxS44iaa89aTgsNzHDzx4UGM,1049
-k1lib-1.3.9.2.dist-info/METADATA,sha256=PrMsEXRCToekfsW4OwAnHJ2Py5WGGiiAKsmUZppOSCA,3890
-k1lib-1.3.9.2.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-k1lib-1.3.9.2.dist-info/top_level.txt,sha256=xxWmqZzuThnLZn49Mse6A6j41-IVduPVnQW54imcOTA,6
-k1lib-1.3.9.2.dist-info/RECORD,,
+k1lib-1.3.9.3.data/data/k1lib/k1ui/256.model.state_dict.pth,sha256=Ga-UXlAJfUPNOZsvP_c1-1cfB2Hp_-oQ4ghdouX1d7g,2453826
+k1lib-1.3.9.3.data/data/k1lib/k1ui/mouseKey.pth,sha256=KULhK_gdK2Ppju9gQnv1zV2kf_A0K-vX2W7trY6DIg8,304735
+k1lib-1.3.9.3.data/data/k1lib/serve/main.html,sha256=gHFNqzE9JKb4eCwCJN-Du45jj75lDRED4Ico91T-b4g,20544
+k1lib-1.3.9.3.dist-info/LICENSE,sha256=psuy2wnTg9zacuCQ0dXfxS44iaa89aTgsNzHDzx4UGM,1049
+k1lib-1.3.9.3.dist-info/METADATA,sha256=vvdNPUjeno7i15nI6mALyB4Gtbt2bzkDTFu3uht4hZQ,3890
+k1lib-1.3.9.3.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+k1lib-1.3.9.3.dist-info/top_level.txt,sha256=xxWmqZzuThnLZn49Mse6A6j41-IVduPVnQW54imcOTA,6
+k1lib-1.3.9.3.dist-info/RECORD,,
```

