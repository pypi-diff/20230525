# Comparing `tmp/keras_aug-0.5.1-py3-none-any.whl.zip` & `tmp/keras_aug-0.5.2-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,135 +1,135 @@
-Zip file size: 180808 bytes, number of entries: 133
--rw-r--r--  2.0 unx      373 b- defN 23-May-15 14:23 keras_aug/__init__.py
--rw-r--r--  2.0 unx      174 b- defN 23-May-15 14:23 keras_aug/conftest.py
--rw-r--r--  2.0 unx      572 b- defN 23-May-15 14:23 keras_aug/core/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-15 14:23 keras_aug/core/factor_sampler/__init__.py
--rw-r--r--  2.0 unx      727 b- defN 23-May-15 14:23 keras_aug/core/factor_sampler/constant_factor_sampler.py
--rw-r--r--  2.0 unx      666 b- defN 23-May-15 14:23 keras_aug/core/factor_sampler/constant_factor_sampler_test.py
--rw-r--r--  2.0 unx      944 b- defN 23-May-15 14:23 keras_aug/core/factor_sampler/factor_sampler.py
--rw-r--r--  2.0 unx     1585 b- defN 23-May-15 14:23 keras_aug/core/factor_sampler/normal_factor_sampler.py
--rw-r--r--  2.0 unx      949 b- defN 23-May-15 14:23 keras_aug/core/factor_sampler/normal_factor_sampler_test.py
--rw-r--r--  2.0 unx     1666 b- defN 23-May-15 14:23 keras_aug/core/factor_sampler/signed_constant_factor_sampler.py
--rw-r--r--  2.0 unx      739 b- defN 23-May-15 14:23 keras_aug/core/factor_sampler/signed_constant_factor_sampler_test.py
--rw-r--r--  2.0 unx     2556 b- defN 23-May-15 14:23 keras_aug/core/factor_sampler/signed_normal_factor_sampler.py
--rw-r--r--  2.0 unx     1284 b- defN 23-May-15 14:23 keras_aug/core/factor_sampler/signed_normal_factor_sampler_test.py
--rw-r--r--  2.0 unx     1204 b- defN 23-May-15 14:23 keras_aug/core/factor_sampler/uniform_factor_sampler.py
--rw-r--r--  2.0 unx      778 b- defN 23-May-15 14:23 keras_aug/core/factor_sampler/uniform_factor_sampler_test.py
--rw-r--r--  2.0 unx     3539 b- defN 23-May-15 14:23 keras_aug/layers/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-15 14:23 keras_aug/layers/__internal__/__init__.py
--rw-r--r--  2.0 unx     2641 b- defN 23-May-15 14:23 keras_aug/layers/__internal__/base_layer.py
--rw-r--r--  2.0 unx     1260 b- defN 23-May-15 14:23 keras_aug/layers/__internal__/base_layer_test.py
--rw-r--r--  2.0 unx     7270 b- defN 23-May-15 14:23 keras_aug/layers/__internal__/config_test.py
--rw-r--r--  2.0 unx     8579 b- defN 23-May-15 14:23 keras_aug/layers/__internal__/graph_xla_mode_test.py
--rw-r--r--  2.0 unx     8756 b- defN 23-May-15 14:23 keras_aug/layers/__internal__/mixed_precision_test.py
--rw-r--r--  2.0 unx     8205 b- defN 23-May-15 14:23 keras_aug/layers/__internal__/output_common_test.py
--rw-r--r--  2.0 unx     8236 b- defN 23-May-15 14:23 keras_aug/layers/__internal__/with_ragged_image_test.py
--rw-r--r--  2.0 unx     2718 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/auto/__init__.py
--rw-r--r--  2.0 unx    12027 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/auto/aug_mix.py
--rw-r--r--  2.0 unx      815 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/auto/aug_mix_test.py
--rw-r--r--  2.0 unx    16866 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/auto/rand_augment.py
--rw-r--r--  2.0 unx      609 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/auto/rand_augment_test.py
--rw-r--r--  2.0 unx    13055 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/auto/trivial_augment_wide.py
--rw-r--r--  2.0 unx      368 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/auto/trivial_augment_wide_test.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/geometry/__init__.py
--rw-r--r--  2.0 unx    21644 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/geometry/random_affine.py
--rw-r--r--  2.0 unx    13608 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/geometry/random_affine_test.py
--rw-r--r--  2.0 unx    10957 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/geometry/random_crop.py
--rw-r--r--  2.0 unx    10794 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/geometry/random_crop_and_resize.py
--rw-r--r--  2.0 unx     7874 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/geometry/random_crop_and_resize_test.py
--rw-r--r--  2.0 unx     6189 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/geometry/random_crop_test.py
--rw-r--r--  2.0 unx     7403 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/geometry/random_flip.py
--rw-r--r--  2.0 unx     9717 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/geometry/random_flip_test.py
--rw-r--r--  2.0 unx     7721 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/geometry/random_resize.py
--rw-r--r--  2.0 unx     6596 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/geometry/random_resize_test.py
--rw-r--r--  2.0 unx     8303 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/geometry/random_rotate.py
--rw-r--r--  2.0 unx     5788 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/geometry/random_rotate_test.py
--rw-r--r--  2.0 unx    10026 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/geometry/random_zoom_and_crop.py
--rw-r--r--  2.0 unx     4844 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/geometry/random_zoom_and_crop_test.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/intensity/__init__.py
--rw-r--r--  2.0 unx     3356 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/intensity/channel_shuffle.py
--rw-r--r--  2.0 unx     1633 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/intensity/channel_shuffle_test.py
--rw-r--r--  2.0 unx     4167 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/intensity/random_blur.py
--rw-r--r--  2.0 unx     1010 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/intensity/random_blur_test.py
--rw-r--r--  2.0 unx     3481 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/intensity/random_channel_shift.py
--rw-r--r--  2.0 unx     1506 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/intensity/random_channel_shift_test.py
--rw-r--r--  2.0 unx     9563 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/intensity/random_clahe.py
--rw-r--r--  2.0 unx     3093 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/intensity/random_clahe_test.py
--rw-r--r--  2.0 unx     9411 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/intensity/random_color_jitter.py
--rw-r--r--  2.0 unx     5660 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/intensity/random_color_jitter_test.py
--rw-r--r--  2.0 unx     3430 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/intensity/random_gamma.py
--rw-r--r--  2.0 unx     1420 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/intensity/random_gamma_test.py
--rw-r--r--  2.0 unx     5256 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/intensity/random_gaussian_blur.py
--rw-r--r--  2.0 unx     2098 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/intensity/random_gaussian_blur_test.py
--rw-r--r--  2.0 unx     7785 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/intensity/random_hsv.py
--rw-r--r--  2.0 unx     5230 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/intensity/random_hsv_test.py
--rw-r--r--  2.0 unx     4503 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/intensity/random_jpeg_quality.py
--rw-r--r--  2.0 unx     1155 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/intensity/random_jpeg_quality_test.py
--rw-r--r--  2.0 unx     4388 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/intensity/random_posterize.py
--rw-r--r--  2.0 unx     2768 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/intensity/random_posterize_test.py
--rw-r--r--  2.0 unx     5116 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/intensity/random_sharpness.py
--rw-r--r--  2.0 unx     1366 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/intensity/random_sharpness_test.py
--rw-r--r--  2.0 unx     5125 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/intensity/random_solarize.py
--rw-r--r--  2.0 unx     2269 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/intensity/random_solarize_test.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/mix/__init__.py
--rw-r--r--  2.0 unx     6278 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/mix/cut_mix.py
--rw-r--r--  2.0 unx     3212 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/mix/cut_mix_test.py
--rw-r--r--  2.0 unx     5955 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/mix/mix_up.py
--rw-r--r--  2.0 unx     2947 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/mix/mix_up_test.py
--rw-r--r--  2.0 unx    16258 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/mix/mosaic.py
--rw-r--r--  2.0 unx     2297 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/mix/mosaic_test.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/regularization/__init__.py
--rw-r--r--  2.0 unx     3737 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/regularization/random_channel_dropout.py
--rw-r--r--  2.0 unx      706 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/regularization/random_channel_dropout_test.py
--rw-r--r--  2.0 unx     9425 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/regularization/random_cutout.py
--rw-r--r--  2.0 unx     3189 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/regularization/random_cutout_test.py
--rw-r--r--  2.0 unx     8126 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/regularization/random_erase.py
--rw-r--r--  2.0 unx     3236 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/regularization/random_erase_test.py
--rw-r--r--  2.0 unx    11490 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/regularization/random_grid_mask.py
--rw-r--r--  2.0 unx     2161 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/regularization/random_grid_mask_test.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/utility/__init__.py
--rw-r--r--  2.0 unx     6301 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/utility/random_apply.py
--rw-r--r--  2.0 unx     2792 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/utility/random_apply_test.py
--rw-r--r--  2.0 unx     6537 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/utility/random_choice.py
--rw-r--r--  2.0 unx     2732 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/utility/random_choice_test.py
--rw-r--r--  2.0 unx     3588 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/utility/repeated_augment.py
--rw-r--r--  2.0 unx     1106 b- defN 23-May-15 14:23 keras_aug/layers/augmentation/utility/repeated_augment_test.py
--rw-r--r--  2.0 unx       98 b- defN 23-May-15 14:23 keras_aug/layers/base/__init__.py
--rw-r--r--  2.0 unx    21658 b- defN 23-May-15 14:23 keras_aug/layers/base/vectorized_base_random_layer.py
--rw-r--r--  2.0 unx    21212 b- defN 23-May-15 14:23 keras_aug/layers/base/vectorized_base_random_layer_test.py
--rw-r--r--  2.0 unx      723 b- defN 23-May-15 14:23 keras_aug/layers/preprocessing/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-15 14:23 keras_aug/layers/preprocessing/geometry/__init__.py
--rw-r--r--  2.0 unx    10646 b- defN 23-May-15 14:23 keras_aug/layers/preprocessing/geometry/center_crop.py
--rw-r--r--  2.0 unx     6669 b- defN 23-May-15 14:23 keras_aug/layers/preprocessing/geometry/center_crop_test.py
--rw-r--r--  2.0 unx    10878 b- defN 23-May-15 14:23 keras_aug/layers/preprocessing/geometry/pad_if_needed.py
--rw-r--r--  2.0 unx     8071 b- defN 23-May-15 14:23 keras_aug/layers/preprocessing/geometry/pad_if_needed_test.py
--rw-r--r--  2.0 unx    17026 b- defN 23-May-15 14:23 keras_aug/layers/preprocessing/geometry/resize.py
--rw-r--r--  2.0 unx    20408 b- defN 23-May-15 14:23 keras_aug/layers/preprocessing/geometry/resize_test.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-15 14:23 keras_aug/layers/preprocessing/intensity/__init__.py
--rw-r--r--  2.0 unx     2878 b- defN 23-May-15 14:23 keras_aug/layers/preprocessing/intensity/auto_contrast.py
--rw-r--r--  2.0 unx     2698 b- defN 23-May-15 14:23 keras_aug/layers/preprocessing/intensity/auto_contrast_test.py
--rw-r--r--  2.0 unx     4513 b- defN 23-May-15 14:23 keras_aug/layers/preprocessing/intensity/equalize.py
--rw-r--r--  2.0 unx     1529 b- defN 23-May-15 14:23 keras_aug/layers/preprocessing/intensity/equalize_test.py
--rw-r--r--  2.0 unx     2376 b- defN 23-May-15 14:23 keras_aug/layers/preprocessing/intensity/grayscale.py
--rw-r--r--  2.0 unx     1224 b- defN 23-May-15 14:23 keras_aug/layers/preprocessing/intensity/grayscale_test.py
--rw-r--r--  2.0 unx     1023 b- defN 23-May-15 14:23 keras_aug/layers/preprocessing/intensity/identity.py
--rw-r--r--  2.0 unx     1391 b- defN 23-May-15 14:23 keras_aug/layers/preprocessing/intensity/identity_test.py
--rw-r--r--  2.0 unx     1653 b- defN 23-May-15 14:23 keras_aug/layers/preprocessing/intensity/invert.py
--rw-r--r--  2.0 unx      459 b- defN 23-May-15 14:23 keras_aug/layers/preprocessing/intensity/invert_test.py
--rw-r--r--  2.0 unx     2931 b- defN 23-May-15 14:23 keras_aug/layers/preprocessing/intensity/normalize.py
--rw-r--r--  2.0 unx     1483 b- defN 23-May-15 14:23 keras_aug/layers/preprocessing/intensity/normalize_test.py
--rw-r--r--  2.0 unx     1923 b- defN 23-May-15 14:23 keras_aug/layers/preprocessing/intensity/rescale.py
--rw-r--r--  2.0 unx     1365 b- defN 23-May-15 14:23 keras_aug/layers/preprocessing/intensity/rescale_test.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-15 14:23 keras_aug/utils/__init__.py
--rw-r--r--  2.0 unx    15362 b- defN 23-May-15 14:23 keras_aug/utils/augmentation.py
--rw-r--r--  2.0 unx     4990 b- defN 23-May-15 14:23 keras_aug/utils/augmentation_test.py
--rw-r--r--  2.0 unx     5197 b- defN 23-May-15 14:23 keras_aug/utils/bounding_box.py
--rw-r--r--  2.0 unx     3235 b- defN 23-May-15 14:23 keras_aug/utils/bounding_box_test.py
--rw-r--r--  2.0 unx      373 b- defN 23-May-15 14:23 keras_aug/utils/conditional_imports.py
--rw-r--r--  2.0 unx     4596 b- defN 23-May-15 14:23 keras_aug/utils/demo.py
--rw-r--r--  2.0 unx    11456 b- defN 23-May-15 14:24 keras_aug-0.5.1.dist-info/LICENSE
--rw-r--r--  2.0 unx     9858 b- defN 23-May-15 14:24 keras_aug-0.5.1.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-May-15 14:24 keras_aug-0.5.1.dist-info/WHEEL
--rw-r--r--  2.0 unx       10 b- defN 23-May-15 14:24 keras_aug-0.5.1.dist-info/top_level.txt
--rw-rw-r--  2.0 unx    14546 b- defN 23-May-15 14:24 keras_aug-0.5.1.dist-info/RECORD
-133 files, 652037 bytes uncompressed, 156566 bytes compressed:  76.0%
+Zip file size: 188763 bytes, number of entries: 133
+-rw-r--r--  2.0 unx      373 b- defN 23-May-25 15:37 keras_aug/__init__.py
+-rw-r--r--  2.0 unx      174 b- defN 23-May-25 15:37 keras_aug/conftest.py
+-rw-r--r--  2.0 unx      572 b- defN 23-May-25 15:37 keras_aug/core/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-25 15:37 keras_aug/core/factor_sampler/__init__.py
+-rw-r--r--  2.0 unx      727 b- defN 23-May-25 15:37 keras_aug/core/factor_sampler/constant_factor_sampler.py
+-rw-r--r--  2.0 unx      666 b- defN 23-May-25 15:37 keras_aug/core/factor_sampler/constant_factor_sampler_test.py
+-rw-r--r--  2.0 unx      944 b- defN 23-May-25 15:37 keras_aug/core/factor_sampler/factor_sampler.py
+-rw-r--r--  2.0 unx     1585 b- defN 23-May-25 15:37 keras_aug/core/factor_sampler/normal_factor_sampler.py
+-rw-r--r--  2.0 unx      949 b- defN 23-May-25 15:37 keras_aug/core/factor_sampler/normal_factor_sampler_test.py
+-rw-r--r--  2.0 unx     1666 b- defN 23-May-25 15:37 keras_aug/core/factor_sampler/signed_constant_factor_sampler.py
+-rw-r--r--  2.0 unx      739 b- defN 23-May-25 15:37 keras_aug/core/factor_sampler/signed_constant_factor_sampler_test.py
+-rw-r--r--  2.0 unx     2556 b- defN 23-May-25 15:37 keras_aug/core/factor_sampler/signed_normal_factor_sampler.py
+-rw-r--r--  2.0 unx     1284 b- defN 23-May-25 15:37 keras_aug/core/factor_sampler/signed_normal_factor_sampler_test.py
+-rw-r--r--  2.0 unx     1204 b- defN 23-May-25 15:37 keras_aug/core/factor_sampler/uniform_factor_sampler.py
+-rw-r--r--  2.0 unx      778 b- defN 23-May-25 15:37 keras_aug/core/factor_sampler/uniform_factor_sampler_test.py
+-rw-r--r--  2.0 unx     3641 b- defN 23-May-25 15:37 keras_aug/layers/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-25 15:37 keras_aug/layers/__internal__/__init__.py
+-rw-r--r--  2.0 unx     2641 b- defN 23-May-25 15:37 keras_aug/layers/__internal__/base_layer.py
+-rw-r--r--  2.0 unx     1260 b- defN 23-May-25 15:37 keras_aug/layers/__internal__/base_layer_test.py
+-rw-r--r--  2.0 unx     7763 b- defN 23-May-25 15:37 keras_aug/layers/__internal__/config_test.py
+-rw-r--r--  2.0 unx    10731 b- defN 23-May-25 15:37 keras_aug/layers/__internal__/graph_xla_mode_test.py
+-rw-r--r--  2.0 unx    10954 b- defN 23-May-25 15:37 keras_aug/layers/__internal__/mixed_precision_test.py
+-rw-r--r--  2.0 unx    16428 b- defN 23-May-25 15:37 keras_aug/layers/__internal__/output_common_test.py
+-rw-r--r--  2.0 unx    11480 b- defN 23-May-25 15:37 keras_aug/layers/__internal__/with_ragged_image_test.py
+-rw-r--r--  2.0 unx     2718 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/auto/__init__.py
+-rw-r--r--  2.0 unx    12271 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/auto/aug_mix.py
+-rw-r--r--  2.0 unx      815 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/auto/aug_mix_test.py
+-rw-r--r--  2.0 unx    18413 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/auto/rand_augment.py
+-rw-r--r--  2.0 unx     1281 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/auto/rand_augment_test.py
+-rw-r--r--  2.0 unx    14525 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/auto/trivial_augment_wide.py
+-rw-r--r--  2.0 unx      368 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/auto/trivial_augment_wide_test.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/geometry/__init__.py
+-rw-r--r--  2.0 unx    23246 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/geometry/random_affine.py
+-rw-r--r--  2.0 unx    15409 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/geometry/random_affine_test.py
+-rw-r--r--  2.0 unx    12054 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/geometry/random_crop.py
+-rw-r--r--  2.0 unx    11758 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/geometry/random_crop_and_resize.py
+-rw-r--r--  2.0 unx     9817 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/geometry/random_crop_and_resize_test.py
+-rw-r--r--  2.0 unx     7738 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/geometry/random_crop_test.py
+-rw-r--r--  2.0 unx     7997 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/geometry/random_flip.py
+-rw-r--r--  2.0 unx    11147 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/geometry/random_flip_test.py
+-rw-r--r--  2.0 unx     7186 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/geometry/random_resize.py
+-rw-r--r--  2.0 unx     8591 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/geometry/random_resize_test.py
+-rw-r--r--  2.0 unx     9239 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/geometry/random_rotate.py
+-rw-r--r--  2.0 unx     7395 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/geometry/random_rotate_test.py
+-rw-r--r--  2.0 unx    12633 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/geometry/random_zoom_and_crop.py
+-rw-r--r--  2.0 unx     6808 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/geometry/random_zoom_and_crop_test.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/intensity/__init__.py
+-rw-r--r--  2.0 unx     3356 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/intensity/channel_shuffle.py
+-rw-r--r--  2.0 unx     1633 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/intensity/channel_shuffle_test.py
+-rw-r--r--  2.0 unx     4167 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/intensity/random_blur.py
+-rw-r--r--  2.0 unx     1010 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/intensity/random_blur_test.py
+-rw-r--r--  2.0 unx     3481 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/intensity/random_channel_shift.py
+-rw-r--r--  2.0 unx     1506 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/intensity/random_channel_shift_test.py
+-rw-r--r--  2.0 unx     9563 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/intensity/random_clahe.py
+-rw-r--r--  2.0 unx     3093 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/intensity/random_clahe_test.py
+-rw-r--r--  2.0 unx     9411 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/intensity/random_color_jitter.py
+-rw-r--r--  2.0 unx     5660 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/intensity/random_color_jitter_test.py
+-rw-r--r--  2.0 unx     3430 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/intensity/random_gamma.py
+-rw-r--r--  2.0 unx     1420 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/intensity/random_gamma_test.py
+-rw-r--r--  2.0 unx     5256 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/intensity/random_gaussian_blur.py
+-rw-r--r--  2.0 unx     2098 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/intensity/random_gaussian_blur_test.py
+-rw-r--r--  2.0 unx     7785 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/intensity/random_hsv.py
+-rw-r--r--  2.0 unx     5230 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/intensity/random_hsv_test.py
+-rw-r--r--  2.0 unx     4503 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/intensity/random_jpeg_quality.py
+-rw-r--r--  2.0 unx     1155 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/intensity/random_jpeg_quality_test.py
+-rw-r--r--  2.0 unx     4388 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/intensity/random_posterize.py
+-rw-r--r--  2.0 unx     2768 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/intensity/random_posterize_test.py
+-rw-r--r--  2.0 unx     5116 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/intensity/random_sharpness.py
+-rw-r--r--  2.0 unx     1366 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/intensity/random_sharpness_test.py
+-rw-r--r--  2.0 unx     5125 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/intensity/random_solarize.py
+-rw-r--r--  2.0 unx     2269 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/intensity/random_solarize_test.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/mix/__init__.py
+-rw-r--r--  2.0 unx     7143 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/mix/cut_mix.py
+-rw-r--r--  2.0 unx     4258 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/mix/cut_mix_test.py
+-rw-r--r--  2.0 unx     6149 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/mix/mix_up.py
+-rw-r--r--  2.0 unx     2947 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/mix/mix_up_test.py
+-rw-r--r--  2.0 unx    16288 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/mix/mosaic.py
+-rw-r--r--  2.0 unx     2297 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/mix/mosaic_test.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/regularization/__init__.py
+-rw-r--r--  2.0 unx     3737 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/regularization/random_channel_dropout.py
+-rw-r--r--  2.0 unx      706 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/regularization/random_channel_dropout_test.py
+-rw-r--r--  2.0 unx     9425 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/regularization/random_cutout.py
+-rw-r--r--  2.0 unx     3189 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/regularization/random_cutout_test.py
+-rw-r--r--  2.0 unx     7296 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/regularization/random_erase.py
+-rw-r--r--  2.0 unx     3236 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/regularization/random_erase_test.py
+-rw-r--r--  2.0 unx    10927 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/regularization/random_grid_mask.py
+-rw-r--r--  2.0 unx     2161 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/regularization/random_grid_mask_test.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/utility/__init__.py
+-rw-r--r--  2.0 unx     6080 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/utility/random_apply.py
+-rw-r--r--  2.0 unx     2792 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/utility/random_apply_test.py
+-rw-r--r--  2.0 unx     6457 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/utility/random_choice.py
+-rw-r--r--  2.0 unx     2732 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/utility/random_choice_test.py
+-rw-r--r--  2.0 unx     3588 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/utility/repeated_augment.py
+-rw-r--r--  2.0 unx     1106 b- defN 23-May-25 15:37 keras_aug/layers/augmentation/utility/repeated_augment_test.py
+-rw-r--r--  2.0 unx       98 b- defN 23-May-25 15:37 keras_aug/layers/base/__init__.py
+-rw-r--r--  2.0 unx    24094 b- defN 23-May-25 15:37 keras_aug/layers/base/vectorized_base_random_layer.py
+-rw-r--r--  2.0 unx    22086 b- defN 23-May-25 15:37 keras_aug/layers/base/vectorized_base_random_layer_test.py
+-rw-r--r--  2.0 unx      825 b- defN 23-May-25 15:37 keras_aug/layers/preprocessing/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-25 15:37 keras_aug/layers/preprocessing/geometry/__init__.py
+-rw-r--r--  2.0 unx    10864 b- defN 23-May-25 15:37 keras_aug/layers/preprocessing/geometry/center_crop.py
+-rw-r--r--  2.0 unx     8368 b- defN 23-May-25 15:37 keras_aug/layers/preprocessing/geometry/center_crop_test.py
+-rw-r--r--  2.0 unx    10833 b- defN 23-May-25 15:37 keras_aug/layers/preprocessing/geometry/pad_if_needed.py
+-rw-r--r--  2.0 unx     9878 b- defN 23-May-25 15:37 keras_aug/layers/preprocessing/geometry/pad_if_needed_test.py
+-rw-r--r--  2.0 unx    15545 b- defN 23-May-25 15:37 keras_aug/layers/preprocessing/geometry/resize.py
+-rw-r--r--  2.0 unx    22167 b- defN 23-May-25 15:37 keras_aug/layers/preprocessing/geometry/resize_test.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-25 15:37 keras_aug/layers/preprocessing/intensity/__init__.py
+-rw-r--r--  2.0 unx     2878 b- defN 23-May-25 15:37 keras_aug/layers/preprocessing/intensity/auto_contrast.py
+-rw-r--r--  2.0 unx     2698 b- defN 23-May-25 15:37 keras_aug/layers/preprocessing/intensity/auto_contrast_test.py
+-rw-r--r--  2.0 unx     4513 b- defN 23-May-25 15:37 keras_aug/layers/preprocessing/intensity/equalize.py
+-rw-r--r--  2.0 unx     1529 b- defN 23-May-25 15:37 keras_aug/layers/preprocessing/intensity/equalize_test.py
+-rw-r--r--  2.0 unx     2376 b- defN 23-May-25 15:37 keras_aug/layers/preprocessing/intensity/grayscale.py
+-rw-r--r--  2.0 unx     1224 b- defN 23-May-25 15:37 keras_aug/layers/preprocessing/intensity/grayscale_test.py
+-rw-r--r--  2.0 unx     1023 b- defN 23-May-25 15:37 keras_aug/layers/preprocessing/intensity/identity.py
+-rw-r--r--  2.0 unx     1391 b- defN 23-May-25 15:37 keras_aug/layers/preprocessing/intensity/identity_test.py
+-rw-r--r--  2.0 unx     1653 b- defN 23-May-25 15:37 keras_aug/layers/preprocessing/intensity/invert.py
+-rw-r--r--  2.0 unx      459 b- defN 23-May-25 15:37 keras_aug/layers/preprocessing/intensity/invert_test.py
+-rw-r--r--  2.0 unx     2931 b- defN 23-May-25 15:37 keras_aug/layers/preprocessing/intensity/normalize.py
+-rw-r--r--  2.0 unx     1483 b- defN 23-May-25 15:37 keras_aug/layers/preprocessing/intensity/normalize_test.py
+-rw-r--r--  2.0 unx     1923 b- defN 23-May-25 15:37 keras_aug/layers/preprocessing/intensity/rescale.py
+-rw-r--r--  2.0 unx     1365 b- defN 23-May-25 15:37 keras_aug/layers/preprocessing/intensity/rescale_test.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-25 15:37 keras_aug/utils/__init__.py
+-rw-r--r--  2.0 unx    18127 b- defN 23-May-25 15:37 keras_aug/utils/augmentation.py
+-rw-r--r--  2.0 unx     7832 b- defN 23-May-25 15:37 keras_aug/utils/augmentation_test.py
+-rw-r--r--  2.0 unx     8682 b- defN 23-May-25 15:37 keras_aug/utils/bounding_box.py
+-rw-r--r--  2.0 unx     3235 b- defN 23-May-25 15:37 keras_aug/utils/bounding_box_test.py
+-rw-r--r--  2.0 unx      373 b- defN 23-May-25 15:37 keras_aug/utils/conditional_imports.py
+-rw-r--r--  2.0 unx     6101 b- defN 23-May-25 15:37 keras_aug/utils/demo.py
+-rw-r--r--  2.0 unx    11456 b- defN 23-May-25 15:37 keras_aug-0.5.2.dist-info/LICENSE
+-rw-r--r--  2.0 unx    13601 b- defN 23-May-25 15:37 keras_aug-0.5.2.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-May-25 15:37 keras_aug-0.5.2.dist-info/WHEEL
+-rw-r--r--  2.0 unx       10 b- defN 23-May-25 15:37 keras_aug-0.5.2.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx    14553 b- defN 23-May-25 15:37 keras_aug-0.5.2.dist-info/RECORD
+133 files, 714093 bytes uncompressed, 164521 bytes compressed:  77.0%
```

## zipnote {}

```diff
@@ -378,23 +378,23 @@
 
 Filename: keras_aug/utils/conditional_imports.py
 Comment: 
 
 Filename: keras_aug/utils/demo.py
 Comment: 
 
-Filename: keras_aug-0.5.1.dist-info/LICENSE
+Filename: keras_aug-0.5.2.dist-info/LICENSE
 Comment: 
 
-Filename: keras_aug-0.5.1.dist-info/METADATA
+Filename: keras_aug-0.5.2.dist-info/METADATA
 Comment: 
 
-Filename: keras_aug-0.5.1.dist-info/WHEEL
+Filename: keras_aug-0.5.2.dist-info/WHEEL
 Comment: 
 
-Filename: keras_aug-0.5.1.dist-info/top_level.txt
+Filename: keras_aug-0.5.2.dist-info/top_level.txt
 Comment: 
 
-Filename: keras_aug-0.5.1.dist-info/RECORD
+Filename: keras_aug-0.5.2.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## keras_aug/__init__.py

```diff
@@ -3,8 +3,8 @@
 from keras_aug.core import ConstantFactorSampler
 from keras_aug.core import FactorSampler
 from keras_aug.core import NormalFactorSampler
 from keras_aug.core import SignedConstantFactorSampler
 from keras_aug.core import SignedNormalFactorSampler
 from keras_aug.core import UniformFactorSampler
 
-__version__ = "0.5.1"
+__version__ = "0.5.2"
```

## keras_aug/layers/__init__.py

```diff
@@ -71,7 +71,10 @@
 from keras_aug.layers.preprocessing.intensity.auto_contrast import AutoContrast
 from keras_aug.layers.preprocessing.intensity.equalize import Equalize
 from keras_aug.layers.preprocessing.intensity.grayscale import Grayscale
 from keras_aug.layers.preprocessing.intensity.identity import Identity
 from keras_aug.layers.preprocessing.intensity.invert import Invert
 from keras_aug.layers.preprocessing.intensity.normalize import Normalize
 from keras_aug.layers.preprocessing.intensity.rescale import Rescale
+from keras_aug.layers.preprocessing.utility.sanitize_bounding_box import (
+    SanitizeBoundingBox,
+)
```

## keras_aug/layers/__internal__/config_test.py

```diff
@@ -5,17 +5,25 @@
 
 from keras_aug import layers
 from keras_aug.core import ConstantFactorSampler
 from keras_aug.core import UniformFactorSampler
 from keras_aug.layers import augmentation
 from keras_aug.layers import preprocessing
 
-TEST_CONFIGURATIONS = [
-    ("AugMix", layers.AugMix, {"value_range": (0, 255)}),
-    ("RandAugment", layers.RandAugment, {"value_range": (0, 255)}),
+GENERAL_TESTS = [
+    (
+        "AugMix",
+        layers.AugMix,
+        {"value_range": (0, 255)},
+    ),
+    (
+        "RandAugment",
+        layers.RandAugment,
+        {"value_range": (0, 255)},
+    ),
     (
         "TrivialAugmentWide",
         layers.TrivialAugmentWide,
         {"value_range": (0, 255)},
     ),
     (
         "RandomAffine",
@@ -26,28 +34,44 @@
             "translation_width_factor": 0.1,
             "zoom_height_factor": 0.1,
             "zoom_width_factor": 0.1,
             "shear_height_factor": 0.1,
             "shear_width_factor": 0.1,
         },
     ),
-    ("RandomCrop", layers.RandomCrop, {"height": 2, "width": 2}),
+    (
+        "RandomCrop",
+        layers.RandomCrop,
+        {"height": 2, "width": 2},
+    ),
     (
         "RandomCropAndResize",
         layers.RandomCropAndResize,
         {
             "height": 2,
             "width": 2,
             "crop_area_factor": (0.8, 1.0),
             "aspect_ratio_factor": (3 / 4, 4 / 3),
         },
     ),
-    ("RandomFlip", layers.RandomFlip, {"mode": "horizontal"}),
-    ("RandomResize", layers.RandomResize, {"heights": [2]}),
-    ("RandomRotate", layers.RandomRotate, {"factor": 10}),
+    (
+        "RandomFlip",
+        layers.RandomFlip,
+        {"mode": "horizontal"},
+    ),
+    (
+        "RandomResize",
+        layers.RandomResize,
+        {"heights": [2]},
+    ),
+    (
+        "RandomRotate",
+        layers.RandomRotate,
+        {"factor": 10},
+    ),
     (
         "RandomZoomAndCrop",
         layers.RandomZoomAndCrop,
         {"height": 2, "width": 2, "scale_factor": (0.8, 1.25)},
     ),
     (
         "CenterCrop",
@@ -55,22 +79,34 @@
         {"height": 2, "width": 2},
     ),
     (
         "PadIfNeeded",
         layers.PadIfNeeded,
         {"min_height": 2, "min_width": 2},
     ),
-    ("ChannelShuffle", layers.ChannelShuffle, {"groups": 3}),
-    ("RandomBlur", layers.RandomBlur, {"factor": (3, 7)}),
+    (
+        "ChannelShuffle",
+        layers.ChannelShuffle,
+        {"groups": 3},
+    ),
+    (
+        "RandomBlur",
+        layers.RandomBlur,
+        {"factor": (3, 7)},
+    ),
     (
         "RandomChannelShift",
         layers.RandomChannelShift,
         {"value_range": (0, 255), "factor": 0.1},
     ),
-    ("RandomCLAHE", layers.RandomCLAHE, {"value_range": (0, 255)}),
+    (
+        "RandomCLAHE",
+        layers.RandomCLAHE,
+        {"value_range": (0, 255)},
+    ),
     (
         "RandomColorJitter",
         layers.RandomColorJitter,
         {
             "value_range": (0, 255),
             "brightness_factor": 0.1,
             "contrast_factor": 0.1,
@@ -197,66 +233,93 @@
         },
     ),
     (
         "Resize",
         layers.Resize,
         {"height": 2, "width": 2},
     ),
-    ("AutoContrast", layers.AutoContrast, {"value_range": (0, 255)}),
-    ("Equalize", layers.Equalize, {"value_range": (0, 255)}),
-    ("Grayscale", layers.Grayscale, {"output_channels": 3}),
-    ("Invert", layers.Invert, {"value_range": (0, 255)}),
-    ("Normalize", layers.Normalize, {"value_range": (0, 255)}),
+    (
+        "AutoContrast",
+        layers.AutoContrast,
+        {"value_range": (0, 255)},
+    ),
+    (
+        "Equalize",
+        layers.Equalize,
+        {"value_range": (0, 255)},
+    ),
+    (
+        "Grayscale",
+        layers.Grayscale,
+        {"output_channels": 3},
+    ),
+    (
+        "Identity",
+        layers.Identity,
+        {},
+    ),
+    (
+        "Invert",
+        layers.Invert,
+        {"value_range": (0, 255)},
+    ),
+    (
+        "Normalize",
+        layers.Normalize,
+        {"value_range": (0, 255)},
+    ),
     (
         "Rescale",
         layers.Rescale,
         {"scale": 1.0 / 255.0},
     ),
-    ("Identity", layers.Identity, {}),
+    (
+        "SanitizeBoundingBox",
+        layers.SanitizeBoundingBox,
+        {"min_size": 10, "bounding_box_format": "xyxy"},
+    ),
 ]
 
 
 class ConfigTest(tf.test.TestCase, parameterized.TestCase):
     def test_all_2d_aug_layers_included(self):
         base_cls = layers.VectorizedBaseRandomLayer
-        all_2d_aug_layers = inspect.getmembers(
-            augmentation,
-            predicate=inspect.isclass,
-        ) + inspect.getmembers(
-            preprocessing,
-            predicate=inspect.isclass,
+        cls_spaces = [augmentation, preprocessing]
+        all_2d_aug_layers = []
+        for cls_space in cls_spaces:
+            all_2d_aug_layers.extend(
+                inspect.getmembers(cls_space, predicate=inspect.isclass)
+            )
+        all_2d_aug_layer_names = set(
+            item[0]
+            for item in all_2d_aug_layers
+            if issubclass(item[1], base_cls)
         )
-        all_2d_aug_layers = [
-            item for item in all_2d_aug_layers if issubclass(item[1], base_cls)
-        ]
-        all_2d_aug_layer_names = set(item[0] for item in all_2d_aug_layers)
-        test_configuration_names = set(item[0] for item in TEST_CONFIGURATIONS)
+
+        general_names = set(item[0] for item in GENERAL_TESTS)
+        all_test_names = general_names
 
         for name in all_2d_aug_layer_names:
-            self.assertIn(
-                name,
-                test_configuration_names,
-                msg=f"{name} not found in TEST_CONFIGURATIONS",
-            )
+            self.assertIn(name, all_test_names, msg=f"{name} not found")
 
-    @parameterized.named_parameters(*TEST_CONFIGURATIONS)
+    @parameterized.named_parameters(*GENERAL_TESTS)
     def test_config(self, layer_cls, args):
         layer = layer_cls(**args)
 
         config = layer.get_config()
 
         for key in args.keys():
             if isinstance(config[key], UniformFactorSampler):
                 self.assertTrue(isinstance(config[key], UniformFactorSampler))
             elif isinstance(config[key], ConstantFactorSampler):
                 self.assertTrue(isinstance(config[key], ConstantFactorSampler))
             else:
                 self.assertEqual(config[key], args[key])
 
-    @parameterized.named_parameters(*TEST_CONFIGURATIONS)
+    @parameterized.named_parameters(*GENERAL_TESTS)
     def test_config_with_custom_name(self, layer_cls, args):
         layer = layer_cls(**args, name="image_preproc")
         config = layer.get_config()
 
         layer_1 = layer_cls.from_config(config)
 
         self.assertEqual(layer_1.name, layer.name)
```

## keras_aug/layers/__internal__/graph_xla_mode_test.py

```diff
@@ -2,302 +2,422 @@
 
 import tensorflow as tf
 from absl.testing import parameterized
 
 from keras_aug import layers
 from keras_aug.layers import augmentation
 from keras_aug.layers import preprocessing
+from keras_aug.utils.augmentation import BOUNDING_BOXES
 from keras_aug.utils.augmentation import IMAGES
 from keras_aug.utils.augmentation import LABELS
 
-TEST_CONFIGURATIONS = [
-    ("AugMix", layers.AugMix, {"value_range": (0, 255)}),
+#   (
+#       name,
+#       layer_cls,
+#       args,
+#       is_xla_compatible,
+#   )
+# all configurations should be expanded for readability
+GENERAL_TESTS = [
+    (
+        "AugMix",
+        layers.AugMix,
+        {"value_range": (0, 255)},
+        False,  # containing invalid operations
+    ),
     (
         "RandAugment",
         layers.RandAugment,
         {"value_range": (0, 255), "seed": 2023},
+        False,  # containing invalid operations
     ),
     (
         "TrivialAugmentWide",
         layers.TrivialAugmentWide,
         {"value_range": (0, 255)},
+        False,  # containing invalid operations
     ),
     (
         "RandomAffine",
         layers.RandomAffine,
         {
             "rotation_factor": 10,
             "translation_height_factor": 0.1,
             "translation_width_factor": 0.1,
             "zoom_height_factor": 0.1,
             "zoom_width_factor": 0.1,
             "shear_height_factor": 0.1,
             "shear_width_factor": 0.1,
         },
+        False,  # tf.raw_ops.ImageProjectiveTransformV3
+    ),
+    (
+        "RandomCrop",
+        layers.RandomCrop,
+        {"height": 2, "width": 2},
+        False,  # tf.image.crop_and_resize
     ),
-    ("RandomCrop", layers.RandomCrop, {"height": 2, "width": 2}),
     (
         "RandomCropAndResize",
         layers.RandomCropAndResize,
         {
             "height": 2,
             "width": 2,
             "crop_area_factor": (0.8, 1.0),
             "aspect_ratio_factor": (3 / 4, 4 / 3),
         },
+        False,  # tf.image.crop_and_resize
+    ),
+    (
+        "RandomFlip",
+        layers.RandomFlip,
+        {"mode": "horizontal"},
+        True,
+    ),
+    (
+        "RandomResize",
+        layers.RandomResize,
+        {"heights": [2]},
+        False,  # tf.image.resize
+    ),
+    (
+        "RandomRotate",
+        layers.RandomRotate,
+        {"factor": 10},
+        False,  # tf.raw_ops.ImageProjectiveTransformV3
     ),
-    ("RandomFlip", layers.RandomFlip, {"mode": "horizontal"}),
-    ("RandomResize", layers.RandomResize, {"heights": [2]}),
-    ("RandomRotate", layers.RandomRotate, {"factor": 10}),
     (
         "RandomZoomAndCrop",
         layers.RandomZoomAndCrop,
         {"height": 2, "width": 2, "scale_factor": (0.8, 1.25)},
+        False,  # tf.image.resize
+    ),
+    (
+        "ChannelShuffle",
+        layers.ChannelShuffle,
+        {"groups": 3},
+        True,
+    ),
+    (
+        "RandomBlur",
+        layers.RandomBlur,
+        {"factor": (3, 7)},
+        False,  # tf.map_fn
     ),
-    ("ChannelShuffle", layers.ChannelShuffle, {"groups": 3}),
-    ("RandomBlur", layers.RandomBlur, {"factor": (3, 7)}),
     (
         "RandomChannelShift",
         layers.RandomChannelShift,
         {"value_range": (0, 255), "factor": 0.1},
+        True,
     ),
     (
         "RandomCLAHE",
         layers.RandomCLAHE,
         {"value_range": (0, 255), "factor": (2, 10), "tile_grid_size": (4, 4)},
+        True,
     ),
     (
         "RandomColorJitter",
         layers.RandomColorJitter,
         {
             "value_range": (0, 255),
             "brightness_factor": 0.1,
             "contrast_factor": 0.1,
             "saturation_factor": 0.1,
             "hue_factor": 0.1,
         },
+        True,
     ),
     (
         "RandomGamma",
         layers.RandomGamma,
         {"value_range": (0, 255), "factor": 0.1},
+        True,
     ),
     (
         "RandomGaussianBlur",
         layers.RandomGaussianBlur,
         {"kernel_size": 3, "factor": 2.0},
+        True,
     ),
     (
         "RandomHSV",
         layers.RandomHSV,
         {
             "value_range": (0, 255),
             "hue_factor": 0.1,
             "saturation_factor": 0.1,
             "value_factor": 0.1,
         },
+        True,
     ),
     (
         "RandomJpegQuality",
         layers.RandomJpegQuality,
         {
             "value_range": (0, 255),
             "factor": (75, 100),
         },
+        False,  # tf.image.adjust_jpeg_quality
     ),
     (
         "RandomPosterize",
         layers.RandomPosterize,
         {"value_range": (0, 255), "factor": (5, 8)},
+        True,
     ),
     (
         "RandomSharpness",
         layers.RandomSharpness,
         {"value_range": (0, 255), "factor": 0.1},
+        True,
     ),
     (
         "RandomSolarize",
         layers.RandomSolarize,
         {
             "value_range": (0, 255),
             "threshold_factor": 10,
             "addition_factor": 10,
         },
+        True,
     ),
     (
         "CutMix",
         layers.CutMix,
         {"alpha": 1.0},
+        True,
     ),
     (
         "MixUp",
         layers.MixUp,
         {},
+        True,
     ),
     (
         "Mosaic",
         layers.Mosaic,
         {
             "height": 100,
             "width": 100,
         },
+        False,  # tf.map_fn
     ),
     (
         "RandomChannelDropout",
         layers.RandomChannelDropout,
         {},
+        True,
     ),
     (
         "RandomCutout",
         layers.RandomCutout,
         {"height_factor": 0.3, "width_factor": 0.3},
+        True,
     ),
     (
         "RandomErase",
         layers.RandomErase,
         {"area_factor": (0.02, 0.4), "aspect_ratio_factor": (0.3, 1.0 / 0.3)},
+        True,
     ),
     (
         "RandomGridMask",
         layers.RandomGridMask,
         {
             "size_factor": (0.5, 1.0),
             "ratio_factor": (0.6, 0.6),
             "rotation_factor": (-10, 10),
         },
+        False,  # tf.raw_ops.ImageProjectiveTransformV3
     ),
     (
         "RandomApply",
         layers.RandomApply,
         {"layer": layers.RandomChannelDropout()},
+        True,  # depends on the `layer`
     ),
     (
         "RandomChoice",
         layers.RandomChoice,
         {
             "layers": [
                 layers.RandomChannelDropout(),
                 layers.RandomChannelDropout(),
             ]
         },
+        True,  # depends on the `layers`
     ),
     (
         "RepeatedAugment",
         layers.RepeatedAugment,
         {
             "layers": [
                 layers.RandomColorJitter(
                     value_range=(0, 255), brightness_factor=(1.5, 1.5)
                 ),
                 layers.RandomColorJitter(
                     value_range=(0, 255), contrast_factor=(1.5, 1.5)
                 ),
             ]
         },
+        False,  # tf.random.state_less.shuffle
     ),
     (
         "CenterCrop",
         layers.CenterCrop,
         {"height": 2, "width": 2},
+        True,
     ),
     (
         "PadIfNeeded",
         layers.PadIfNeeded,
         {"min_height": 2, "min_width": 2},
+        True,
     ),
     (
         "Resize",
         layers.Resize,
         {"height": 2, "width": 2},
+        True,
+    ),
+    (
+        "AutoContrast",
+        layers.AutoContrast,
+        {"value_range": (0, 255)},
+        True,
+    ),
+    (
+        "Equalize",
+        layers.Equalize,
+        {"value_range": (0, 255)},
+        False,  # tf.histogram_fixed_width
+    ),
+    (
+        "Grayscale",
+        layers.Grayscale,
+        {"output_channels": 3},
+        True,
+    ),
+    (
+        "Identity",
+        layers.Identity,
+        {},
+        True,
+    ),
+    (
+        "Invert",
+        layers.Invert,
+        {"value_range": (0, 255)},
+        True,
+    ),
+    (
+        "Normalize",
+        layers.Normalize,
+        {"value_range": (0, 255)},
+        True,
     ),
-    ("AutoContrast", layers.AutoContrast, {"value_range": (0, 255)}),
-    ("Equalize", layers.Equalize, {"value_range": (0, 255)}),
-    ("Grayscale", layers.Grayscale, {"output_channels": 3}),
-    ("Invert", layers.Invert, {"value_range": (0, 255)}),
-    ("Normalize", layers.Normalize, {"value_range": (0, 255)}),
     (
         "Rescale",
         layers.Rescale,
         {"scale": 1.0 / 255.0},
+        True,
     ),
-    ("Identity", layers.Identity, {}),
-]
-
-NO_XLA_SUPPORT_LAYERS = [
-    layers.AugMix,
-    layers.RandAugment,
-    layers.TrivialAugmentWide,
-    layers.RandomAffine,  # tf.raw_ops.ImageProjectiveTransformV3
-    layers.RandomCrop,  # tf.image.crop_and_resize
-    layers.RandomCropAndResize,  # tf.image.crop_and_resize
-    layers.RandomResize,  # tf.image.resize
-    layers.RandomRotate,  # tf.raw_ops.ImageProjectiveTransformV3
-    layers.RandomZoomAndCrop,  # tf.image.resize
-    layers.RandomBlur,  # tf.map_fn
-    layers.RandomJpegQuality,  # tf.image.adjust_jpeg_quality
-    layers.Mosaic,  # tf.map_fn
-    layers.RandomGridMask,  # tf.raw_ops.ImageProjectiveTransformV3
-    layers.RepeatedAugment,  # tf.random.state_less.shuffle
-    layers.Equalize,  # tf.histogram_fixed_width
 ]
 
-SKIP_XLA_TEST_LAYERS = [
-    layers.AugMix,  # too slow to compile
-    layers.RandAugment,  # too slow to compile
-    layers.TrivialAugmentWide,  # too slow to compile
-    layers.RandomColorJitter,  # too slow to compile
-    layers.Equalize,  # too slow to compile
+MUST_RUN_WITH_BOUNDING_BOXES = [
+    (
+        "SanitizeBoundingBox",
+        layers.SanitizeBoundingBox,
+        {"min_size": 10},
+        False,  # bounding_box.to_dense
+    ),
 ]
 
 
-class GraphModeTest(tf.test.TestCase, parameterized.TestCase):
-    def test_all_2d_aug_layers_included(self):
+class GraphAndXLAModeTest(tf.test.TestCase, parameterized.TestCase):
+    def test_all_2d_aug_layers_are_included(self):
         base_cls = layers.VectorizedBaseRandomLayer
-        all_2d_aug_layers = inspect.getmembers(
-            augmentation,
-            predicate=inspect.isclass,
-        ) + inspect.getmembers(
-            preprocessing,
-            predicate=inspect.isclass,
+        cls_spaces = [augmentation, preprocessing]
+        all_2d_aug_layers = []
+        for cls_space in cls_spaces:
+            all_2d_aug_layers.extend(
+                inspect.getmembers(cls_space, predicate=inspect.isclass)
+            )
+        all_2d_aug_layer_names = set(
+            item[0]
+            for item in all_2d_aug_layers
+            if issubclass(item[1], base_cls)
         )
-        all_2d_aug_layers = [
-            item for item in all_2d_aug_layers if issubclass(item[1], base_cls)
-        ]
-        all_2d_aug_layer_names = set(item[0] for item in all_2d_aug_layers)
-        test_configuration_names = set(item[0] for item in TEST_CONFIGURATIONS)
+
+        general_names = set(item[0] for item in GENERAL_TESTS)
+        bbox_names = set(item[0] for item in MUST_RUN_WITH_BOUNDING_BOXES)
+        all_test_names = general_names.union(bbox_names)
 
         for name in all_2d_aug_layer_names:
-            self.assertIn(
-                name,
-                test_configuration_names,
-                msg=f"{name} not found in TEST_CONFIGURATIONS",
-            )
+            self.assertIn(name, all_test_names, msg=f"{name} not found")
 
-    @parameterized.named_parameters(*TEST_CONFIGURATIONS)
-    def test_can_run_in_graph_mode(self, layer_cls, args):
-        images = tf.random.uniform(shape=(1, 8, 8, 3)) * 255.0
-        labels = tf.random.uniform(shape=(1, 1)) * 10.0
-        layer = layer_cls(**args)
+    @parameterized.named_parameters(*GENERAL_TESTS)
+    def test_run_in_graph_mode(self, layer_cls, args, is_xla_compatible):
+        images = tf.random.uniform(shape=(2, 8, 8, 3)) * 255.0
+        labels = tf.random.uniform(shape=(2, 1)) * 10.0
+        bounding_boxes = {
+            "boxes": tf.ragged.constant(
+                [
+                    [[10, 10, 20, 20], [100, 100, 150, 150]],
+                    [[200, 200, 400, 400]],
+                ],
+                dtype=tf.float32,
+            ),
+            "classes": tf.ragged.constant([[0, 1], [2]], dtype=tf.float32),
+        }
+        try:
+            layer = layer_cls(**args, bounding_box_format="xyxy")
+            has_bounding_boxes = True
+        except TypeError:
+            layer = layer_cls(**args)
+            has_bounding_boxes = False
 
         @tf.function
         def fn(inputs):
             layer(inputs)
 
-        fn({IMAGES: images, LABELS: labels})
+        if has_bounding_boxes:
+            fn({IMAGES: images, LABELS: labels, BOUNDING_BOXES: bounding_boxes})
+        else:
+            fn({IMAGES: images, LABELS: labels})
 
-    @parameterized.named_parameters(*TEST_CONFIGURATIONS)
-    def test_can_run_in_xla_mode(self, layer_cls, args):
-        if layer_cls in SKIP_XLA_TEST_LAYERS:
+    @parameterized.named_parameters(*GENERAL_TESTS)
+    def test_run_in_xla_mode(self, layer_cls, args, is_xla_compatible):
+        if is_xla_compatible is False:
             return
-        images = tf.random.uniform(shape=(1, 8, 8, 3)) * 255.0
+        images = tf.random.uniform(shape=(1, 4, 4, 3)) * 255.0
         labels = tf.random.uniform(shape=(1, 1)) * 10.0
         layer = layer_cls(**args)
 
         @tf.function(jit_compile=True)
         def fn(inputs):
             layer(inputs)
 
-        if layer_cls not in NO_XLA_SUPPORT_LAYERS:
-            fn({IMAGES: images, LABELS: labels})
-        else:
-            with self.assertRaises(tf.errors.InvalidArgumentError):
-                fn({IMAGES: images, LABELS: labels})
+        fn({IMAGES: images, LABELS: labels})
+
+    @parameterized.named_parameters(*MUST_RUN_WITH_BOUNDING_BOXES)
+    def test_run_in_graph_mode_bbox(self, layer_cls, args, is_xla_compatible):
+        images = tf.random.uniform(shape=(2, 4, 4, 3)) * 255.0
+        labels = tf.random.uniform(shape=(2, 1)) * 10.0
+        bounding_boxes = {
+            "boxes": tf.ragged.constant(
+                [
+                    [[0, 0, 1, 1], [0, 0, 4, 4]],
+                    [[0, 0, 2, 3]],
+                ],
+                dtype=tf.float32,
+            ),
+            "classes": tf.ragged.constant([[0, 1], [2]], dtype=tf.float32),
+        }
+        layer = layer_cls(**args, bounding_box_format="xyxy")
+
+        @tf.function
+        def fn(inputs):
+            layer(inputs)
+
+        fn({IMAGES: images, LABELS: labels, BOUNDING_BOXES: bounding_boxes})
```

## keras_aug/layers/__internal__/mixed_precision_test.py

```diff
@@ -1,211 +1,307 @@
 import inspect
 
 import tensorflow as tf
 from absl.testing import parameterized
+from keras_cv import bounding_box
 from tensorflow import keras
 
 from keras_aug import layers
 from keras_aug.layers import augmentation
 from keras_aug.layers import preprocessing
+from keras_aug.utils.augmentation import BOUNDING_BOXES
 from keras_aug.utils.augmentation import IMAGES
 from keras_aug.utils.augmentation import LABELS
 
-TEST_CONFIGURATIONS = [
-    ("AugMix", layers.AugMix, {"value_range": (0, 255)}),
-    ("RandAugment", layers.RandAugment, {"value_range": (0, 255)}),
+#   (
+#       name,
+#       layer_cls,
+#       args,
+#       is_bbox_compatible,
+#   )
+# all configurations should be expanded for readability
+GENERAL_TESTS = [
+    (
+        "AugMix",
+        layers.AugMix,
+        {"value_range": (0, 255)},
+        False,
+    ),
+    (
+        "RandAugment",
+        layers.RandAugment,
+        {"value_range": (0, 255)},
+        True,
+    ),
     (
         "TrivialAugmentWide",
         layers.TrivialAugmentWide,
         {"value_range": (0, 255)},
+        True,
     ),
     (
         "RandomAffine",
         layers.RandomAffine,
         {
             "rotation_factor": 10,
             "translation_height_factor": 0.1,
             "translation_width_factor": 0.1,
             "zoom_height_factor": 0.1,
             "zoom_width_factor": 0.1,
             "shear_height_factor": 0.1,
             "shear_width_factor": 0.1,
         },
+        True,
+    ),
+    (
+        "RandomCrop",
+        layers.RandomCrop,
+        {"height": 2, "width": 2},
+        True,
     ),
-    ("RandomCrop", layers.RandomCrop, {"height": 2, "width": 2}),
     (
         "RandomCropAndResize",
         layers.RandomCropAndResize,
         {
             "height": 2,
             "width": 2,
             "crop_area_factor": (0.8, 1.0),
             "aspect_ratio_factor": (3 / 4, 4 / 3),
         },
+        True,
+    ),
+    (
+        "RandomFlip",
+        layers.RandomFlip,
+        {"mode": "horizontal"},
+        True,
+    ),
+    (
+        "RandomResize",
+        layers.RandomResize,
+        {"heights": [2]},
+        True,
+    ),
+    (
+        "RandomRotate",
+        layers.RandomRotate,
+        {"factor": 10},
+        True,
     ),
-    ("RandomFlip", layers.RandomFlip, {"mode": "horizontal"}),
-    ("RandomResize", layers.RandomResize, {"heights": [2]}),
-    ("RandomRotate", layers.RandomRotate, {"factor": 10}),
     (
         "RandomZoomAndCrop",
         layers.RandomZoomAndCrop,
         {"height": 2, "width": 2, "scale_factor": (0.8, 1.25)},
+        True,
+    ),
+    (
+        "ChannelShuffle",
+        layers.ChannelShuffle,
+        {"groups": 3},
+        True,
+    ),
+    (
+        "RandomBlur",
+        layers.RandomBlur,
+        {"factor": (3, 7)},
+        True,
     ),
-    ("ChannelShuffle", layers.ChannelShuffle, {"groups": 3}),
-    ("RandomBlur", layers.RandomBlur, {"factor": (3, 7)}),
     (
         "RandomChannelShift",
         layers.RandomChannelShift,
         {"value_range": (0, 255), "factor": 0.1},
+        True,
     ),
     (
         "RandomCLAHE",
         layers.RandomCLAHE,
         {"value_range": (0, 255), "factor": (2, 10), "tile_grid_size": (4, 4)},
+        True,
     ),
     (
         "RandomColorJitter",
         layers.RandomColorJitter,
         {
             "value_range": (0, 255),
             "brightness_factor": 0.1,
             "contrast_factor": 0.1,
             "saturation_factor": 0.1,
             "hue_factor": 0.1,
         },
+        True,
     ),
     (
         "RandomGamma",
         layers.RandomGamma,
         {"value_range": (0, 255), "factor": 0.1},
+        True,
     ),
     (
         "RandomGaussianBlur",
         layers.RandomGaussianBlur,
         {"kernel_size": 3, "factor": 2.0},
+        True,
     ),
     (
         "RandomHSV",
         layers.RandomHSV,
         {
             "value_range": (0, 255),
             "hue_factor": 0.1,
             "saturation_factor": 0.1,
             "value_factor": 0.1,
         },
+        True,
     ),
     (
         "RandomJpegQuality",
         layers.RandomJpegQuality,
         {
             "value_range": (0, 255),
             "factor": (75, 100),
         },
+        True,
     ),
     (
         "RandomPosterize",
         layers.RandomPosterize,
         {"value_range": (0, 255), "factor": (5, 8)},
+        True,
     ),
     (
         "RandomSharpness",
         layers.RandomSharpness,
         {"value_range": (0, 255), "factor": 0.1},
+        True,
     ),
     (
         "RandomSolarize",
         layers.RandomSolarize,
         {
             "value_range": (0, 255),
             "threshold_factor": 10,
             "addition_factor": 10,
         },
+        True,
     ),
     (
         "CutMix",
         layers.CutMix,
         {"alpha": 1.0},
+        False,
     ),
     (
         "MixUp",
         layers.MixUp,
         {},
+        True,
     ),
     (
         "Mosaic",
         layers.Mosaic,
         {
             "height": 100,
             "width": 100,
         },
+        True,
     ),
     (
         "RandomChannelDropout",
         layers.RandomChannelDropout,
         {},
+        True,
     ),
     (
         "RandomCutout",
         layers.RandomCutout,
         {"height_factor": 0.3, "width_factor": 0.3},
+        True,
     ),
     (
         "RandomErase",
         layers.RandomErase,
         {"area_factor": (0.02, 0.4), "aspect_ratio_factor": (0.3, 1.0 / 0.3)},
+        False,
     ),
     (
         "RandomGridMask",
         layers.RandomGridMask,
         {
             "size_factor": (0.5, 1.0),
             "ratio_factor": (0.6, 0.6),
             "rotation_factor": (-10, 10),
         },
-    ),
-    ("Equalize", layers.Equalize, {"value_range": (0, 255)}),
-    ("Grayscale", layers.Grayscale, {"output_channels": 3}),
-    ("Invert", layers.Invert, {"value_range": (0, 255)}),
-    ("Normalize", layers.Normalize, {"value_range": (0, 255)}),
-    (
-        "RepeatedAugment",
-        layers.RepeatedAugment,
-        {
-            "layers": [
-                layers.RandomColorJitter(
-                    value_range=(0, 255), brightness_factor=(1.5, 1.5)
-                ),
-                layers.RandomColorJitter(
-                    value_range=(0, 255), contrast_factor=(1.5, 1.5)
-                ),
-            ]
-        },
+        True,
     ),
     (
         "CenterCrop",
         layers.CenterCrop,
         {"height": 2, "width": 2},
+        True,
     ),
     (
         "PadIfNeeded",
         layers.PadIfNeeded,
         {"min_height": 2, "min_width": 2},
+        True,
     ),
     (
         "Resize",
         layers.Resize,
         {"height": 2, "width": 2},
+        True,
+    ),
+    (
+        "AutoContrast",
+        layers.AutoContrast,
+        {"value_range": (0, 255)},
+        True,
+    ),
+    (
+        "Equalize",
+        layers.Equalize,
+        {"value_range": (0, 255)},
+        True,
+    ),
+    (
+        "Grayscale",
+        layers.Grayscale,
+        {"output_channels": 3},
+        True,
+    ),
+    (
+        "Identity",
+        layers.Identity,
+        {},
+        True,
+    ),
+    (
+        "Invert",
+        layers.Invert,
+        {"value_range": (0, 255)},
+        True,
+    ),
+    (
+        "Normalize",
+        layers.Normalize,
+        {"value_range": (0, 255)},
+        True,
     ),
-    ("AutoContrast", layers.AutoContrast, {"value_range": (0, 255)}),
     (
         "Rescale",
         layers.Rescale,
         {"scale": 1.0 / 255.0},
+        True,
+    ),
+    (
+        "SanitizeBoundingBox",
+        layers.SanitizeBoundingBox,
+        {"min_size": 10},
+        True,
     ),
-    ("Identity", layers.Identity, {}),
 ]
 
 BUILD_IN_RUNTIME = [
     (
         "RandomApply",
         layers.RandomApply,
         {"name": "layer", "value": "single", "args": {}},
@@ -229,81 +325,119 @@
     (
         "RandomChoiceBatchwise",
         layers.RandomChoice,
         {"name": "layers", "value": "multiple", "args": {"batchwise": True}},
         layers.RandomChannelDropout,
         {},
     ),
+    (
+        "RepeatedAugment",
+        layers.RepeatedAugment,
+        {"name": "layers", "value": "multiple", "args": {}},
+        layers.RandomColorJitter,
+        {"value_range": (0, 255), "brightness_factor": (1.5, 1.5)},
+    ),
 ]
 
 
-class WithMixedPrecisionTest(tf.test.TestCase, parameterized.TestCase):
+class MixedPrecisionTest(tf.test.TestCase, parameterized.TestCase):
     def test_all_2d_aug_layers_included(self):
         base_cls = layers.VectorizedBaseRandomLayer
-        all_2d_aug_layers = inspect.getmembers(
-            augmentation,
-            predicate=inspect.isclass,
-        ) + inspect.getmembers(
-            preprocessing,
-            predicate=inspect.isclass,
+        cls_spaces = [augmentation, preprocessing]
+        all_2d_aug_layers = []
+        for cls_space in cls_spaces:
+            all_2d_aug_layers.extend(
+                inspect.getmembers(cls_space, predicate=inspect.isclass)
+            )
+        all_2d_aug_layer_names = set(
+            item[0]
+            for item in all_2d_aug_layers
+            if issubclass(item[1], base_cls)
         )
-        all_2d_aug_layers = [
-            item for item in all_2d_aug_layers if issubclass(item[1], base_cls)
-        ]
-        all_2d_aug_layer_names = set(item[0] for item in all_2d_aug_layers)
-        test_configs = set(item[0] for item in TEST_CONFIGURATIONS)
-        build_in_runtime = set(item[0] for item in BUILD_IN_RUNTIME)
-        all_test_conf_names = test_configs.union(build_in_runtime)
+
+        general_names = set(item[0] for item in GENERAL_TESTS)
+        build_names = set(item[0] for item in BUILD_IN_RUNTIME)
+        all_test_names = general_names.union(build_names)
 
         for name in all_2d_aug_layer_names:
-            self.assertIn(
-                name,
-                all_test_conf_names,
-                msg=f"{name} not found in TEST_CONFIGURATIONS",
-            )
+            self.assertIn(name, all_test_names, msg=f"{name} not found")
 
-    @parameterized.named_parameters(*TEST_CONFIGURATIONS)
-    def test_can_run_in_mixed_precision(self, layer_cls, args):
+    @parameterized.named_parameters(*GENERAL_TESTS)
+    def test_run_in_mixed_precision(self, layer_cls, args, is_bbox_compatible):
         keras.mixed_precision.set_global_policy("mixed_float16")
         images = tf.cast(
-            tf.random.uniform(shape=(4, 32, 32, 3)) * 255.0,
+            tf.random.uniform(shape=(2, 32, 32, 3)) * 255.0,
             dtype=tf.float64,
         )
         labels = tf.cast(
-            tf.random.uniform(shape=(4, 1)) * 10.0, dtype=tf.float64
+            tf.random.uniform(shape=(2, 1)) * 10.0, dtype=tf.float64
         )
-        layer = layer_cls(**args)
-        layer({IMAGES: images, LABELS: labels})
+        bounding_boxes = {
+            "boxes": tf.ragged.constant(
+                [
+                    [[10, 10, 20, 20], [100, 100, 150, 150]],
+                    [[200, 200, 400, 400]],
+                ],
+                dtype=tf.float32,
+            ),
+            "classes": tf.ragged.constant([[0, 1], [2]], dtype=tf.float32),
+        }
+        if is_bbox_compatible:
+            try:
+                layer = layer_cls(**args, bounding_box_format="xyxy")
+            except TypeError:
+                layer = layer_cls(**args)
+            inputs = {
+                IMAGES: images,
+                LABELS: labels,
+                BOUNDING_BOXES: bounding_boxes,
+            }
+        else:
+            layer = layer_cls(**args)
+            inputs = {IMAGES: images, LABELS: labels}
+
+        outputs = layer(inputs)
+
+        if is_bbox_compatible:
+            self.assertDTypeEqual(outputs[IMAGES], tf.float16)
+            dense_bounding_boxes = bounding_box.to_dense(
+                outputs[BOUNDING_BOXES]
+            )
+            self.assertDTypeEqual(dense_bounding_boxes["boxes"], tf.float16)
+        else:
+            self.assertDTypeEqual(outputs[IMAGES], tf.float16)
 
     @parameterized.named_parameters(*BUILD_IN_RUNTIME)
-    def test_can_run_in_mixed_precision_build_in_runtime(
-        self, layer_cls, args, build_layer, build_args
+    def test_run_in_mixed_precision_and_build_in_runtime(
+        self, layer_cls, args, build_layer_cls, build_args
     ):
         keras.mixed_precision.set_global_policy("mixed_float16")
         images = tf.cast(
             tf.random.uniform(shape=(4, 32, 32, 3)) * 255.0,
             dtype=tf.float64,
         )
         labels = tf.cast(
             tf.random.uniform(shape=(4, 1)) * 10.0, dtype=tf.float64
         )
         name = args["name"]
         value = args["value"]
         other_args = args["args"]
         if value == "single":
-            build_layers = build_layer(**build_args)
+            build_layers = build_layer_cls(**build_args)
         elif value == "multiple":
             build_layers = [
-                build_layer(**build_args),
-                build_layer(**build_args),
-                build_layer(**build_args),
+                build_layer_cls(**build_args),
+                build_layer_cls(**build_args),
             ]
         else:
             raise NotImplementedError()
         args = {name: build_layers, **other_args}
         layer = layer_cls(**args)
-        layer({IMAGES: images, LABELS: labels})
+
+        outputs = layer({IMAGES: images, LABELS: labels})
+
+        self.assertDTypeEqual(outputs[IMAGES], tf.float16)
 
     @classmethod
     def tearDownClass(cls) -> None:
         # Do not affect other tests
         keras.mixed_precision.set_global_policy("float32")
```

## keras_aug/layers/__internal__/output_common_test.py

```diff
@@ -1,301 +1,605 @@
+import copy
 import inspect
 
 import tensorflow as tf
 from absl.testing import parameterized
 
 from keras_aug import layers
 from keras_aug.layers import augmentation
 from keras_aug.layers import preprocessing
+from keras_aug.utils.augmentation import BOUNDING_BOXES
 from keras_aug.utils.augmentation import IMAGES
 from keras_aug.utils.augmentation import LABELS
 
-CONSISTENT_OUTPUTS_LAYERS = [
-    ("AugMix", layers.AugMix, {"value_range": (0, 255)}),
+SEED = 2025
+#   (
+#       name,
+#       layer_cls,
+#       args,
+#       is_bbox_compatible,
+#   )
+# all configurations should be expanded for readability
+GENERAL_TESTS = [
+    (
+        "AugMix",
+        layers.AugMix,
+        {"value_range": (0, 255)},
+        False,
+    ),
     (
         "RandAugment",
         layers.RandAugment,
-        {"value_range": (0, 255), "seed": 2023},
+        {"value_range": (0, 255)},
+        True,
     ),
     (
         "TrivialAugmentWide",
         layers.TrivialAugmentWide,
         {"value_range": (0, 255)},
+        True,
     ),
     (
         "RandomAffine",
         layers.RandomAffine,
         {
             "rotation_factor": 10,
             "translation_height_factor": 0.1,
             "translation_width_factor": 0.1,
             "zoom_height_factor": 0.1,
             "zoom_width_factor": 0.1,
             "shear_height_factor": 0.1,
             "shear_width_factor": 0.1,
         },
+        True,
+    ),
+    (
+        "RandomCrop",
+        layers.RandomCrop,
+        {"height": 2, "width": 2},
+        True,
+    ),
+    (
+        "RandomCropAndResize",
+        layers.RandomCropAndResize,
+        {
+            "height": 2,
+            "width": 2,
+            "crop_area_factor": (0.8, 1.0),
+            "aspect_ratio_factor": (3 / 4, 4 / 3),
+        },
+        True,
+    ),
+    (
+        "RandomFlip",
+        layers.RandomFlip,
+        {"mode": "horizontal_and_vertical"},
+        True,
+    ),
+    (
+        "RandomResize",
+        layers.RandomResize,
+        {"heights": [2]},
+        True,
+    ),
+    (
+        "RandomRotate",
+        layers.RandomRotate,
+        {"factor": 10},
+        True,
+    ),
+    (
+        "RandomZoomAndCrop",
+        layers.RandomZoomAndCrop,
+        {"height": 2, "width": 2, "scale_factor": (0.8, 1.25)},
+        True,
+    ),
+    (
+        "ChannelShuffle",
+        layers.ChannelShuffle,
+        {"groups": 3},
+        True,
+    ),
+    (
+        "RandomBlur",
+        layers.RandomBlur,
+        {"factor": (3, 7)},
+        True,
     ),
-    ("RandomFlip", layers.RandomFlip, {"mode": "horizontal"}),
-    ("RandomRotate", layers.RandomRotate, {"factor": 10}),
-    ("ChannelShuffle", layers.ChannelShuffle, {"groups": 3}),
-    ("RandomBlur", layers.RandomBlur, {"factor": (3, 7)}),
     (
         "RandomChannelShift",
         layers.RandomChannelShift,
         {"value_range": (0, 255), "factor": 0.1},
+        True,
+    ),
+    (
+        "RandomCLAHE",
+        layers.RandomCLAHE,
+        {
+            "value_range": (0, 255),
+            "factor": (1, 100),
+            "tile_grid_size": (4, 4),
+            "seed": 2024,  # manually set
+        },
+        True,
     ),
-    ("RandomCLAHE", layers.RandomCLAHE, {"value_range": (0, 255)}),
     (
         "RandomColorJitter",
         layers.RandomColorJitter,
         {
             "value_range": (0, 255),
             "brightness_factor": 0.1,
             "contrast_factor": 0.1,
             "saturation_factor": 0.1,
             "hue_factor": 0.1,
         },
+        True,
     ),
     (
         "RandomGamma",
         layers.RandomGamma,
         {"value_range": (0, 255), "factor": 0.1},
+        True,
     ),
     (
         "RandomGaussianBlur",
         layers.RandomGaussianBlur,
         {"kernel_size": 3, "factor": 2.0},
+        True,
     ),
     (
         "RandomHSV",
         layers.RandomHSV,
         {
             "value_range": (0, 255),
             "hue_factor": 0.1,
             "saturation_factor": 0.1,
             "value_factor": 0.1,
         },
+        True,
     ),
     (
         "RandomJpegQuality",
         layers.RandomJpegQuality,
         {
             "value_range": (0, 255),
             "factor": (75, 100),
         },
+        True,
     ),
     (
         "RandomPosterize",
         layers.RandomPosterize,
         {"value_range": (0, 255), "factor": (5, 8)},
+        True,
     ),
     (
         "RandomSharpness",
         layers.RandomSharpness,
         {"value_range": (0, 255), "factor": 0.1},
+        True,
     ),
     (
         "RandomSolarize",
         layers.RandomSolarize,
         {
             "value_range": (0, 255),
             "threshold_factor": 10,
             "addition_factor": 10,
         },
+        True,
+    ),
+    (
+        "CutMix",
+        layers.CutMix,
+        {"alpha": 1.0},
+        False,
     ),
     (
         "MixUp",
         layers.MixUp,
         {},
+        True,
+    ),
+    (
+        "Mosaic",
+        layers.Mosaic,
+        {
+            "height": 100,
+            "width": 100,
+        },
+        True,
     ),
     (
         "RandomChannelDropout",
         layers.RandomChannelDropout,
         {},
+        True,
     ),
     (
         "RandomCutout",
         layers.RandomCutout,
         {"height_factor": 0.3, "width_factor": 0.3},
+        True,
     ),
     (
         "RandomErase",
         layers.RandomErase,
         {"area_factor": (0.02, 0.4), "aspect_ratio_factor": (0.3, 1.0 / 0.3)},
+        False,
     ),
     (
         "RandomGridMask",
         layers.RandomGridMask,
         {
             "size_factor": (0.5, 1.0),
             "ratio_factor": (0.6, 0.6),
             "rotation_factor": (-10, 10),
         },
+        True,
     ),
     (
         "RandomApply",
         layers.RandomApply,
-        {"layer": layers.RandomChannelDropout()},
+        {
+            "layer": layers.RandomColorJitter(
+                value_range=(0, 255), brightness_factor=(0.5, 1.5), seed=SEED
+            ),
+            "seed": 2024,
+        },
+        True,
     ),
     (
         "RandomChoice",
         layers.RandomChoice,
         {
             "layers": [
-                layers.RandomChannelDropout(),
-                layers.RandomChannelDropout(),
-            ]
+                layers.RandomColorJitter(
+                    value_range=(0, 255), brightness_factor=(0.5, 0.5)
+                ),
+                layers.RandomColorJitter(
+                    value_range=(0, 255), brightness_factor=(1.5, 1.5)
+                ),
+            ],
+            "seed": 2024,
         },
+        True,
     ),
     (
         "RepeatedAugment",
         layers.RepeatedAugment,
         {
             "layers": [
                 layers.RandomColorJitter(
                     value_range=(0, 255), brightness_factor=(1.5, 1.5)
                 ),
                 layers.RandomColorJitter(
                     value_range=(0, 255), contrast_factor=(1.5, 1.5)
                 ),
             ]
         },
+        True,
+    ),
+    (
+        "CenterCrop",
+        layers.CenterCrop,
+        {"height": 2, "width": 2},
+        True,
     ),
     (
         "PadIfNeeded",
         layers.PadIfNeeded,
         {"min_height": 2, "min_width": 2},
+        True,
     ),
-    ("AutoContrast", layers.AutoContrast, {"value_range": (0, 255)}),
-    ("Equalize", layers.Equalize, {"value_range": (0, 255)}),
-    ("Grayscale", layers.Grayscale, {"output_channels": 3}),
-    ("Invert", layers.Invert, {"value_range": (0, 255)}),
-    ("Normalize", layers.Normalize, {"value_range": (0, 255)}),
     (
-        "Rescale",
-        layers.Rescale,
-        {"scale": 1.0 / 255.0},
+        "Resize",
+        layers.Resize,
+        {"height": 2, "width": 2},
+        True,
     ),
-    ("Identity", layers.Identity, {}),
-]
-
-FORCE_DENSE_IMAGES_LAYERS = [
     (
-        "CenterCrop",
-        layers.CenterCrop,
-        {"height": 2, "width": 2},
+        "AutoContrast",
+        layers.AutoContrast,
+        {"value_range": (0, 255)},
+        True,
     ),
-    ("RandomCrop", layers.RandomCrop, {"height": 2, "width": 2}),
     (
-        "RandomCropAndResize",
-        layers.RandomCropAndResize,
-        {
-            "height": 2,
-            "width": 2,
-            "crop_area_factor": (0.8, 1.0),
-            "aspect_ratio_factor": (3 / 4, 4 / 3),
-        },
+        "Equalize",
+        layers.Equalize,
+        {"value_range": (0, 255)},
+        True,
     ),
-    ("RandomResize", layers.RandomResize, {"heights": [2]}),
     (
-        "RandomZoomAndCrop",
-        layers.RandomZoomAndCrop,
-        {"height": 2, "width": 2, "scale_factor": (0.8, 1.25)},
+        "Grayscale",
+        layers.Grayscale,
+        {"output_channels": 3},
+        True,
     ),
     (
-        "Resize",
-        layers.Resize,
-        {"height": 2, "width": 2},
+        "Identity",
+        layers.Identity,
+        {},
+        True,
     ),
     (
-        "Mosaic",
-        layers.Mosaic,
-        {
-            "height": 2,
-            "width": 2,
-        },
+        "Invert",
+        layers.Invert,
+        {"value_range": (0, 255)},
+        True,
+    ),
+    (
+        "Normalize",
+        layers.Normalize,
+        {"value_range": (0, 255)},
+        True,
+    ),
+    (
+        "Rescale",
+        layers.Rescale,
+        {"scale": 1.0 / 255.0},
+        True,
+    ),
+    (
+        "SanitizeBoundingBox",
+        layers.SanitizeBoundingBox,
+        {"min_size": 10},
+        True,
     ),
 ]
 
-NO_RAGGED_IMAGES_SUPPORT = [
-    ("CutMix", layers.CutMix, {"alpha": 1.0}),
+NO_PRESERVED_SHAPE = [
+    layers.RandomCrop,
+    layers.RandomCropAndResize,
+    layers.RandomResize,
+    layers.RandomZoomAndCrop,
+    layers.Mosaic,
+    layers.RepeatedAugment,
+    layers.CenterCrop,
+    layers.Resize,
+]
+
+NO_BFLOAT16 = [
+    # tf.raw_ops.ImageProjectiveTransformV3 is not supported with bfloat16
+    layers.AugMix,
+    layers.RandAugment,
+    layers.TrivialAugmentWide,
+    layers.RandomAffine,
+    layers.RandomCrop,
+    layers.RandomCropAndResize,
+    layers.RandomRotate,
+]
+
+NO_UINT8 = [
+    layers.RandAugment,  # stateless_random_uniform
+    layers.TrivialAugmentWide,  # stateless_random_uniform
+    layers.RandomAffine,  # stateless_random_uniform
+    layers.RandomCrop,  # stateless_random_uniform
+    layers.RandomRotate,  # stateless_random_uniform
+    layers.RandomZoomAndCrop,  # stateless_random_uniform
+    layers.RandomSharpness,  # stateless_random_uniform
+    layers.RandomSolarize,  # stateless_random_uniform
+    layers.CutMix,  # tf.convert_to_tensor
+    layers.MixUp,  # tf.convert_to_tensor
+    layers.Mosaic,  # stateless_random_uniform
+    layers.RandomCutout,  # tf.where with -1 (invalid bbox)
+    layers.RandomErase,  # stateless_random_uniform
+    layers.RandomGridMask,  # tf.sqrt
+    layers.RandomHSV,  # stateless_random_uniform
+    layers.RandomChannelShift,  # stateless_random_uniform
+    layers.RandomColorJitter,  # stateless_random_uniform
+    layers.RandomGamma,  # stateless_random_uniform
+    layers.RandomGaussianBlur,  # tf.nn.depthwise_conv2d
+    layers.RandomJpegQuality,  # preprocessing_utils.transform_value_range
+    layers.AutoContrast,  # tf.convert_to_tensor
+    layers.Grayscale,  # tf.mul
+    layers.Normalize,  # mean, std
+]
+
+SKIP_DTYPE = [
+    # it is hard to change dtype in runtime
+    layers.RandomApply,
+    layers.RepeatedAugment,
+]
+
+ALWAYS_SAME_OUTPUT_WITHIN_BATCH_LAYERS = [
+    layers.RandomResize,  # same size in the batch
+    layers.CutMix,  # cannot test CutMix with same images
+    layers.MixUp,  # cannot test MixUp with same images
+    layers.CenterCrop,
+    layers.PadIfNeeded,
+    layers.Resize,
+    layers.AutoContrast,
+    layers.Equalize,
+    layers.Grayscale,
+    layers.Identity,
+    layers.Invert,
+    layers.Normalize,
+    layers.Rescale,
+    layers.SanitizeBoundingBox,
 ]
 
 
-class WithRaggedImageTest(tf.test.TestCase, parameterized.TestCase):
+class OutputCommonTest(tf.test.TestCase, parameterized.TestCase):
     def test_all_2d_aug_layers_included(self):
         base_cls = layers.VectorizedBaseRandomLayer
-        all_2d_aug_layers = inspect.getmembers(
-            augmentation,
-            predicate=inspect.isclass,
-        ) + inspect.getmembers(
-            preprocessing,
-            predicate=inspect.isclass,
-        )
-        all_2d_aug_layers = [
-            item for item in all_2d_aug_layers if issubclass(item[1], base_cls)
-        ]
-        all_2d_aug_layer_names = set(item[0] for item in all_2d_aug_layers)
-        cosistent_names = set(item[0] for item in CONSISTENT_OUTPUTS_LAYERS)
-        force_dense_names = set(item[0] for item in FORCE_DENSE_IMAGES_LAYERS)
-        no_ragged_names = set(item[0] for item in NO_RAGGED_IMAGES_SUPPORT)
-        all_test_conf_names = cosistent_names.union(force_dense_names).union(
-            no_ragged_names
+        cls_spaces = [augmentation, preprocessing]
+        all_2d_aug_layers = []
+        for cls_space in cls_spaces:
+            all_2d_aug_layers.extend(
+                inspect.getmembers(cls_space, predicate=inspect.isclass)
+            )
+        all_2d_aug_layer_names = set(
+            item[0]
+            for item in all_2d_aug_layers
+            if issubclass(item[1], base_cls)
         )
 
+        general_names = set(item[0] for item in GENERAL_TESTS)
+        all_test_names = general_names
+
         for name in all_2d_aug_layer_names:
-            self.assertIn(
-                name,
-                all_test_conf_names,
-                msg=f"{name} not found in TEST_CONFIGURATIONS",
-            )
+            self.assertIn(name, all_test_names, msg=f"{name} not found")
 
-    @parameterized.named_parameters(*CONSISTENT_OUTPUTS_LAYERS)
-    def test_preserves_ragged_status(self, layer_cls, args):
-        layer = layer_cls(**args)
-        # MixUp needs two same shape image
-        if layer_cls == layers.MixUp:
-            images = tf.ragged.stack(
+    @parameterized.named_parameters(*GENERAL_TESTS)
+    def test_preserves_output_shape(self, layer_cls, args, is_bbox_compatible):
+        images = tf.random.uniform(shape=(2, 16, 16, 3), seed=SEED) * 255.0
+        labels = tf.random.uniform(shape=(2, 1), seed=SEED) * 10.0
+        bounding_boxes = {
+            "boxes": tf.ragged.constant(
                 [
-                    tf.ones((8, 8, 3)),
-                    tf.ones((8, 8, 3)),
-                ]
-            )
-        else:
-            images = tf.ragged.stack(
+                    [[0, 0, 2, 2], [0, 0, 16, 16]],
+                    [[2, 5, 1, 4]],
+                ],
+                dtype=tf.float32,
+            ),
+            "classes": tf.ragged.constant(
                 [
-                    tf.ones((5, 5, 3)),
-                    tf.ones((8, 8, 3)),
-                ]
-            )
-        labels = tf.ragged.stack(
-            [
-                tf.ones((1,)),
-                tf.ones((1,)),
-            ]
-        )
-        inputs = {IMAGES: images, LABELS: labels}
+                    [0, 1],
+                    [2],
+                ],
+                dtype=tf.float32,
+            ),
+        }
+        if is_bbox_compatible:
+            try:
+                layer = layer_cls(**args, bounding_box_format="xyxy")
+            except TypeError:
+                layer = layer_cls(**args)
+            inputs = {
+                IMAGES: images,
+                LABELS: labels,
+                BOUNDING_BOXES: bounding_boxes,
+            }
+        else:
+            layer = layer_cls(**args)
+            inputs = {IMAGES: images, LABELS: labels}
 
         outputs = layer(inputs)
 
-        self.assertTrue(isinstance(outputs[IMAGES], tf.RaggedTensor))
+        if layer_cls not in NO_PRESERVED_SHAPE:
+            self.assertEqual(images.shape, outputs[IMAGES].shape)
+        else:
+            self.assertNotEqual(images.shape, outputs[IMAGES].shape)
 
-    @parameterized.named_parameters(*FORCE_DENSE_IMAGES_LAYERS)
-    def test_force_dense_images(self, layer_cls, args):
-        layer = layer_cls(**args)
-        images = tf.ragged.stack(
-            [
-                tf.ones((5, 5, 3)),
-                tf.ones((8, 8, 3)),
-            ]
-        )
-        labels = tf.ragged.stack(
-            [
-                tf.ones((1,)),
-                tf.ones((1,)),
-            ]
-        )
-        inputs = {IMAGES: images, LABELS: labels}
+    @parameterized.named_parameters(*GENERAL_TESTS)
+    def test_layer_dtypes(self, layer_cls, args, is_bbox_compatible):
+        if layer_cls in SKIP_DTYPE:
+            return
+        images = tf.random.uniform(shape=(2, 16, 16, 3), seed=SEED) * 255.0
+        labels = tf.random.uniform(shape=(2, 1), seed=SEED) * 10.0
+        bounding_boxes = {
+            "boxes": tf.ragged.constant(
+                [
+                    [[0, 0, 2, 2], [0, 0, 16, 16]],
+                    [[2, 5, 1, 4]],
+                ],
+                dtype=tf.float32,
+            ),
+            "classes": tf.ragged.constant(
+                [
+                    [0, 1],
+                    [2],
+                ],
+                dtype=tf.float32,
+            ),
+        }
+        copied_args = copy.deepcopy(args)
+        if is_bbox_compatible:
+            try:
+                layer_cls(**copied_args, bounding_box_format="xyxy")
+                copied_args["bounding_box_format"] = "xyxy"
+            except TypeError:
+                pass
+            inputs = {
+                IMAGES: images,
+                LABELS: labels,
+                BOUNDING_BOXES: bounding_boxes,
+            }
+        else:
+            inputs = {IMAGES: images, LABELS: labels}
 
-        outputs = layer(inputs)
+        # float64
+        layer = layer_cls(**copied_args, dtype=tf.float64)
+        results = layer(inputs)
+        self.assertDTypeEqual(results[IMAGES], tf.float64)
+
+        # float32
+        layer = layer_cls(**copied_args)
+        results = layer(inputs)
+        self.assertDTypeEqual(results[IMAGES], tf.float32)
+
+        # float16
+        layer = layer_cls(**copied_args, dtype=tf.float16)
+        results = layer(inputs)
+        self.assertDTypeEqual(results[IMAGES], tf.float16)
+
+        # bfloat16
+        if layer_cls not in NO_BFLOAT16:
+            layer = layer_cls(**copied_args, dtype=tf.bfloat16)
+            results = layer(inputs)
+            self.assertDTypeEqual(results[IMAGES], tf.bfloat16)
+        else:
+            with self.assertRaises(tf.errors.InvalidArgumentError):
+                layer = layer_cls(**copied_args, dtype=tf.bfloat16)
+                layer(inputs)
+
+        # uint8
+        if layer_cls not in NO_UINT8:
+            layer = layer_cls(**copied_args, dtype=tf.uint8)
+            results = layer(inputs)
+            self.assertDTypeEqual(results[IMAGES], tf.uint8)
+        else:
+            with self.assertRaises(
+                (TypeError, ValueError, tf.errors.InvalidArgumentError)
+            ):
+                layer = layer_cls(**copied_args, dtype=tf.uint8)
+                layer(inputs)
+
+    @parameterized.named_parameters(*GENERAL_TESTS)
+    def test_independence_on_batched(self, layer_cls, args, is_bbox_compatible):
+        image = tf.random.uniform((16, 16, 3), seed=SEED) * 255.0
+        label = tf.random.uniform((1,), seed=SEED) * 255.0
+        batched_images = tf.stack((image, image, image, image, image), axis=0)
+        batched_labels = tf.stack((label, label, label, label, label), axis=0)
+        batched_bounding_boxes = {
+            "boxes": tf.ragged.constant(
+                [
+                    [[10, 10, 20, 20], [100, 100, 150, 150]],
+                    [[10, 10, 20, 20], [100, 100, 150, 150]],
+                    [[10, 10, 20, 20], [100, 100, 150, 150]],
+                    [[10, 10, 20, 20], [100, 100, 150, 150]],
+                    [[10, 10, 20, 20], [100, 100, 150, 150]],
+                ],
+                dtype=tf.float32,
+            ),
+            "classes": tf.ragged.constant(
+                [[0, 1], [0, 1], [0, 1], [0, 1], [0, 1]], dtype=tf.float32
+            ),
+        }
+        copied_args = copy.deepcopy(args)
+        if is_bbox_compatible:
+            try:
+                layer_cls(**copied_args, bounding_box_format="xyxy")
+                copied_args["bounding_box_format"] = "xyxy"
+            except TypeError:
+                pass
+            inputs = {
+                IMAGES: batched_images,
+                LABELS: batched_labels,
+                BOUNDING_BOXES: batched_bounding_boxes,
+            }
+        else:
+            inputs = {IMAGES: batched_images, LABELS: batched_labels}
+        try:
+            layer_cls(**copied_args, seed=SEED)
+            copied_args["seed"] = SEED
+        except TypeError:
+            pass
+        layer = layer_cls(**copied_args)
 
-        self.assertTrue(isinstance(outputs[IMAGES], tf.Tensor))
+        results = layer(inputs)
+
+        if layer_cls not in ALWAYS_SAME_OUTPUT_WITHIN_BATCH_LAYERS:
+            self.assertNotAllClose(results[IMAGES][0], results[IMAGES][1])
+        else:
+            self.assertAllClose(results[IMAGES][0], results[IMAGES][1])
```

## keras_aug/layers/__internal__/with_ragged_image_test.py

```diff
@@ -2,304 +2,457 @@
 
 import tensorflow as tf
 from absl.testing import parameterized
 
 from keras_aug import layers
 from keras_aug.layers import augmentation
 from keras_aug.layers import preprocessing
+from keras_aug.utils.augmentation import BOUNDING_BOXES
 from keras_aug.utils.augmentation import IMAGES
 from keras_aug.utils.augmentation import LABELS
 
+#   (
+#       name,
+#       layer_cls,
+#       args,
+#       is_bbox_compatible,
+#   )
+# all configurations should be expanded for readability
 CONSISTENT_OUTPUTS_LAYERS = [
-    ("AugMix", layers.AugMix, {"value_range": (0, 255)}),
+    (
+        "AugMix",
+        layers.AugMix,
+        {"value_range": (0, 255)},
+        False,
+    ),
     (
         "RandAugment",
         layers.RandAugment,
         {"value_range": (0, 255), "seed": 2023},
+        True,
     ),
     (
         "TrivialAugmentWide",
         layers.TrivialAugmentWide,
         {"value_range": (0, 255)},
+        True,
     ),
     (
         "RandomAffine",
         layers.RandomAffine,
         {
             "rotation_factor": 10,
             "translation_height_factor": 0.1,
             "translation_width_factor": 0.1,
             "zoom_height_factor": 0.1,
             "zoom_width_factor": 0.1,
             "shear_height_factor": 0.1,
             "shear_width_factor": 0.1,
         },
+        True,
+    ),
+    (
+        "RandomFlip",
+        layers.RandomFlip,
+        {"mode": "horizontal"},
+        True,
+    ),
+    (
+        "RandomRotate",
+        layers.RandomRotate,
+        {"factor": 10},
+        True,
+    ),
+    (
+        "ChannelShuffle",
+        layers.ChannelShuffle,
+        {"groups": 3},
+        True,
+    ),
+    (
+        "RandomBlur",
+        layers.RandomBlur,
+        {"factor": (3, 7)},
+        True,
     ),
-    ("RandomFlip", layers.RandomFlip, {"mode": "horizontal"}),
-    ("RandomRotate", layers.RandomRotate, {"factor": 10}),
-    ("ChannelShuffle", layers.ChannelShuffle, {"groups": 3}),
-    ("RandomBlur", layers.RandomBlur, {"factor": (3, 7)}),
     (
         "RandomChannelShift",
         layers.RandomChannelShift,
         {"value_range": (0, 255), "factor": 0.1},
+        True,
+    ),
+    (
+        "RandomCLAHE",
+        layers.RandomCLAHE,
+        {"value_range": (0, 255)},
+        True,
     ),
-    ("RandomCLAHE", layers.RandomCLAHE, {"value_range": (0, 255)}),
     (
         "RandomColorJitter",
         layers.RandomColorJitter,
         {
             "value_range": (0, 255),
             "brightness_factor": 0.1,
             "contrast_factor": 0.1,
             "saturation_factor": 0.1,
             "hue_factor": 0.1,
         },
+        True,
     ),
     (
         "RandomGamma",
         layers.RandomGamma,
         {"value_range": (0, 255), "factor": 0.1},
+        True,
     ),
     (
         "RandomGaussianBlur",
         layers.RandomGaussianBlur,
         {"kernel_size": 3, "factor": 2.0},
+        True,
     ),
     (
         "RandomHSV",
         layers.RandomHSV,
         {
             "value_range": (0, 255),
             "hue_factor": 0.1,
             "saturation_factor": 0.1,
             "value_factor": 0.1,
         },
+        True,
     ),
     (
         "RandomJpegQuality",
         layers.RandomJpegQuality,
         {
             "value_range": (0, 255),
             "factor": (75, 100),
         },
+        True,
     ),
     (
         "RandomPosterize",
         layers.RandomPosterize,
         {"value_range": (0, 255), "factor": (5, 8)},
+        True,
     ),
     (
         "RandomSharpness",
         layers.RandomSharpness,
         {"value_range": (0, 255), "factor": 0.1},
+        True,
     ),
     (
         "RandomSolarize",
         layers.RandomSolarize,
         {
             "value_range": (0, 255),
             "threshold_factor": 10,
             "addition_factor": 10,
         },
-    ),
-    (
-        "MixUp",
-        layers.MixUp,
-        {},
+        True,
     ),
     (
         "RandomChannelDropout",
         layers.RandomChannelDropout,
         {},
+        True,
     ),
     (
         "RandomCutout",
         layers.RandomCutout,
         {"height_factor": 0.3, "width_factor": 0.3},
+        True,
     ),
     (
         "RandomErase",
         layers.RandomErase,
         {"area_factor": (0.02, 0.4), "aspect_ratio_factor": (0.3, 1.0 / 0.3)},
+        False,
     ),
     (
         "RandomGridMask",
         layers.RandomGridMask,
         {
             "size_factor": (0.5, 1.0),
             "ratio_factor": (0.6, 0.6),
             "rotation_factor": (-10, 10),
         },
+        True,
     ),
     (
         "RandomApply",
         layers.RandomApply,
         {"layer": layers.RandomChannelDropout()},
+        True,
     ),
     (
         "RandomChoice",
         layers.RandomChoice,
         {
             "layers": [
                 layers.RandomChannelDropout(),
                 layers.RandomChannelDropout(),
             ]
         },
+        True,
     ),
     (
         "RepeatedAugment",
         layers.RepeatedAugment,
         {
             "layers": [
                 layers.RandomColorJitter(
                     value_range=(0, 255), brightness_factor=(1.5, 1.5)
                 ),
                 layers.RandomColorJitter(
                     value_range=(0, 255), contrast_factor=(1.5, 1.5)
                 ),
             ]
         },
+        True,
     ),
     (
         "PadIfNeeded",
         layers.PadIfNeeded,
         {"min_height": 2, "min_width": 2},
+        True,
+    ),
+    (
+        "AutoContrast",
+        layers.AutoContrast,
+        {"value_range": (0, 255)},
+        True,
+    ),
+    (
+        "Equalize",
+        layers.Equalize,
+        {"value_range": (0, 255)},
+        True,
+    ),
+    (
+        "Grayscale",
+        layers.Grayscale,
+        {"output_channels": 3},
+        True,
+    ),
+    (
+        "Identity",
+        layers.Identity,
+        {},
+        True,
+    ),
+    (
+        "Invert",
+        layers.Invert,
+        {"value_range": (0, 255)},
+        True,
+    ),
+    (
+        "Normalize",
+        layers.Normalize,
+        {"value_range": (0, 255)},
+        True,
     ),
-    ("AutoContrast", layers.AutoContrast, {"value_range": (0, 255)}),
-    ("Equalize", layers.Equalize, {"value_range": (0, 255)}),
-    ("Grayscale", layers.Grayscale, {"output_channels": 3}),
-    ("Invert", layers.Invert, {"value_range": (0, 255)}),
-    ("Normalize", layers.Normalize, {"value_range": (0, 255)}),
     (
         "Rescale",
         layers.Rescale,
         {"scale": 1.0 / 255.0},
+        True,
+    ),
+    (
+        "SanitizeBoundingBox",
+        layers.SanitizeBoundingBox,
+        {"min_size": 10},
+        True,
     ),
-    ("Identity", layers.Identity, {}),
 ]
 
 FORCE_DENSE_IMAGES_LAYERS = [
     (
-        "CenterCrop",
-        layers.CenterCrop,
+        "RandomCrop",
+        layers.RandomCrop,
         {"height": 2, "width": 2},
+        True,
     ),
-    ("RandomCrop", layers.RandomCrop, {"height": 2, "width": 2}),
     (
         "RandomCropAndResize",
         layers.RandomCropAndResize,
         {
             "height": 2,
             "width": 2,
             "crop_area_factor": (0.8, 1.0),
             "aspect_ratio_factor": (3 / 4, 4 / 3),
         },
+        True,
+    ),
+    (
+        "RandomResize",
+        layers.RandomResize,
+        {"heights": [2]},
+        True,
     ),
-    ("RandomResize", layers.RandomResize, {"heights": [2]}),
     (
         "RandomZoomAndCrop",
         layers.RandomZoomAndCrop,
         {"height": 2, "width": 2, "scale_factor": (0.8, 1.25)},
-    ),
-    (
-        "Resize",
-        layers.Resize,
-        {"height": 2, "width": 2},
+        True,
     ),
     (
         "Mosaic",
         layers.Mosaic,
         {
             "height": 2,
             "width": 2,
         },
+        True,
+    ),
+    (
+        "CenterCrop",
+        layers.CenterCrop,
+        {"height": 2, "width": 2},
+        True,
+    ),
+    (
+        "Resize",
+        layers.Resize,
+        {"height": 2, "width": 2},
+        True,
     ),
 ]
 
 NO_RAGGED_IMAGES_SUPPORT = [
     (
         "CutMix",
         layers.CutMix,
         {"alpha": 1.0},
+        False,
+    ),
+    (
+        "MixUp",
+        layers.MixUp,
+        {},
+        True,
     ),
 ]
 
 
 class WithRaggedImageTest(tf.test.TestCase, parameterized.TestCase):
     def test_all_2d_aug_layers_included(self):
         base_cls = layers.VectorizedBaseRandomLayer
-        all_2d_aug_layers = inspect.getmembers(
-            augmentation,
-            predicate=inspect.isclass,
-        ) + inspect.getmembers(
-            preprocessing,
-            predicate=inspect.isclass,
+        cls_spaces = [augmentation, preprocessing]
+        all_2d_aug_layers = []
+        for cls_space in cls_spaces:
+            all_2d_aug_layers.extend(
+                inspect.getmembers(cls_space, predicate=inspect.isclass)
+            )
+        all_2d_aug_layer_names = set(
+            item[0]
+            for item in all_2d_aug_layers
+            if issubclass(item[1], base_cls)
         )
-        all_2d_aug_layers = [
-            item for item in all_2d_aug_layers if issubclass(item[1], base_cls)
-        ]
-        all_2d_aug_layer_names = set(item[0] for item in all_2d_aug_layers)
+
         cosistent_names = set(item[0] for item in CONSISTENT_OUTPUTS_LAYERS)
-        force_dense_names = set(item[0] for item in FORCE_DENSE_IMAGES_LAYERS)
+        dense_names = set(item[0] for item in FORCE_DENSE_IMAGES_LAYERS)
         no_ragged_names = set(item[0] for item in NO_RAGGED_IMAGES_SUPPORT)
-        all_test_conf_names = cosistent_names.union(force_dense_names).union(
+        all_test_names = cosistent_names.union(dense_names).union(
             no_ragged_names
         )
 
         for name in all_2d_aug_layer_names:
-            self.assertIn(
-                name,
-                all_test_conf_names,
-                msg=f"{name} not found in TEST_CONFIGURATIONS",
-            )
+            self.assertIn(name, all_test_names, msg=f"{name} not found")
 
     @parameterized.named_parameters(*CONSISTENT_OUTPUTS_LAYERS)
-    def test_preserves_ragged_status(self, layer_cls, args):
-        layer = layer_cls(**args)
-        # MixUp needs two same shape image
-        if layer_cls == layers.MixUp:
-            images = tf.ragged.stack(
+    def test_consistent_images(self, layer_cls, args, is_bbox_compatible):
+        images = tf.ragged.stack([tf.ones((5, 5, 3)), tf.ones((8, 8, 3))])
+        labels = tf.ragged.stack([tf.ones((1,)), tf.ones((1,))])
+        bounding_boxes = {
+            "boxes": tf.ragged.constant(
                 [
-                    tf.ones((8, 8, 3)),
-                    tf.ones((8, 8, 3)),
-                ]
-            )
+                    [[10, 10, 20, 20], [100, 100, 150, 150]],
+                    [[200, 200, 400, 400]],
+                ],
+                dtype=tf.float32,
+            ),
+            "classes": tf.ragged.constant([[0, 1], [2]], dtype=tf.float32),
+        }
+        if is_bbox_compatible:
+            try:
+                layer = layer_cls(**args, bounding_box_format="xyxy")
+            except TypeError:
+                layer = layer_cls(**args)
+            inputs = {
+                IMAGES: images,
+                LABELS: labels,
+                BOUNDING_BOXES: bounding_boxes,
+            }
         else:
-            images = tf.ragged.stack(
-                [
-                    tf.ones((5, 5, 3)),
-                    tf.ones((8, 8, 3)),
-                ]
-            )
-        labels = tf.ragged.stack(
-            [
-                tf.ones((1,)),
-                tf.ones((1,)),
-            ]
-        )
-        inputs = {IMAGES: images, LABELS: labels}
+            layer = layer_cls(**args)
+            inputs = {IMAGES: images, LABELS: labels}
 
         outputs = layer(inputs)
 
         self.assertTrue(isinstance(outputs[IMAGES], tf.RaggedTensor))
 
     @parameterized.named_parameters(*FORCE_DENSE_IMAGES_LAYERS)
-    def test_force_dense_images(self, layer_cls, args):
-        layer = layer_cls(**args)
-        images = tf.ragged.stack(
-            [
-                tf.ones((5, 5, 3)),
-                tf.ones((8, 8, 3)),
-            ]
-        )
-        labels = tf.ragged.stack(
-            [
-                tf.ones((1,)),
-                tf.ones((1,)),
-            ]
-        )
-        inputs = {IMAGES: images, LABELS: labels}
+    def test_force_dense_images(self, layer_cls, args, is_bbox_compatible):
+        images = tf.ragged.stack([tf.ones((5, 5, 3)), tf.ones((8, 8, 3))])
+        labels = tf.ragged.stack([tf.ones((1,)), tf.ones((1,))])
+        bounding_boxes = {
+            "boxes": tf.ragged.constant(
+                [
+                    [[10, 10, 20, 20], [100, 100, 150, 150]],
+                    [[200, 200, 400, 400]],
+                ],
+                dtype=tf.float32,
+            ),
+            "classes": tf.ragged.constant([[0, 1], [2]], dtype=tf.float32),
+        }
+        if is_bbox_compatible:
+            try:
+                layer = layer_cls(**args, bounding_box_format="xyxy")
+            except TypeError:
+                layer = layer_cls(**args)
+            inputs = {
+                IMAGES: images,
+                LABELS: labels,
+                BOUNDING_BOXES: bounding_boxes,
+            }
+        else:
+            layer = layer_cls(**args)
+            inputs = {IMAGES: images, LABELS: labels}
 
         outputs = layer(inputs)
 
         self.assertTrue(isinstance(outputs[IMAGES], tf.Tensor))
+
+    @parameterized.named_parameters(*NO_RAGGED_IMAGES_SUPPORT)
+    def test_no_ragged_images(self, layer_cls, args, is_bbox_compatible):
+        images = tf.ragged.stack([tf.ones((5, 5, 3)), tf.ones((8, 8, 3))])
+        labels = tf.ragged.stack([tf.ones((1,)), tf.ones((1,))])
+        bounding_boxes = {
+            "boxes": tf.ragged.constant(
+                [
+                    [[10, 10, 20, 20], [100, 100, 150, 150]],
+                    [[200, 200, 400, 400]],
+                ],
+                dtype=tf.float32,
+            ),
+            "classes": tf.ragged.constant([[0, 1], [2]], dtype=tf.float32),
+        }
+        if is_bbox_compatible:
+            try:
+                layer = layer_cls(**args, bounding_box_format="xyxy")
+            except TypeError:
+                layer = layer_cls(**args)
+            inputs = {
+                IMAGES: images,
+                LABELS: labels,
+                BOUNDING_BOXES: bounding_boxes,
+            }
+        else:
+            layer = layer_cls(**args)
+            inputs = {IMAGES: images, LABELS: labels}
+
+        with self.assertRaises(ValueError):
+            layer(inputs)
```

## keras_aug/layers/augmentation/auto/aug_mix.py

```diff
@@ -78,16 +78,20 @@
         # distribution
         self.beta_dist = tfp.distributions.Beta(self.alpha, self.alpha)
         self.dirichlet_dist = tfp.distributions.Dirichlet(
             tf.ones([self.num_chains]) * self.alpha
         )
 
         # initialize layers
-        self.auto_contrast = layers.AutoContrast(value_range=self.value_range)
-        self.equalize = layers.Equalize(value_range=self.value_range)
+        self.auto_contrast = layers.AutoContrast(
+            value_range=self.value_range, dtype=self.compute_dtype
+        )
+        self.equalize = layers.Equalize(
+            value_range=self.value_range, dtype=self.compute_dtype
+        )
 
     def get_random_transformation_batch(self, batch_size, **kwargs):
         # sample from dirichlet
         seed = tf.cast(
             self._random_generator.make_seed_for_stateless_op(), dtype=tf.int32
         )
         chain_mixing_weights = self.dirichlet_dist.sample(
@@ -112,42 +116,44 @@
         )
         images = self.augment_images(
             images=images, transformations=transformations, **kwargs
         )
         return tf.squeeze(images, axis=0)
 
     def augment_images(self, images, transformations, **kwargs):
+        original_shape = images.shape
         images = preprocessing_utils.transform_value_range(
-            images, self.value_range, (0, 255), self.compute_dtype
+            images, self.value_range, (0, 255), dtype=self.compute_dtype
         )
         inputs_for_aug_mix_single_image = {
             IMAGES: images,
             "transformations": transformations,
         }
         images = tf.map_fn(
             self.aug_mix_single_image,
             inputs_for_aug_mix_single_image,
             fn_output_signature=self.compute_dtype,
         )
         images = preprocessing_utils.transform_value_range(
             images, (0, 255), self.value_range, self.compute_dtype
         )
+        images = tf.ensure_shape(images, shape=original_shape)
         return images
 
     def augment_labels(self, labels, transformations, **kwargs):
         return labels
 
     def aug_mix_single_image(self, inputs):
         image = inputs.get(IMAGES, None)
         transformation = inputs.get("transformations", None)
 
         chain_mixing_weights = transformation["chain_mixing_weights"]
         weight_sample = transformation["weight_sample"]
 
-        result = tf.zeros_like(image)
+        result = tf.zeros_like(image, dtype=image.dtype)
         curr_chain = tf.constant([0], dtype=tf.int32)
         image, chain_mixing_weights, curr_chain, result = tf.while_loop(
             lambda image, chain_mixing_weights, curr_chain, result: tf.less(
                 curr_chain, self.num_chains
             ),
             self.loop_on_width,
             [image, chain_mixing_weights, curr_chain, result],
@@ -235,15 +241,16 @@
         ori_dtype = image.dtype
         bits = tf.cast(self.severity() * 3, tf.int32)
         shift = tf.cast(4 - bits + 1, tf.uint8)
         image = tf.cast(image, tf.uint8)
         image = tf.bitwise.left_shift(
             tf.bitwise.right_shift(image, shift), shift
         )
-        return tf.cast(image, dtype=ori_dtype)
+        image = tf.cast(image, dtype=ori_dtype)
+        return image
 
     def rotate(self, image):
         angle = tf.expand_dims(
             self.severity(shape=(1,), dtype=tf.float32) * 30, axis=0
         )
         height = tf.expand_dims(tf.shape(image)[H_AXIS : H_AXIS + 1], axis=0)
         width = tf.expand_dims(tf.shape(image)[W_AXIS : W_AXIS + 1], axis=0)
```

## keras_aug/layers/augmentation/auto/rand_augment.py

```diff
@@ -1,20 +1,22 @@
 from functools import partial
 
 import tensorflow as tf
+from keras_cv import bounding_box
 from keras_cv.utils import preprocessing as preprocessing_utils
 from tensorflow import keras
 
 from keras_aug import layers
 from keras_aug.core import NormalFactorSampler
 from keras_aug.core import SignedNormalFactorSampler
 from keras_aug.layers.base.vectorized_base_random_layer import (
     VectorizedBaseRandomLayer,
 )
 from keras_aug.utils import augmentation as augmentation_utils
+from keras_aug.utils.augmentation import BOUNDING_BOXES
 from keras_aug.utils.augmentation import IMAGES
 
 
 @keras.utils.register_keras_serializable(package="keras_aug")
 class RandAugment(VectorizedBaseRandomLayer):
     """RandAugment performs the Rand Augment operation on input images.
 
@@ -179,77 +181,81 @@
                 )
             elif key == "sharpness":
                 aug_layers.append(
                     layers.RandomSharpness(
                         **policy[key], value_range=(0, 255), seed=seed, **kwargs
                     )
                 )
-            elif key == "rotate" and use_geometry:
-                aug_layers.append(
-                    layers.RandomAffine(
-                        **policy[key],
-                        interpolation=self.interpolation,
-                        fill_mode=self.fill_mode,
-                        fill_value=self.fill_value,
-                        bounding_box_format=bounding_box_format,
-                        seed=seed,
-                        **kwargs,
-                    )
-                )
-            elif key == "shear_x" and use_geometry:
-                aug_layers.append(
-                    layers.RandomAffine(
-                        **policy[key],
-                        interpolation=self.interpolation,
-                        fill_mode=self.fill_mode,
-                        fill_value=self.fill_value,
-                        bounding_box_format=bounding_box_format,
-                        seed=seed,
-                        **kwargs,
-                    )
-                )
-            elif key == "shear_y" and use_geometry:
-                aug_layers.append(
-                    layers.RandomAffine(
-                        **policy[key],
-                        interpolation=self.interpolation,
-                        fill_mode=self.fill_mode,
-                        fill_value=self.fill_value,
-                        bounding_box_format=bounding_box_format,
-                        seed=seed,
-                        **kwargs,
-                    )
-                )
-            elif key == "translate_x" and use_geometry:
-                aug_layers.append(
-                    layers.RandomAffine(
-                        **policy[key],
-                        interpolation=self.interpolation,
-                        fill_mode=self.fill_mode,
-                        fill_value=self.fill_value,
-                        bounding_box_format=bounding_box_format,
-                        seed=seed,
-                        **kwargs,
+            elif key == "rotate":
+                if use_geometry:
+                    aug_layers.append(
+                        layers.RandomAffine(
+                            **policy[key],
+                            interpolation=self.interpolation,
+                            fill_mode=self.fill_mode,
+                            fill_value=self.fill_value,
+                            bounding_box_format=bounding_box_format,
+                            seed=seed,
+                            **kwargs,
+                        )
+                    )
+            elif key == "shear_x":
+                if use_geometry:
+                    aug_layers.append(
+                        layers.RandomAffine(
+                            **policy[key],
+                            interpolation=self.interpolation,
+                            fill_mode=self.fill_mode,
+                            fill_value=self.fill_value,
+                            bounding_box_format=bounding_box_format,
+                            seed=seed,
+                            **kwargs,
+                        )
+                    )
+            elif key == "shear_y":
+                if use_geometry:
+                    aug_layers.append(
+                        layers.RandomAffine(
+                            **policy[key],
+                            interpolation=self.interpolation,
+                            fill_mode=self.fill_mode,
+                            fill_value=self.fill_value,
+                            bounding_box_format=bounding_box_format,
+                            seed=seed,
+                            **kwargs,
+                        )
+                    )
+            elif key == "translate_x":
+                if use_geometry:
+                    aug_layers.append(
+                        layers.RandomAffine(
+                            **policy[key],
+                            interpolation=self.interpolation,
+                            fill_mode=self.fill_mode,
+                            fill_value=self.fill_value,
+                            bounding_box_format=bounding_box_format,
+                            seed=seed,
+                            **kwargs,
+                        )
+                    )
+            elif key == "translate_y":
+                if use_geometry:
+                    aug_layers.append(
+                        layers.RandomAffine(
+                            **policy[key],
+                            interpolation=self.interpolation,
+                            fill_mode=self.fill_mode,
+                            fill_value=self.fill_value,
+                            bounding_box_format=bounding_box_format,
+                            seed=seed,
+                            **kwargs,
+                        )
                     )
-                )
-            elif key == "translate_y" and use_geometry:
-                aug_layers.append(
-                    layers.RandomAffine(
-                        **policy[key],
-                        interpolation=self.interpolation,
-                        fill_mode=self.fill_mode,
-                        fill_value=self.fill_value,
-                        bounding_box_format=bounding_box_format,
-                        seed=seed,
-                        **kwargs,
-                    )
-                )
             else:
-                if key not in exclude_ops:
-                    raise ValueError(f"Not recognized policy key: {key}")
+                raise ValueError(f"Not recognized policy key: {key}")
         return aug_layers
 
     def get_random_transformation_batch(self, batch_size):
         random_indices = self._random_generator.random_uniform(
             shape=(
                 batch_size,
                 self.augmentations_per_image,
@@ -263,49 +269,79 @@
     def _batch_augment(self, inputs):
         images = inputs.get(augmentation_utils.IMAGES, None)
         batch_size = tf.shape(images)[0]
         transformations = self.get_random_transformation_batch(batch_size)
 
         # images value_range transform to [0, 255]
         images = preprocessing_utils.transform_value_range(
-            images, self.value_range, (0, 255), self.compute_dtype
+            images, self.value_range, (0, 255), dtype=self.compute_dtype
         )
         inputs[IMAGES] = images
 
+        # make bounding_boxes to dense first
+        if BOUNDING_BOXES in inputs:
+            inputs[BOUNDING_BOXES] = bounding_box.to_dense(
+                inputs[BOUNDING_BOXES]
+            )
+
         inputs_for_rand_augment_single_input = {
             "inputs": inputs,
             "transformations": transformations,
         }
         result = tf.map_fn(
             self.rand_augment_single_input,
             inputs_for_rand_augment_single_input,
+            fn_output_signature=augmentation_utils.compute_signature(
+                inputs, self.compute_dtype
+            ),
         )
-        # unpack result to normal inputs
-        result = result["inputs"]
 
         # recover value_range
         images = result.get(IMAGES, None)
         images = preprocessing_utils.transform_value_range(
             images, (0, 255), self.value_range, self.compute_dtype
         )
         result[IMAGES] = images
         return result
 
     def rand_augment_single_input(self, inputs):
         input = inputs.get("inputs")
         random_indices = inputs.get("transformations")
 
-        for random_indice in random_indices:
+        # TODO:
+        # figure out why tf will make tf.float32 instead of tf.float16
+        # keras.mixed_precision.set_global_policy("mixed_float16")
+        for i in range(self.augmentations_per_image):
+            random_indice = random_indices[i]
+            if BOUNDING_BOXES in input:
+                tf.autograph.experimental.set_loop_options(
+                    shape_invariants=[
+                        (
+                            input[BOUNDING_BOXES]["boxes"],
+                            tf.TensorSpec([None, 4]),
+                        ),
+                        (
+                            input[BOUNDING_BOXES]["classes"],
+                            tf.TensorSpec([None]),
+                        ),
+                    ]
+                )
             # construct branch_fns
             branch_fns = {}
             for idx, layer in enumerate(self.aug_layers):
                 branch_fns[idx] = partial(layer, input)
             # augment
             input = tf.switch_case(random_indice, branch_fns=branch_fns)
-        return {"inputs": input, "transformations": random_indices}
+            input = augmentation_utils.cast_to(input, self.compute_dtype)
+        result = input
+        if BOUNDING_BOXES in result:
+            result[BOUNDING_BOXES] = bounding_box.to_ragged(
+                result[BOUNDING_BOXES], dtype=self.compute_dtype
+            )
+        return result
 
     def get_config(self):
         config = super().get_config()
         config.update(
             {
                 "value_range": self.value_range,
                 "augmentations_per_image": self.augmentations_per_image,
```

## keras_aug/layers/augmentation/auto/rand_augment_test.py

```diff
@@ -19,7 +19,33 @@
             seed=2023,
         )
         xs = tf.ones((2, 4, 4, 3))
 
         ys = rand_augment(xs)
 
         self.assertEqual(ys.shape, (2, 4, 4, 3))
+
+    def test_runs_with_no_geometry(self):
+        rand_augment = layers.RandAugment(
+            value_range=(0, 255),
+            magnitude=10,
+            use_geometry=False,
+            seed=2023,
+        )
+        xs = tf.ones((2, 4, 4, 3))
+
+        ys = rand_augment(xs)
+
+        self.assertEqual(ys.shape, (2, 4, 4, 3))
+
+    def test_runs_with_exclude_ops(self):
+        rand_augment = layers.RandAugment(
+            value_range=(0, 255),
+            magnitude=10,
+            exclude_ops=["sharpness", "shear_y"],
+            seed=2023,
+        )
+        xs = tf.ones((2, 4, 4, 3))
+
+        ys = rand_augment(xs)
+
+        self.assertEqual(ys.shape, (2, 4, 4, 3))
```

## keras_aug/layers/augmentation/auto/trivial_augment_wide.py

```diff
@@ -1,19 +1,21 @@
 from functools import partial
 
 import tensorflow as tf
+from keras_cv import bounding_box
 from keras_cv.utils import preprocessing as preprocessing_utils
 from tensorflow import keras
 
 from keras_aug import layers
 from keras_aug.core import UniformFactorSampler
 from keras_aug.layers.base.vectorized_base_random_layer import (
     VectorizedBaseRandomLayer,
 )
 from keras_aug.utils import augmentation as augmentation_utils
+from keras_aug.utils.augmentation import BOUNDING_BOXES
 from keras_aug.utils.augmentation import IMAGES
 
 
 @keras.utils.register_keras_serializable(package="keras_aug")
 class TrivialAugmentWide(VectorizedBaseRandomLayer):
     """TrivialAugmentWide performs the Wide version of Trivial Augment
     operation on input images.
@@ -104,122 +106,150 @@
                 policy.pop(op)
         for key in policy.keys():
             if key == "identity":
                 aug_layers.append(layers.Identity(**policy[key], **kwargs))
             elif key == "auto_contrast":
                 aug_layers.append(
                     layers.AutoContrast(
-                        **policy[key], value_range=(0, 255), seed=seed, **kwargs
+                        **policy[key],
+                        value_range=(0, 255),
+                        seed=seed,
+                        **kwargs,
                     )
                 )
             elif key == "equalize":
                 aug_layers.append(
                     layers.Equalize(
-                        **policy[key], value_range=(0, 255), seed=seed, **kwargs
+                        **policy[key],
+                        value_range=(0, 255),
+                        seed=seed,
+                        **kwargs,
                     )
                 )
             elif key == "posterize":
                 aug_layers.append(
                     layers.RandomPosterize(
-                        **policy[key], value_range=(0, 255), seed=seed, **kwargs
+                        **policy[key],
+                        value_range=(0, 255),
+                        seed=seed,
+                        **kwargs,
                     )
                 )
             elif key == "solarize":
                 aug_layers.append(
                     layers.RandomSolarize(
-                        **policy[key], value_range=(0, 255), seed=seed, **kwargs
-                    )
-                )
-            elif key == "color":
-                aug_layers.append(
-                    layers.RandomColorJitter(
-                        **policy[key], value_range=(0, 255), seed=seed, **kwargs
-                    )
-                )
-            elif key == "contrast":
-                aug_layers.append(
-                    layers.RandomColorJitter(
-                        **policy[key], value_range=(0, 255), seed=seed, **kwargs
-                    )
-                )
-            elif key == "brightness":
-                aug_layers.append(
-                    layers.RandomColorJitter(
-                        **policy[key], value_range=(0, 255), seed=seed, **kwargs
-                    )
-                )
-            elif key == "sharpness":
-                aug_layers.append(
-                    layers.RandomSharpness(
-                        **policy[key], value_range=(0, 255), seed=seed, **kwargs
-                    )
-                )
-            elif key == "rotate" and use_geometry:
-                aug_layers.append(
-                    layers.RandomAffine(
                         **policy[key],
-                        interpolation=self.interpolation,
-                        fill_mode=self.fill_mode,
-                        fill_value=self.fill_value,
-                        bounding_box_format=bounding_box_format,
+                        value_range=(0, 255),
                         seed=seed,
                         **kwargs,
                     )
                 )
-            elif key == "shear_x" and use_geometry:
+            elif key == "color":
                 aug_layers.append(
-                    layers.RandomAffine(
+                    layers.RandomColorJitter(
                         **policy[key],
-                        interpolation=self.interpolation,
-                        fill_mode=self.fill_mode,
-                        fill_value=self.fill_value,
-                        bounding_box_format=bounding_box_format,
+                        value_range=(0, 255),
                         seed=seed,
                         **kwargs,
                     )
                 )
-            elif key == "shear_y" and use_geometry:
+            elif key == "contrast":
                 aug_layers.append(
-                    layers.RandomAffine(
+                    layers.RandomColorJitter(
                         **policy[key],
-                        interpolation=self.interpolation,
-                        fill_mode=self.fill_mode,
-                        fill_value=self.fill_value,
-                        bounding_box_format=bounding_box_format,
+                        value_range=(0, 255),
                         seed=seed,
                         **kwargs,
                     )
                 )
-            elif key == "translate_x" and use_geometry:
+            elif key == "brightness":
                 aug_layers.append(
-                    layers.RandomAffine(
+                    layers.RandomColorJitter(
                         **policy[key],
-                        interpolation=self.interpolation,
-                        fill_mode=self.fill_mode,
-                        fill_value=self.fill_value,
-                        bounding_box_format=bounding_box_format,
+                        value_range=(0, 255),
                         seed=seed,
                         **kwargs,
                     )
                 )
-            elif key == "translate_y" and use_geometry:
+            elif key == "sharpness":
                 aug_layers.append(
-                    layers.RandomAffine(
+                    layers.RandomSharpness(
                         **policy[key],
-                        interpolation=self.interpolation,
-                        fill_mode=self.fill_mode,
-                        fill_value=self.fill_value,
-                        bounding_box_format=bounding_box_format,
+                        value_range=(0, 255),
                         seed=seed,
                         **kwargs,
                     )
                 )
+            elif key == "rotate":
+                if use_geometry:
+                    aug_layers.append(
+                        layers.RandomAffine(
+                            **policy[key],
+                            interpolation=self.interpolation,
+                            fill_mode=self.fill_mode,
+                            fill_value=self.fill_value,
+                            bounding_box_format=bounding_box_format,
+                            seed=seed,
+                            **kwargs,
+                        )
+                    )
+            elif key == "shear_x":
+                if use_geometry:
+                    aug_layers.append(
+                        layers.RandomAffine(
+                            **policy[key],
+                            interpolation=self.interpolation,
+                            fill_mode=self.fill_mode,
+                            fill_value=self.fill_value,
+                            bounding_box_format=bounding_box_format,
+                            seed=seed,
+                            **kwargs,
+                        )
+                    )
+            elif key == "shear_y":
+                if use_geometry:
+                    aug_layers.append(
+                        layers.RandomAffine(
+                            **policy[key],
+                            interpolation=self.interpolation,
+                            fill_mode=self.fill_mode,
+                            fill_value=self.fill_value,
+                            bounding_box_format=bounding_box_format,
+                            seed=seed,
+                            **kwargs,
+                        )
+                    )
+            elif key == "translate_x":
+                if use_geometry:
+                    aug_layers.append(
+                        layers.RandomAffine(
+                            **policy[key],
+                            interpolation=self.interpolation,
+                            fill_mode=self.fill_mode,
+                            fill_value=self.fill_value,
+                            bounding_box_format=bounding_box_format,
+                            seed=seed,
+                            **kwargs,
+                        )
+                    )
+            elif key == "translate_y":
+                if use_geometry:
+                    aug_layers.append(
+                        layers.RandomAffine(
+                            **policy[key],
+                            interpolation=self.interpolation,
+                            fill_mode=self.fill_mode,
+                            fill_value=self.fill_value,
+                            bounding_box_format=bounding_box_format,
+                            seed=seed,
+                            **kwargs,
+                        )
+                    )
             else:
-                if key not in exclude_ops:
-                    raise ValueError(f"Not recognized policy key: {key}")
+                raise ValueError(f"Not recognized policy key: {key}")
         return aug_layers
 
     def get_random_transformation_batch(self, batch_size):
         random_indices = self._random_generator.random_uniform(
             shape=(batch_size,),
             minval=0,
             maxval=self.num_layers,
@@ -230,28 +260,35 @@
     def _batch_augment(self, inputs):
         images = inputs.get(augmentation_utils.IMAGES, None)
         batch_size = tf.shape(images)[0]
         transformations = self.get_random_transformation_batch(batch_size)
 
         # images value_range transform to [0, 255]
         images = preprocessing_utils.transform_value_range(
-            images, self.value_range, (0, 255), self.compute_dtype
+            images, self.value_range, (0, 255), dtype=self.compute_dtype
         )
         inputs[IMAGES] = images
 
+        # make bounding_boxes to dense first
+        if BOUNDING_BOXES in inputs:
+            inputs[BOUNDING_BOXES] = bounding_box.to_dense(
+                inputs[BOUNDING_BOXES]
+            )
+
         inputs_for_trivial_augment_single_input = {
             "inputs": inputs,
             "transformations": transformations,
         }
         result = tf.map_fn(
             self.trivial_augment_single_input,
             inputs_for_trivial_augment_single_input,
+            fn_output_signature=augmentation_utils.compute_signature(
+                inputs, self.compute_dtype
+            ),
         )
-        # unpack result to normal inputs
-        result = result["inputs"]
 
         # recover value_range
         images = result.get(IMAGES, None)
         images = preprocessing_utils.transform_value_range(
             images, (0, 255), self.value_range, self.compute_dtype
         )
         result[IMAGES] = images
@@ -260,16 +297,24 @@
     def trivial_augment_single_input(self, inputs):
         input = inputs.get("inputs")
         random_indice = inputs.get("transformations")
         # construct branch_fns
         branch_fns = {}
         for idx, layer in enumerate(self.aug_layers):
             branch_fns[idx] = partial(layer, input)
-        input = tf.switch_case(random_indice, branch_fns=branch_fns)
-        return {"inputs": input, "transformations": random_indice}
+
+        # TODO:
+        # figure out why tf will make tf.float32 instead of tf.float16
+        # keras.mixed_precision.set_global_policy("mixed_float16")
+        result = tf.switch_case(random_indice, branch_fns=branch_fns)
+        if BOUNDING_BOXES in result:
+            result[BOUNDING_BOXES] = bounding_box.to_ragged(
+                result[BOUNDING_BOXES], dtype=self.compute_dtype
+            )
+        return result
 
     def get_config(self):
         config = super().get_config()
         config.update(
             {
                 "value_range": self.value_range,
                 "use_geometry": self.use_geometry,
```

## keras_aug/layers/augmentation/geometry/random_affine.py

```diff
@@ -209,59 +209,73 @@
         )
         self._enable_shear = _enable_shear_height or _enable_shear_width
 
     def get_random_transformation_batch(
         self, batch_size, images=None, **kwargs
     ):
         heights, widths = augmentation_utils.get_images_shape(
-            images, dtype=tf.float32
+            images, dtype=self.compute_dtype
         )
         factor_shape = (batch_size, 1)
         # dummy
-        angles = tf.zeros(factor_shape)
-        translation_heights = tf.zeros(factor_shape)
-        translation_widths = tf.zeros(factor_shape)
-        zoom_heights = tf.zeros(factor_shape)
-        zoom_widths = tf.zeros(factor_shape)
-        shear_heights = tf.zeros(factor_shape)
-        shear_widths = tf.zeros(factor_shape)
+        angles = tf.zeros(factor_shape, dtype=self.compute_dtype)
+        translation_heights = tf.zeros(factor_shape, dtype=self.compute_dtype)
+        translation_widths = tf.zeros(factor_shape, dtype=self.compute_dtype)
+        zoom_heights = tf.zeros(factor_shape, dtype=self.compute_dtype)
+        zoom_widths = tf.zeros(factor_shape, dtype=self.compute_dtype)
+        shear_heights = tf.zeros(factor_shape, dtype=self.compute_dtype)
+        shear_widths = tf.zeros(factor_shape, dtype=self.compute_dtype)
 
         if self._enable_rotation:
-            angles = self.rotation_factor(factor_shape)
+            angles = self.rotation_factor(
+                factor_shape, dtype=self.compute_dtype
+            )
         if self._enable_translation:
-            translation_heights = self.translation_height_factor(factor_shape)
-            translation_widths = self.translation_width_factor(factor_shape)
+            translation_heights = self.translation_height_factor(
+                factor_shape, dtype=self.compute_dtype
+            )
+            translation_widths = self.translation_width_factor(
+                factor_shape, dtype=self.compute_dtype
+            )
         if self._enable_zoom:
-            zoom_heights = self.zoom_height_factor(factor_shape)
+            zoom_heights = self.zoom_height_factor(
+                factor_shape, dtype=self.compute_dtype
+            )
             if self.same_zoom_factor:
                 zoom_widths = zoom_heights
             else:
-                zoom_widths = self.zoom_width_factor(factor_shape)
+                zoom_widths = self.zoom_width_factor(
+                    factor_shape, dtype=self.compute_dtype
+                )
         if self._enable_shear:
-            shear_heights = self.shear_height_factor(factor_shape)
-            shear_widths = self.shear_width_factor(factor_shape)
+            shear_heights = self.shear_height_factor(
+                factor_shape, dtype=self.compute_dtype
+            )
+            shear_widths = self.shear_width_factor(
+                factor_shape, dtype=self.compute_dtype
+            )
 
         angles = angles / 360.0 * 2.0 * math.pi
         translations = tf.concat(
             [translation_widths, translation_heights], axis=1
         )
         zooms = tf.concat([zoom_widths, zoom_heights], axis=1)
         shears = tf.concat([shear_widths, shear_heights], axis=1)
 
         # start from identity matrixes:
         #     [[1 0 0]
         #      [0 1 0]
         #      [0 0 1]]
         identity_matrixes = tf.concat(
             [
-                tf.ones((batch_size, 1)),
-                tf.zeros((batch_size, 3)),
-                tf.ones((batch_size, 1)),
-                tf.zeros((batch_size, 3)),
-                tf.ones((batch_size, 1)),
+                tf.ones((batch_size, 1), dtype=self.compute_dtype),
+                tf.zeros((batch_size, 3), dtype=self.compute_dtype),
+                tf.ones((batch_size, 1), dtype=self.compute_dtype),
+                tf.zeros((batch_size, 3), dtype=self.compute_dtype),
+                tf.ones((batch_size, 1), dtype=self.compute_dtype),
             ],
             axis=1,
         )
         combined_matrixes = tf.reshape(identity_matrixes, (batch_size, 3, 3))
         # process zoom
         if self._enable_zoom:
             zoom_matrixes = augmentation_utils.get_zoom_matrix(
@@ -301,28 +315,30 @@
         )
         image = self.augment_images(
             images=image, transformations=transformation, **kwargs
         )
         return tf.squeeze(image, axis=0)
 
     def augment_images(self, images, transformations, **kwargs):
+        original_shape = images.shape
         batch_size = tf.shape(images)[0]
         combined_matrixes = transformations["combined_matrixes"]
         combined_matrixes = tf.reshape(
             combined_matrixes, shape=(batch_size, -1)
         )
         combined_matrixes = combined_matrixes[:, :-1]
 
         images = preprocessing_utils.transform(
             images,
-            combined_matrixes,
+            tf.cast(combined_matrixes, dtype=tf.float32),  # must be float32
             fill_mode=self.fill_mode,
             fill_value=self.fill_value,
             interpolation=self.interpolation,
         )
+        images = tf.ensure_shape(images, shape=original_shape)
         return images
 
     def augment_labels(self, labels, transformations, **kwargs):
         return labels
 
     def augment_bounding_boxes(
         self, bounding_boxes, transformations, raw_images=None, **kwargs
@@ -339,15 +355,15 @@
         )
         bounding_boxes = bounding_box.to_dense(bounding_boxes)
         bounding_boxes = bounding_box.convert_format(
             bounding_boxes,
             source=self.bounding_box_format,
             target="xyxy",
             images=raw_images,
-            dtype=tf.float32,
+            dtype=self.compute_dtype,
         )
         boxes = bounding_boxes["boxes"]
         original_bounding_boxes = bounding_boxes.copy()
         # process rotations
         if self._enable_rotation:
             origin_x = widths / 2
             origin_y = heights / 2
@@ -431,15 +447,15 @@
             x2s = (x2s - x_offsets) / zoom_widths
             y1s = (y1s - y_offsets) / zoom_heights
             y2s = (y2s - y_offsets) / zoom_heights
             boxes = tf.concat([x1s, y1s, x2s, y2s], axis=-1)
 
         bounding_boxes = bounding_boxes.copy()
         bounding_boxes["boxes"] = boxes
-        bounding_boxes = bounding_box.clip_to_image(
+        bounding_boxes = bounding_box_utils.clip_to_image(
             bounding_boxes,
             bounding_box_format="xyxy",
             images=raw_images,
         )
         bounding_boxes = bounding_box_utils.sanitize_bounding_boxes(
             bounding_boxes,
             min_area_ratio=self.bounding_box_min_area_ratio,
@@ -454,31 +470,49 @@
             source="xyxy",
             target=self.bounding_box_format,
             dtype=self.compute_dtype,
             images=raw_images,
         )
         return bounding_boxes
 
+    def augment_ragged_segmentation_mask(
+        self, segmentation_mask, transformation, **kwargs
+    ):
+        segmentation_mask = tf.expand_dims(segmentation_mask, axis=0)
+        transformation = augmentation_utils.expand_dict_dims(
+            transformation, axis=0
+        )
+        segmentation_mask = self.augment_segmentation_masks(
+            segmentation_masks=segmentation_mask,
+            transformations=transformation,
+            **kwargs,
+        )
+        return tf.squeeze(segmentation_mask, axis=0)
+
     def augment_segmentation_masks(
-        self, segmentation_masks, transformations, raw_images=None, **kwargs
+        self, segmentation_masks, transformations, **kwargs
     ):
-        batch_size = tf.shape(raw_images)[0]
+        original_shape = segmentation_masks.shape
+        batch_size = tf.shape(segmentation_masks)[0]
         combined_matrixes = transformations["combined_matrixes"]
         combined_matrixes = tf.reshape(
             combined_matrixes, shape=(batch_size, -1)
         )
         combined_matrixes = combined_matrixes[:, :-1]
 
         segmentation_masks = preprocessing_utils.transform(
             segmentation_masks,
-            combined_matrixes,
+            tf.cast(combined_matrixes, dtype=tf.float32),  # must be float32
             fill_mode=self.fill_mode,
             fill_value=0,
             interpolation="nearest",
         )
+        segmentation_masks = tf.ensure_shape(
+            segmentation_masks, shape=original_shape
+        )
         return segmentation_masks
 
     def get_config(self):
         config = super().get_config()
         config.update(
             {
                 "rotation_factor": self.rotation_factor,
```

## keras_aug/layers/augmentation/geometry/random_affine_test.py

```diff
@@ -388,7 +388,62 @@
         )
         old_area = tf.math.multiply(
             tf.abs(tf.subtract(ys["boxes"][..., 2], ys["boxes"][..., 0])),
             tf.abs(tf.subtract(ys["boxes"][..., 3], ys["boxes"][..., 1])),
         )
 
         self.assertTrue(tf.math.reduce_all(new_area > old_area))
+
+    def test_dense_segmentation_masks(self):
+        images = tf.random.uniform((2, 10, 10, 3))
+        segmentation_masks = tf.random.uniform(
+            (2, 10, 10, 1), minval=0, maxval=10, dtype=tf.int32
+        )
+        args = self.no_aug_args.copy()
+        args.update(
+            {
+                "shear_height_factor": (0.3, 0.7),
+                "shear_width_factor": (0.4, 0.7),
+                "interpolation": "nearest",
+                "seed": 0,
+            }
+        )
+        layer = layers.RandomAffine(**args)
+
+        result = layer(
+            {"images": images, "segmentation_masks": segmentation_masks}
+        )
+
+        self.assertTrue(isinstance(result["segmentation_masks"], tf.Tensor))
+
+    def test_ragged_segmentation_masks(self):
+        images = tf.ragged.stack(
+            [
+                tf.random.uniform((8, 8, 3), dtype=tf.float32),
+                tf.random.uniform((16, 8, 3), dtype=tf.float32),
+            ]
+        )
+        segmentation_masks = tf.ragged.stack(
+            [
+                tf.random.uniform((8, 8, 1), maxval=10, dtype=tf.int32),
+                tf.random.uniform((16, 8, 1), maxval=10, dtype=tf.int32),
+            ]
+        )
+        segmentation_masks = tf.cast(segmentation_masks, dtype=tf.float32)
+        args = self.no_aug_args.copy()
+        args.update(
+            {
+                "shear_height_factor": (0.3, 0.7),
+                "shear_width_factor": (0.4, 0.7),
+                "interpolation": "nearest",
+                "seed": 0,
+            }
+        )
+        layer = layers.RandomAffine(**args)
+
+        result = layer(
+            {"images": images, "segmentation_masks": segmentation_masks}
+        )
+
+        self.assertTrue(
+            isinstance(result["segmentation_masks"], tf.RaggedTensor)
+        )
```

## keras_aug/layers/augmentation/geometry/random_crop.py

```diff
@@ -60,24 +60,23 @@
         self.resize_bilinear = keras.layers.Resizing(self.height, self.width)
         self.resize_nearest = keras.layers.Resizing(
             self.height, self.width, interpolation="nearest"
         )
         # set force_output_dense_images=True because the output images must
         # have same shape (B, height, width, C)
         self.force_output_dense_images = True
-        self.force_output_dense_segmentation_masks = True
 
     def get_random_transformation_batch(
         self, batch_size, images=None, **kwargs
     ):
         tops = self._random_generator.random_uniform(
-            shape=(batch_size, 1), minval=0, maxval=1, dtype=tf.float32
+            shape=(batch_size, 1), minval=0, maxval=1, dtype=self.compute_dtype
         )
         lefts = self._random_generator.random_uniform(
-            shape=(batch_size, 1), minval=0, maxval=1, dtype=tf.float32
+            shape=(batch_size, 1), minval=0, maxval=1, dtype=self.compute_dtype
         )
         return {"crop_tops": tops, "crop_lefts": lefts}
 
     def compute_ragged_image_signature(self, images):
         ragged_spec = tf.RaggedTensorSpec(
             shape=(self.height, self.width, images.shape[-1]),
             ragged_rank=1,
@@ -103,14 +102,17 @@
         h_diffs = h_diffs[:, tf.newaxis, tf.newaxis, :]
         w_diffs = w_diffs[:, tf.newaxis, tf.newaxis, :]
         images = tf.where(
             tf.math.logical_and(h_diffs >= 0, w_diffs >= 0),
             self.crop_images(images, transformations),
             self.resize_images(images, interpolation=self.interpolation),
         )
+        images = tf.ensure_shape(
+            images, shape=(None, self.height, self.width, None)
+        )
         return images
 
     def augment_labels(self, labels, transformations, **kwargs):
         return labels
 
     def augment_bounding_boxes(
         self,
@@ -129,14 +131,15 @@
             )
         bounding_boxes = bounding_box.to_dense(bounding_boxes)
         bounding_boxes = bounding_box.convert_format(
             bounding_boxes,
             source=self.bounding_box_format,
             target="xyxy",
             images=raw_images,
+            dtype=self.compute_dtype,
         )
         original_bounding_boxes = bounding_boxes.copy()
 
         heights, widths = augmentation_utils.get_images_shape(raw_images)
         h_diffs = heights - self.height
         w_diffs = widths - self.width
         # broadcast
@@ -149,15 +152,15 @@
             ),
             self.resize_bounding_boxes(
                 raw_images,
                 bounding_boxes["boxes"],
             ),
         )
         bounding_boxes["boxes"] = boxes
-        bounding_boxes = bounding_box.clip_to_image(
+        bounding_boxes = bounding_box_utils.clip_to_image(
             bounding_boxes,
             bounding_box_format="xyxy",
             images=images,
         )
         bounding_boxes = bounding_box_utils.sanitize_bounding_boxes(
             bounding_boxes,
             min_area_ratio=self.bounding_box_min_area_ratio,
@@ -172,14 +175,35 @@
             source="xyxy",
             target=self.bounding_box_format,
             dtype=self.compute_dtype,
             images=images,
         )
         return bounding_boxes
 
+    def compute_ragged_segmentation_mask_signature(self, segmentation_masks):
+        return tf.RaggedTensorSpec(
+            shape=(self.height, self.width, segmentation_masks.shape[-1]),
+            ragged_rank=1,
+            dtype=self.compute_dtype,
+        )
+
+    def augment_ragged_segmentation_mask(
+        self, segmentation_mask, transformation, **kwargs
+    ):
+        segmentation_mask = tf.expand_dims(segmentation_mask, axis=0)
+        transformation = augmentation_utils.expand_dict_dims(
+            transformation, axis=0
+        )
+        segmentation_mask = self.augment_segmentation_masks(
+            segmentation_masks=segmentation_mask,
+            transformations=transformation,
+            **kwargs,
+        )
+        return tf.squeeze(segmentation_mask, axis=0)
+
     def augment_segmentation_masks(
         self, segmentation_masks, transformations, **kwargs
     ):
         heights, widths = augmentation_utils.get_images_shape(
             segmentation_masks
         )
         h_diffs = heights - self.height
@@ -188,20 +212,23 @@
         h_diffs = h_diffs[:, tf.newaxis, tf.newaxis, :]
         w_diffs = w_diffs[:, tf.newaxis, tf.newaxis, :]
         segmentation_masks = tf.where(
             tf.math.logical_and(h_diffs >= 0, w_diffs >= 0),
             self.crop_images(segmentation_masks, transformations),
             self.resize_images(segmentation_masks, interpolation="nearest"),
         )
+        segmentation_masks = tf.ensure_shape(
+            segmentation_masks, shape=(None, self.height, self.width, None)
+        )
         return segmentation_masks
 
     def crop_images(self, images, transformations):
         batch_size = tf.shape(images)[0]
         heights, widths = augmentation_utils.get_images_shape(
-            images, dtype=tf.float32
+            images, dtype=self.compute_dtype
         )
         tops = transformations["crop_tops"]
         lefts = transformations["crop_lefts"]
         x1s = lefts * (widths - self.width)
         y1s = tops * (heights - self.height)
         x2s = x1s + self.width
         y2s = y1s + self.height
@@ -209,15 +236,15 @@
         x1s /= widths
         y1s /= heights
         x2s /= widths
         y2s /= heights
         boxes = tf.concat([y1s, x1s, y2s, x2s], axis=-1)
         images = tf.image.crop_and_resize(
             images,
-            boxes,
+            tf.cast(boxes, dtype=tf.float32),  # must be tf.float32
             tf.range(batch_size),
             [self.height, self.width],
             method="nearest",
         )
         return tf.cast(images, dtype=self.compute_dtype)
 
     def resize_images(self, images, interpolation="bilinear"):
@@ -229,15 +256,15 @@
             raise ValueError(f"Unsupported interpolation: {interpolation}")
         return tf.cast(images, dtype=self.compute_dtype)
 
     def crop_bounding_boxes(self, images, boxes, transformation):
         tops = transformation["crop_tops"]
         lefts = transformation["crop_lefts"]
         heights, widths = augmentation_utils.get_images_shape(
-            images, dtype=tf.float32
+            images, dtype=self.compute_dtype
         )
 
         # compute offsets for xyxy bounding_boxes
         top_offsets = tf.cast(
             tf.math.round(tops * (heights - self.height)),
             dtype=self.compute_dtype,
         )
```

## keras_aug/layers/augmentation/geometry/random_crop_and_resize.py

```diff
@@ -3,14 +3,15 @@
 from tensorflow import keras
 
 from keras_aug import core
 from keras_aug.layers.base.vectorized_base_random_layer import (
     VectorizedBaseRandomLayer,
 )
 from keras_aug.utils import augmentation as augmentation_utils
+from keras_aug.utils import bounding_box as bounding_box_utils
 
 
 @keras.utils.register_keras_serializable(package="keras_aug")
 class RandomCropAndResize(VectorizedBaseRandomLayer):
     """Randomly crops a part of an image and resizes it to provided size.
 
     This implementation takes an intuitive approach, where we crop the images to
@@ -84,15 +85,14 @@
         self.interpolation = interpolation
         self.bounding_box_format = bounding_box_format
         self.seed = seed
 
         # set force_output_dense_images=True because the output images must
         # have same shape (B, height, width, C)
         self.force_output_dense_images = True
-        self.force_output_dense_segmentation_masks = True
 
     def get_random_transformation_batch(
         self, batch_size, images=None, **kwargs
     ):
         crop_area_factor = self.crop_area_factor(shape=(batch_size, 1))
         aspect_ratio = self.aspect_ratio_factor(shape=(batch_size, 1))
 
@@ -122,20 +122,19 @@
         x1s = width_offset
         x2s = width_offset + new_width
 
         boxes = tf.concat([y1s, x1s, y2s, x2s], axis=-1)
         return boxes
 
     def compute_ragged_image_signature(self, images):
-        ragged_spec = tf.RaggedTensorSpec(
+        return tf.RaggedTensorSpec(
             shape=(self.height, self.width, images.shape[-1]),
             ragged_rank=1,
             dtype=self.compute_dtype,
         )
-        return ragged_spec
 
     def augment_ragged_image(self, image, transformation, **kwargs):
         image = tf.expand_dims(image, axis=0)
         transformation = tf.expand_dims(transformation, axis=0)
         image = self.augment_images(
             images=image, transformations=transformation, **kwargs
         )
@@ -149,14 +148,17 @@
             images,  # image shape: [B, H, W, C]
             boxes,  # boxes: (B, 4) in this case; represents area
             # to be cropped from the original image
             indices,  # box_indices: maps boxes to images along batch axis
             [self.height, self.width],  # output size
             method=self.interpolation,
         )
+        images = tf.ensure_shape(
+            images, shape=(None, self.height, self.width, None)
+        )
         return tf.cast(images, dtype=self.compute_dtype)
 
     def augment_labels(self, labels, transformations, **kwargs):
         return labels
 
     def augment_bounding_boxes(
         self,
@@ -197,42 +199,64 @@
                 (y2s - t_y1s) / t_dys,
             ],
             axis=-1,
         )
         bounding_boxes = bounding_boxes.copy()
         bounding_boxes["boxes"] = output
 
-        bounding_boxes = bounding_box.clip_to_image(
+        bounding_boxes = bounding_box_utils.clip_to_image(
             bounding_boxes,
             bounding_box_format="rel_xyxy",
             images=images,
         )
         bounding_boxes = bounding_box.convert_format(
             bounding_boxes,
             source="rel_xyxy",
             target=self.bounding_box_format,
             dtype=self.compute_dtype,
             images=images,
         )
         return bounding_boxes
 
+    def compute_ragged_segmentation_mask_signature(self, segmentation_masks):
+        return tf.RaggedTensorSpec(
+            shape=(self.height, self.width, segmentation_masks.shape[-1]),
+            ragged_rank=1,
+            dtype=self.compute_dtype,
+        )
+
+    def augment_ragged_segmentation_mask(
+        self, segmentation_mask, transformation, **kwargs
+    ):
+        segmentation_mask = tf.expand_dims(segmentation_mask, axis=0)
+        transformation = tf.expand_dims(transformation, axis=0)
+        segmentation_mask = self.augment_segmentation_masks(
+            segmentation_masks=segmentation_mask,
+            transformations=transformation,
+            **kwargs,
+        )
+        return tf.squeeze(segmentation_mask, axis=0)
+
     def augment_segmentation_masks(
         self, segmentation_masks, transformations, **kwargs
     ):
         batch_size = tf.shape(segmentation_masks)[0]
         boxes = transformations
         indices = tf.range(batch_size)
         segmentation_masks = tf.image.crop_and_resize(
             segmentation_masks,  # image shape: [B, H, W, C]
             boxes,  # boxes: (B, 4) in this case; represents area
             # to be cropped from the original image
             indices,  # box_indices: maps boxes to images along batch axis
             [self.height, self.width],  # output size
             method="nearest",
         )
+        segmentation_masks = tf.ensure_shape(
+            segmentation_masks, shape=(None, self.height, self.width, None)
+        )
         return tf.cast(segmentation_masks, dtype=self.compute_dtype)
 
     def _check_arguments(
         self, height, width, crop_area_factor, aspect_ratio_factor
     ):
         if not isinstance(height, int) or not isinstance(width, int):
             raise ValueError(
```

## keras_aug/layers/augmentation/geometry/random_crop_and_resize_test.py

```diff
@@ -224,7 +224,62 @@
 
         self.assertAllClose(
             expected_output["boxes"], output["bounding_boxes"]["boxes"]
         )
         self.assertAllClose(
             expected_output["classes"], output["bounding_boxes"]["classes"]
         )
+
+    def test_dense_segmentation_masks(self):
+        images = tf.random.uniform((2, 10, 10, 3))
+        segmentation_masks = tf.random.uniform(
+            (2, 10, 10, 1), minval=0, maxval=10, dtype=tf.int32
+        )
+        args = self.no_aug_args.copy()
+        args.update(
+            {
+                "height": 18,
+                "width": 18,
+                "aspect_ratio_factor": (0.5**2, 0.5**2),
+                "crop_area_factor": (1.0, 1.0),
+            }
+        )
+        layer = layers.RandomCropAndResize(**args, seed=2023)
+
+        result = layer(
+            {"images": images, "segmentation_masks": segmentation_masks}
+        )
+
+        self.assertTrue(isinstance(result["segmentation_masks"], tf.Tensor))
+        self.assertAllInSet(result["segmentation_masks"], tf.range(0, 10))
+
+    def test_ragged_segmentation_masks(self):
+        images = tf.ragged.stack(
+            [
+                tf.random.uniform((8, 8, 3), dtype=tf.float32),
+                tf.random.uniform((16, 8, 3), dtype=tf.float32),
+            ]
+        )
+        segmentation_masks = tf.ragged.stack(
+            [
+                tf.random.uniform((8, 8, 1), maxval=10, dtype=tf.int32),
+                tf.random.uniform((16, 8, 1), maxval=10, dtype=tf.int32),
+            ]
+        )
+        segmentation_masks = tf.cast(segmentation_masks, dtype=tf.float32)
+        args = self.no_aug_args.copy()
+        args.update(
+            {
+                "height": 18,
+                "width": 18,
+                "aspect_ratio_factor": (0.5**2, 0.5**2),
+                "crop_area_factor": (1.0, 1.0),
+            }
+        )
+        layer = layers.RandomCropAndResize(**args, seed=2023)
+
+        result = layer(
+            {"images": images, "segmentation_masks": segmentation_masks}
+        )
+
+        self.assertTrue(isinstance(result["segmentation_masks"], tf.Tensor))
+        self.assertAllInSet(result["segmentation_masks"], tf.range(0, 10))
```

## keras_aug/layers/augmentation/geometry/random_crop_test.py

```diff
@@ -157,7 +157,46 @@
         self.assertTrue(isinstance(results["images"], tf.Tensor))
         self.assertTrue(
             isinstance(results["bounding_boxes"]["boxes"], tf.RaggedTensor)
         )
         self.assertTrue(
             isinstance(results["bounding_boxes"]["classes"], tf.RaggedTensor)
         )
+
+    def test_dense_segmentation_masks(self):
+        images = tf.random.uniform((2, 10, 10, 3))
+        segmentation_masks = tf.random.uniform(
+            (2, 10, 10, 1), minval=0, maxval=10, dtype=tf.int32
+        )
+        layer = layers.RandomCrop(height=2, width=2)
+
+        result = layer(
+            {"images": images, "segmentation_masks": segmentation_masks}
+        )
+
+        self.assertTrue(isinstance(result["segmentation_masks"], tf.Tensor))
+        self.assertEqual(result["segmentation_masks"].shape[1:3], (2, 2))
+        self.assertAllInSet(result["segmentation_masks"], tf.range(0, 10))
+
+    def test_ragged_segmentation_masks(self):
+        images = tf.ragged.stack(
+            [
+                tf.random.uniform((8, 8, 3), dtype=tf.float32),
+                tf.random.uniform((16, 8, 3), dtype=tf.float32),
+            ]
+        )
+        segmentation_masks = tf.ragged.stack(
+            [
+                tf.random.uniform((8, 8, 1), maxval=10, dtype=tf.int32),
+                tf.random.uniform((16, 8, 1), maxval=10, dtype=tf.int32),
+            ]
+        )
+        segmentation_masks = tf.cast(segmentation_masks, dtype=tf.float32)
+        layer = layers.RandomCrop(height=2, width=2)
+
+        result = layer(
+            {"images": images, "segmentation_masks": segmentation_masks}
+        )
+
+        self.assertTrue(isinstance(result["segmentation_masks"], tf.Tensor))
+        self.assertEqual(result["segmentation_masks"].shape[1:3], (2, 2))
+        self.assertAllInSet(result["segmentation_masks"], tf.range(0, 10))
```

## keras_aug/layers/augmentation/geometry/random_flip.py

```diff
@@ -2,14 +2,15 @@
 from keras_cv import bounding_box
 from tensorflow import keras
 
 from keras_aug.layers.base.vectorized_base_random_layer import (
     VectorizedBaseRandomLayer,
 )
 from keras_aug.utils import augmentation as augmentation_utils
+from keras_aug.utils import bounding_box as bounding_box_utils
 
 # Defining modes for random flipping
 HORIZONTAL = "horizontal"
 VERTICAL = "vertical"
 HORIZONTAL_AND_VERTICAL = "horizontal_and_vertical"
 
 
@@ -135,28 +136,42 @@
             boxes = tf.where(
                 flip_verticals > (1.0 - self.rate),
                 self.flip_boxes_vertical(boxes),
                 boxes,
             )
         bounding_boxes = bounding_boxes.copy()
         bounding_boxes["boxes"] = boxes
-        bounding_boxes = bounding_box.clip_to_image(
+        bounding_boxes = bounding_box_utils.clip_to_image(
             bounding_boxes,
             bounding_box_format="rel_xyxy",
             images=raw_images,
         )
         bounding_boxes = bounding_box.convert_format(
             bounding_boxes,
             source="rel_xyxy",
             target=self.bounding_box_format,
             dtype=self.compute_dtype,
             images=raw_images,
         )
         return bounding_boxes
 
+    def augment_ragged_segmentation_mask(
+        self, segmentation_mask, transformation, **kwargs
+    ):
+        segmentation_mask = tf.expand_dims(segmentation_mask, axis=0)
+        transformation = augmentation_utils.expand_dict_dims(
+            transformation, axis=0
+        )
+        segmentation_mask = self.augment_segmentation_masks(
+            segmentation_masks=segmentation_mask,
+            transformations=transformation,
+            **kwargs,
+        )
+        return tf.squeeze(segmentation_mask, axis=0)
+
     def augment_segmentation_masks(
         self, segmentation_masks, transformations=None, **kwargs
     ):
         return self.flip_images(segmentation_masks, transformations)
 
     def flip_images(self, images, transformations):
         original_shape = images.shape
```

## keras_aug/layers/augmentation/geometry/random_flip_test.py

```diff
@@ -258,7 +258,48 @@
             ),
             "classes": tf.ragged.constant([[0, 0], [0]], dtype=tf.float32),
         }
 
         input = {"images": input_image, "bounding_boxes": bounding_boxes}
         layer = layers.RandomFlip(bounding_box_format="xyxy")
         _ = layer(input)
+
+    def test_dense_segmentation_masks(self):
+        images = tf.random.uniform((2, 10, 10, 3))
+        segmentation_masks = tf.random.uniform(
+            (2, 10, 10, 1), minval=0, maxval=10, dtype=tf.int32
+        )
+        layer = layers.RandomFlip()
+
+        result = layer(
+            {"images": images, "segmentation_masks": segmentation_masks}
+        )
+
+        self.assertTrue(isinstance(result["segmentation_masks"], tf.Tensor))
+        self.assertAllInSet(result["segmentation_masks"], tf.range(0, 10))
+
+    def test_ragged_segmentation_masks(self):
+        images = tf.ragged.stack(
+            [
+                tf.random.uniform((8, 8, 3), dtype=tf.float32),
+                tf.random.uniform((16, 8, 3), dtype=tf.float32),
+            ]
+        )
+        segmentation_masks = tf.ragged.stack(
+            [
+                tf.random.uniform((8, 8, 1), maxval=10, dtype=tf.int32),
+                tf.random.uniform((16, 8, 1), maxval=10, dtype=tf.int32),
+            ]
+        )
+        segmentation_masks = tf.cast(segmentation_masks, dtype=tf.float32)
+        layer = layers.RandomFlip()
+
+        result = layer(
+            {"images": images, "segmentation_masks": segmentation_masks}
+        )
+
+        self.assertTrue(
+            isinstance(result["segmentation_masks"], tf.RaggedTensor)
+        )
+        self.assertAllInSet(
+            result["segmentation_masks"].to_tensor(0), tf.range(0, 10)
+        )
```

## keras_aug/layers/augmentation/geometry/random_resize.py

```diff
@@ -74,15 +74,14 @@
 
         self._heights = tf.convert_to_tensor(self.heights, dtype=tf.int32)
         self._widths = tf.convert_to_tensor(self.widths, dtype=tf.int32)
 
         # set force_output_dense_images=True because the output images must
         # have same shape (B, height, width, C)
         self.force_output_dense_images = True
-        self.force_output_dense_segmentation_masks = True
 
     def get_random_transformation_batch(
         self, batch_size, images=None, **kwargs
     ):
         # sample 1 height and width for the batch
         indice = self._random_generator.random_uniform(
             shape=(1,),
@@ -153,53 +152,41 @@
             source="rel_xyxy",
             target=self.bounding_box_format,
             dtype=self.compute_dtype,
             images=images,
         )
         return bounding_boxes
 
+    def augment_ragged_segmentation_mask(
+        self, segmentation_mask, transformation, **kwargs
+    ):
+        segmentation_mask = tf.expand_dims(segmentation_mask, axis=0)
+        transformation = augmentation_utils.expand_dict_dims(
+            transformation, axis=0
+        )
+        segmentation_mask = self.augment_segmentation_masks(
+            segmentation_masks=segmentation_mask,
+            transformations=transformation,
+            **kwargs,
+        )
+        return tf.squeeze(segmentation_mask, axis=0)
+
     def augment_segmentation_masks(
         self, segmentation_masks, transformations, **kwargs
     ):
-        if isinstance(segmentation_masks, tf.RaggedTensor):
-            inputs = {
-                augmentation_utils.SEGMENTATION_MASKS: segmentation_masks,
-                "transformations": transformations,
-            }
-            segmentation_masks = tf.vectorized_map(
-                self.augment_segmentation_mask_single,
-                inputs,
-            )
-            return tf.cast(segmentation_masks, dtype=self.compute_dtype)
-        else:
-            scaled_size = transformations["scaled_sizes"]
-            new_height = scaled_size[0][0]
-            new_width = scaled_size[0][1]
-            # resize
-            segmentation_masks = tf.image.resize(
-                segmentation_masks,
-                size=(new_height, new_width),
-                method="nearest",
-            )
-        return tf.cast(segmentation_masks, dtype=self.compute_dtype)
-
-    def augment_segmentation_mask_single(self, inputs):
-        segmentation_mask = inputs.get(
-            augmentation_utils.SEGMENTATION_MASKS, None
-        )
-        transformation = inputs.get("transformations", None)
+        scaled_size = transformations["scaled_sizes"]
+        new_height = scaled_size[0][0]
+        new_width = scaled_size[0][1]
         # resize
-        scaled_size = transformation["scaled_sizes"]
-        new_height = scaled_size[0]
-        new_width = scaled_size[1]
-        return tf.image.resize(
-            segmentation_mask,
+        segmentation_masks = tf.image.resize(
+            segmentation_masks,
             size=(new_height, new_width),
             method="nearest",
         )
+        return tf.cast(segmentation_masks, dtype=self.compute_dtype)
 
     def get_config(self):
         config = super().get_config()
         config.update(
             {
                 "heights": self.heights,
                 "widths": self.widths,
```

## keras_aug/layers/augmentation/geometry/random_resize_test.py

```diff
@@ -184,7 +184,54 @@
         args.update({"heights": [4, 6, 8, 10]})
         layer = layers.RandomResize(**args, seed=2023)
 
         for _ in range(3):
             output = layer(images)
             self.assertIn(output.shape[1], [4, 6, 8, 10])
             self.assertIn(output.shape[2], [4, 6, 8, 10])
+
+    def test_dense_segmentation_masks(self):
+        images = tf.random.uniform((2, 10, 10, 3))
+        segmentation_masks = tf.random.uniform(
+            (2, 10, 10, 1), minval=0, maxval=10, dtype=tf.int32
+        )
+        args = self.regular_args.copy()
+        args.update({"heights": [4, 6, 8, 10]})
+        layer = layers.RandomResize(**args, seed=2023)
+
+        for _ in range(3):
+            output = layer(
+                {"images": images, "segmentation_masks": segmentation_masks}
+            )
+
+            self.assertTrue(isinstance(output["segmentation_masks"], tf.Tensor))
+            self.assertIn(output["segmentation_masks"].shape[1], [4, 6, 8, 10])
+            self.assertIn(output["segmentation_masks"].shape[2], [4, 6, 8, 10])
+            self.assertAllInSet(output["segmentation_masks"], tf.range(0, 10))
+
+    def test_ragged_segmentation_masks(self):
+        images = tf.ragged.stack(
+            [
+                tf.random.uniform((8, 8, 3), dtype=tf.float32),
+                tf.random.uniform((16, 8, 3), dtype=tf.float32),
+            ]
+        )
+        segmentation_masks = tf.ragged.stack(
+            [
+                tf.random.uniform((8, 8, 1), maxval=10, dtype=tf.int32),
+                tf.random.uniform((16, 8, 1), maxval=10, dtype=tf.int32),
+            ]
+        )
+        segmentation_masks = tf.cast(segmentation_masks, dtype=tf.float32)
+        args = self.regular_args.copy()
+        args.update({"heights": [4, 6, 8, 10]})
+        layer = layers.RandomResize(**args, seed=2023)
+
+        for _ in range(3):
+            output = layer(
+                {"images": images, "segmentation_masks": segmentation_masks}
+            )
+
+            self.assertTrue(isinstance(output["segmentation_masks"], tf.Tensor))
+            self.assertIn(output["segmentation_masks"].shape[1], [4, 6, 8, 10])
+            self.assertIn(output["segmentation_masks"].shape[2], [4, 6, 8, 10])
+            self.assertAllInSet(output["segmentation_masks"], tf.range(0, 10))
```

## keras_aug/layers/augmentation/geometry/random_rotate.py

```diff
@@ -5,14 +5,15 @@
 from keras_cv.utils import preprocessing as preprocessing_utils
 from tensorflow import keras
 
 from keras_aug.layers.base.vectorized_base_random_layer import (
     VectorizedBaseRandomLayer,
 )
 from keras_aug.utils import augmentation as augmentation_utils
+from keras_aug.utils import bounding_box as bounding_box_utils
 
 
 @keras.utils.register_keras_serializable(package="keras_aug")
 class RandomRotate(VectorizedBaseRandomLayer):
     """Randomly rotates the input images.
 
     The unit of the factor is degree. A positive value means rotating counter
@@ -69,17 +70,17 @@
         self.bounding_box_format = bounding_box_format
         self.seed = seed
 
     def get_random_transformation_batch(
         self, batch_size, images=None, **kwargs
     ):
         heights, widths = augmentation_utils.get_images_shape(
-            images, dtype=tf.float32
+            images, dtype=self.compute_dtype
         )
-        angles = self.factor(shape=(batch_size, 1))
+        angles = self.factor(shape=(batch_size, 1), dtype=self.compute_dtype)
         angles = angles / 360.0 * 2.0 * math.pi
         rotation_matrixes = augmentation_utils.get_rotation_matrix(
             angles, heights, widths, to_square=True
         )
         # (batch_size, 3, 3)
         return {
             "angles": angles,
@@ -93,27 +94,29 @@
         )
         image = self.augment_images(
             images=image, transformations=transformation, **kwargs
         )
         return tf.squeeze(image, axis=0)
 
     def augment_images(self, images, transformations, **kwargs):
+        original_shape = images.shape
         batch_size = tf.shape(images)[0]
         rotation_matrixes = transformations["rotation_matrixes"]
         rotation_matrixes = tf.reshape(
             rotation_matrixes, shape=(batch_size, -1)
         )
         rotation_matrixes = rotation_matrixes[:, :-1]
         images = preprocessing_utils.transform(
             images,
-            rotation_matrixes,
+            tf.cast(rotation_matrixes, dtype=tf.float32),  # must be tf.float32
             fill_mode=self.fill_mode,
             fill_value=self.fill_value,
             interpolation=self.interpolation,
         )
+        images = tf.ensure_shape(images, shape=original_shape)
         return images
 
     def augment_labels(self, labels, transformations, **kwargs):
         return labels
 
     def augment_bounding_boxes(
         self, bounding_boxes, transformations, raw_images=None, **kwargs
@@ -130,15 +133,15 @@
         )
         bounding_boxes = bounding_box.to_dense(bounding_boxes)
         bounding_boxes = bounding_box.convert_format(
             bounding_boxes,
             source=self.bounding_box_format,
             target="xyxy",
             images=raw_images,
-            dtype=tf.float32,
+            dtype=self.compute_dtype,
         )
         boxes = bounding_boxes["boxes"]
 
         # process rotations
         origin_x = widths / 2
         origin_y = heights / 2
         angles = -transformations["angles"]
@@ -168,45 +171,63 @@
         out = tf.concat([new_x, new_y], axis=3)
         min_cordinates = tf.math.reduce_min(out, axis=2)
         max_cordinates = tf.math.reduce_max(out, axis=2)
         boxes = tf.concat([min_cordinates, max_cordinates], axis=2)
 
         bounding_boxes = bounding_boxes.copy()
         bounding_boxes["boxes"] = boxes
-        bounding_boxes = bounding_box.clip_to_image(
+        bounding_boxes = bounding_box_utils.clip_to_image(
             bounding_boxes,
             bounding_box_format="xyxy",
             images=raw_images,
         )
         # coordinates cannot be float values, it is cast to int32
         bounding_boxes = bounding_box.convert_format(
             bounding_boxes,
             source="xyxy",
             target=self.bounding_box_format,
             dtype=self.compute_dtype,
             images=raw_images,
         )
         return bounding_boxes
 
+    def augment_ragged_segmentation_mask(
+        self, segmentation_mask, transformation, **kwargs
+    ):
+        segmentation_mask = tf.expand_dims(segmentation_mask, axis=0)
+        transformation = augmentation_utils.expand_dict_dims(
+            transformation, axis=0
+        )
+        segmentation_mask = self.augment_segmentation_masks(
+            segmentation_masks=segmentation_mask,
+            transformations=transformation,
+            **kwargs,
+        )
+        return tf.squeeze(segmentation_mask, axis=0)
+
     def augment_segmentation_masks(
-        self, segmentation_masks, transformations, raw_images=None, **kwargs
+        self, segmentation_masks, transformations, **kwargs
     ):
-        batch_size = tf.shape(raw_images)[0]
+        original_shape = segmentation_masks.shape
+        batch_size = tf.shape(segmentation_masks)[0]
         rotation_matrixes = transformations["rotation_matrixes"]
         rotation_matrixes = tf.reshape(
             rotation_matrixes, shape=(batch_size, -1)
         )
         rotation_matrixes = rotation_matrixes[:, :-1]
         segmentation_masks = preprocessing_utils.transform(
             segmentation_masks,
             rotation_matrixes,
             fill_mode=self.fill_mode,
             fill_value=0,
             interpolation="nearest",
         )
+        segmentation_masks = tf.ensure_shape(
+            segmentation_masks, shape=original_shape
+        )
         return segmentation_masks
 
     def get_config(self):
         config = super().get_config()
         config.update(
             {
                 "factor": self.factor,
```

## keras_aug/layers/augmentation/geometry/random_rotate_test.py

```diff
@@ -162,7 +162,52 @@
 
         # 45-degree rotation. Only verifies that no interpolation takes place.
         # 90 rotation
         args = self.no_aug_args.copy()
         args.update({"factor": (0.125, 0.125)})
         outputs = layer(inputs)
         self.assertAllInSet(outputs["segmentation_masks"], [0, 7])
+
+    def test_dense_segmentation_masks(self):
+        images = tf.random.uniform((2, 10, 10, 3))
+        segmentation_masks = tf.random.uniform(
+            (2, 10, 10, 1), minval=0, maxval=10, dtype=tf.int32
+        )
+        args = self.no_aug_args.copy()
+        args.update({"factor": (90, 90)})
+        layer = layers.RandomRotate(**args)
+
+        result = layer(
+            {"images": images, "segmentation_masks": segmentation_masks}
+        )
+
+        self.assertTrue(isinstance(result["segmentation_masks"], tf.Tensor))
+        self.assertAllInSet(result["segmentation_masks"], tf.range(0, 10))
+
+    def test_ragged_segmentation_masks(self):
+        images = tf.ragged.stack(
+            [
+                tf.random.uniform((8, 8, 3), dtype=tf.float32),
+                tf.random.uniform((16, 8, 3), dtype=tf.float32),
+            ]
+        )
+        segmentation_masks = tf.ragged.stack(
+            [
+                tf.random.uniform((8, 8, 1), maxval=10, dtype=tf.int32),
+                tf.random.uniform((16, 8, 1), maxval=10, dtype=tf.int32),
+            ]
+        )
+        segmentation_masks = tf.cast(segmentation_masks, dtype=tf.float32)
+        args = self.no_aug_args.copy()
+        args.update({"factor": (90, 90)})
+        layer = layers.RandomRotate(**args)
+
+        result = layer(
+            {"images": images, "segmentation_masks": segmentation_masks}
+        )
+
+        self.assertTrue(
+            isinstance(result["segmentation_masks"], tf.RaggedTensor)
+        )
+        self.assertAllInSet(
+            result["segmentation_masks"].to_tensor(), tf.range(0, 10)
+        )
```

## keras_aug/layers/augmentation/geometry/random_zoom_and_crop.py

```diff
@@ -3,14 +3,15 @@
 from keras_cv.utils import preprocessing as preprocessing_utils
 from tensorflow import keras
 
 from keras_aug.layers.base.vectorized_base_random_layer import (
     VectorizedBaseRandomLayer,
 )
 from keras_aug.utils import augmentation as augmentation_utils
+from keras_aug.utils import bounding_box as bounding_box_utils
 
 
 @keras.utils.register_keras_serializable(package="keras_aug")
 class RandomZoomAndCrop(VectorizedBaseRandomLayer):
     """RandomZoomAndCrop implements resize with scale distortion.
 
     RandomZoomAndCrop takes a three-step approach to size-distortion based image
@@ -152,28 +153,31 @@
         )
         image = self.augment_images(
             images=image, transformations=transformation, **kwargs
         )
         return tf.squeeze(image, axis=0)
 
     def augment_images(self, images, transformations, **kwargs):
-        # unpackage augmentation arguments
+        # tf.image.resize always output tf.float32 unless interpolation==nearest
         scaled_sizes = transformations["scaled_sizes"]
         offsets = transformations["offsets"]
         inputs_for_resize_and_crop_single_image = {
-            "images": images,
+            "images": tf.cast(images, dtype=tf.float32),
             "scaled_sizes": scaled_sizes,
             "offsets": offsets,
         }
-        scaled_images = tf.map_fn(
+        images = tf.map_fn(
             self.resize_and_crop_single_image,
             inputs_for_resize_and_crop_single_image,
             fn_output_signature=tf.float32,
         )
-        return tf.cast(scaled_images, self.compute_dtype)
+        images = tf.ensure_shape(
+            images, shape=(None, self.height, self.width, None)
+        )
+        return tf.cast(images, self.compute_dtype)
 
     def augment_labels(self, labels, transformations, **kwargs):
         return labels
 
     def augment_bounding_boxes(
         self,
         bounding_boxes,
@@ -191,61 +195,122 @@
             )
         bounding_boxes = bounding_box.to_dense(bounding_boxes)
         bounding_boxes = bounding_box.convert_format(
             bounding_boxes,
             source=self.bounding_box_format,
             target="yxyx",
             images=raw_images,
+            dtype=self.compute_dtype,
         )
 
         image_scales = tf.cast(
             transformations["image_scales"], self.compute_dtype
         )
         offsets = tf.cast(transformations["offsets"], self.compute_dtype)
 
         # Adjusts box coordinates based on image_scale and offset.
         bounding_boxes = bounding_boxes.copy()
         yxyx = bounding_boxes["boxes"]
         yxyx *= tf.tile(image_scales, [1, 2])[..., tf.newaxis, :]
         yxyx -= tf.tile(offsets, [1, 2])[..., tf.newaxis, :]
 
         bounding_boxes["boxes"] = yxyx
-        bounding_boxes = bounding_box.clip_to_image(
+        bounding_boxes = bounding_box_utils.clip_to_image(
             bounding_boxes,
             bounding_box_format="yxyx",
             images=images,
         )
         bounding_boxes = bounding_box.convert_format(
             bounding_boxes,
             source="yxyx",
             target=self.bounding_box_format,
             images=images,
         )
         return bounding_boxes
 
+    def compute_ragged_segmentation_mask_signature(self, segmentation_masks):
+        return tf.RaggedTensorSpec(
+            shape=(self.height, self.width, segmentation_masks.shape[-1]),
+            ragged_rank=1,
+            dtype=self.compute_dtype,
+        )
+
+    def augment_ragged_segmentation_mask(
+        self, segmentation_mask, transformation, **kwargs
+    ):
+        segmentation_mask = tf.expand_dims(segmentation_mask, axis=0)
+        transformation = augmentation_utils.expand_dict_dims(
+            transformation, axis=0
+        )
+        segmentation_mask = self.augment_segmentation_masks(
+            segmentation_masks=segmentation_mask,
+            transformations=transformation,
+            **kwargs,
+        )
+        return tf.squeeze(segmentation_mask, axis=0)
+
+    def augment_segmentation_masks(
+        self, segmentation_masks, transformations, **kwargs
+    ):
+        # unpackage augmentation arguments
+        scaled_sizes = transformations["scaled_sizes"]
+        offsets = transformations["offsets"]
+        inputs_for_resize_and_crop_single_segmentation_mask = {
+            "segmentation_masks": segmentation_masks,
+            "scaled_sizes": scaled_sizes,
+            "offsets": offsets,
+        }
+        segmentation_masks = tf.map_fn(
+            self.resize_and_crop_single_segmentation_mask,
+            inputs_for_resize_and_crop_single_segmentation_mask,
+            fn_output_signature=segmentation_masks.dtype,
+        )
+        segmentation_masks = tf.ensure_shape(
+            segmentation_masks, shape=(None, self.height, self.width, None)
+        )
+        return tf.cast(segmentation_masks, self.compute_dtype)
+
     def resize_and_crop_single_image(self, inputs):
         image = inputs.get("images", None)
         scaled_size = inputs.get("scaled_sizes", None)
         offset = inputs.get("offsets", None)
 
-        scaled_image = tf.image.resize(
+        image = tf.image.resize(
             image,
             tf.cast(scaled_size, tf.int32),
             method=self.interpolation,
             antialias=self.antialias,
         )
-        scaled_image = scaled_image[
+        image = image[
+            offset[0] : offset[0] + self.crop_height,
+            offset[1] : offset[1] + self.crop_width,
+            :,
+        ]
+        image = tf.image.pad_to_bounding_box(
+            image, 0, 0, self.height, self.width
+        )
+        return image
+
+    def resize_and_crop_single_segmentation_mask(self, inputs):
+        segmentation_masks = inputs.get("segmentation_masks", None)
+        scaled_size = inputs.get("scaled_sizes", None)
+        offset = inputs.get("offsets", None)
+
+        segmentation_masks = tf.image.resize(
+            segmentation_masks, tf.cast(scaled_size, tf.int32), method="nearest"
+        )
+        segmentation_masks = segmentation_masks[
             offset[0] : offset[0] + self.crop_height,
             offset[1] : offset[1] + self.crop_width,
             :,
         ]
-        scaled_image = tf.image.pad_to_bounding_box(
-            scaled_image, 0, 0, self.height, self.width
+        segmentation_masks = tf.image.pad_to_bounding_box(
+            segmentation_masks, 0, 0, self.height, self.width
         )
-        return scaled_image
+        return segmentation_masks
 
     def get_config(self):
         config = super().get_config()
         config.update(
             {
                 "height": self.height,
                 "width": self.width,
```

## keras_aug/layers/augmentation/geometry/random_zoom_and_crop_test.py

```diff
@@ -126,15 +126,15 @@
         layer = layers.RandomZoomAndCrop(
             height=self.height,
             width=self.width,
             scale_factor=(3 / 4, 4 / 3),
             bounding_box_format="rel_xyxy",
             seed=self.seed,
         )
-        output = layer(input, training=True)
+        output = layer(input)
         # the result boxes will still have the entire image in them
         expected_output = {
             "boxes": tf.ragged.constant(
                 [[[0, 0, 1, 1], [0, 0, 1, 1]], [[0, 0, 1, 1]]], dtype=tf.float32
             ),
             "classes": tf.ragged.constant(
                 [[0.0, 0.0], [0.0]],
@@ -144,7 +144,62 @@
         self.assertAllClose(
             expected_output["boxes"].to_tensor(),
             output["bounding_boxes"]["boxes"].to_tensor(),
         )
         self.assertAllClose(
             expected_output["classes"], output["bounding_boxes"]["classes"]
         )
+
+    def test_dense_segmentation_masks(self):
+        images = tf.random.uniform((2, 10, 10, 3))
+        segmentation_masks = tf.random.uniform(
+            (2, 10, 10, 1), minval=0, maxval=10, dtype=tf.int32
+        )
+        layer = layers.RandomZoomAndCrop(
+            height=self.height,
+            width=self.width,
+            scale_factor=(3 / 4, 4 / 3),
+            bounding_box_format="rel_xyxy",
+            seed=self.seed,
+        )
+
+        result = layer(
+            {"images": images, "segmentation_masks": segmentation_masks}
+        )
+
+        self.assertTrue(isinstance(result["segmentation_masks"], tf.Tensor))
+        self.assertEqual(
+            result["segmentation_masks"].shape[1:3], (self.height, self.width)
+        )
+        self.assertAllInSet(result["segmentation_masks"], tf.range(0, 10))
+
+    def test_ragged_segmentation_masks(self):
+        images = tf.ragged.stack(
+            [
+                tf.random.uniform((8, 8, 3), dtype=tf.float32),
+                tf.random.uniform((16, 8, 3), dtype=tf.float32),
+            ]
+        )
+        segmentation_masks = tf.ragged.stack(
+            [
+                tf.random.uniform((8, 8, 1), maxval=10, dtype=tf.int32),
+                tf.random.uniform((16, 8, 1), maxval=10, dtype=tf.int32),
+            ]
+        )
+        segmentation_masks = tf.cast(segmentation_masks, dtype=tf.float32)
+        layer = layers.RandomZoomAndCrop(
+            height=self.height,
+            width=self.width,
+            scale_factor=(3 / 4, 4 / 3),
+            bounding_box_format="rel_xyxy",
+            seed=self.seed,
+        )
+
+        result = layer(
+            {"images": images, "segmentation_masks": segmentation_masks}
+        )
+
+        self.assertTrue(isinstance(result["segmentation_masks"], tf.Tensor))
+        self.assertEqual(
+            result["segmentation_masks"].shape[1:3], (self.height, self.width)
+        )
+        self.assertAllInSet(result["segmentation_masks"], tf.range(0, 10))
```

## keras_aug/layers/augmentation/mix/cut_mix.py

```diff
@@ -5,14 +5,15 @@
 
 from keras_aug.layers.base.vectorized_base_random_layer import (
     VectorizedBaseRandomLayer,
 )
 from keras_aug.utils.augmentation import BATCHED
 from keras_aug.utils.augmentation import H_AXIS
 from keras_aug.utils.augmentation import LABELS
+from keras_aug.utils.augmentation import SEGMENTATION_MASKS
 from keras_aug.utils.augmentation import W_AXIS
 
 
 @keras.utils.register_keras_serializable(package="keras_aug")
 class CutMix(VectorizedBaseRandomLayer):
     """CutMix implements the CutMix data augmentation technique.
 
@@ -122,14 +123,37 @@
         bounding_box_area = cut_heights * cut_widths
         lambda_sample = 1.0 - bounding_box_area / (height * width)
         lambda_sample = tf.reshape(lambda_sample, [-1, 1])
 
         labels = lambda_sample * labels + (1.0 - lambda_sample) * cutmix_labels
         return labels
 
+    def augment_segmentation_masks(
+        self, segmentation_masks, transformations, **kwargs
+    ):
+        if isinstance(segmentation_masks, tf.RaggedTensor):
+            raise ValueError(
+                "CutMix expects dense segmentation_masks. Received: "
+                f"segmentation_masks type: {type(segmentation_masks)}"
+            )
+        permutation_order = transformations["permutation_order"]
+        center_xs = transformations["center_xs"]
+        center_ys = transformations["center_ys"]
+        cut_heights = transformations["cut_heights"]
+        cut_widths = transformations["cut_widths"]
+        segmentation_masks = fill_utils.fill_rectangle(
+            segmentation_masks,
+            center_xs,
+            center_ys,
+            cut_widths,
+            cut_heights,
+            tf.gather(segmentation_masks, permutation_order),
+        )
+        return segmentation_masks
+
     def _batch_augment(self, inputs):
         self._validate_inputs(inputs)
         return super()._batch_augment(inputs)
 
     def call(self, inputs):
         _, metadata = self._format_inputs(inputs)
         if metadata[BATCHED] is not True:
@@ -139,21 +163,19 @@
                 "will not behave as expected. Please call the layer with 2 "
                 "or more samples."
             )
         return super().call(inputs=inputs)
 
     def _validate_inputs(self, inputs):
         labels = inputs.get(LABELS, None)
-        if labels is None:
+        segmentation_masks = inputs.get(SEGMENTATION_MASKS, None)
+        if labels is None and segmentation_masks is None:
             raise ValueError(
-                "CutMix expects 'labels' to be present in its inputs. "
-                "CutMix relies on both images an labels. "
-                "Please pass a dictionary with keys 'images' "
-                "containing the image Tensor, and 'labels' containing "
-                "the classification labels. "
+                "CutMix expects `labels` or `segmentation_masks` to be present "
+                "in its inputs. "
                 "For example, `cut_mix({'images': images, 'labels': labels})`."
             )
 
     def get_config(self):
         config = super().get_config()
         config.update({"alpha": self.alpha, "seed": self.seed})
         return config
```

## keras_aug/layers/augmentation/mix/cut_mix_test.py

```diff
@@ -78,19 +78,49 @@
             _ = layer(inputs)
 
     def test_missing_labels(self):
         xs = tf.ones((2, 4, 4, 3))
         inputs = {"images": xs}
         layer = layers.CutMix()
 
-        with self.assertRaisesRegexp(ValueError, "CutMix expects 'labels'"):
+        with self.assertRaisesRegexp(ValueError, "CutMix expects `labels`"):
             _ = layer(inputs)
 
     def test_image_input(self):
         xs = tf.ones((2, 4, 4, 3))
         layer = layers.CutMix()
 
         with self.assertRaisesRegexp(
             ValueError,
-            "CutMix expects 'labels' to be present in its inputs",
+            "CutMix expects `labels` or `segmentation_masks` to be present",
         ):
             _ = layer(xs)
+
+    def test_cut_mix_call_segmentation_masks(self):
+        xs = tf.cast(
+            tf.stack(
+                [2 * tf.ones((40, 40, 3)), tf.ones((40, 40, 3))],
+                axis=0,
+            ),
+            tf.float32,
+        )
+        masks = tf.cast(
+            tf.stack(
+                [2 * tf.ones((40, 40, 1)), tf.ones((40, 40, 1))],
+                axis=0,
+            ),
+            tf.float32,
+        )
+        ys = tf.one_hot(tf.constant([0, 1]), 2)
+        layer = layers.CutMix(seed=2024)
+
+        outputs = layer(
+            {"images": xs, "labels": ys, "segmentation_masks": masks}
+        )
+        xs, ys = outputs["images"], outputs["labels"]
+        masks = outputs["segmentation_masks"]
+
+        # At least some pixels should be replaced in the CutMix operation
+        self.assertTrue(tf.math.reduce_any(masks[0] == 1.0))
+        self.assertTrue(tf.math.reduce_any(masks[0] == 2.0))
+        self.assertTrue(tf.math.reduce_any(masks[1] == 1.0))
+        self.assertTrue(tf.math.reduce_any(masks[1] == 2.0))
```

## keras_aug/layers/augmentation/mix/mix_up.py

```diff
@@ -57,14 +57,19 @@
         lambda_samples = tf.cast(lambda_samples, dtype=self.compute_dtype)
         return {
             "permutation_order": permutation_order,
             "lambda_samples": lambda_samples,
         }
 
     def augment_images(self, images, transformations, **kwargs):
+        if isinstance(images, tf.RaggedTensor):
+            raise ValueError(
+                "MixUp expects dense images. Received: images type: "
+                f"{type(images)}"
+            )
         permutation_order = transformations["permutation_order"]
         lambda_samples = transformations["lambda_samples"]
         mixup_images = tf.gather(images, permutation_order)
         mixup_images = tf.cast(mixup_images, dtype=self.compute_dtype)
         images = lambda_samples * images + (1.0 - lambda_samples) * mixup_images
         return images
 
@@ -106,23 +111,21 @@
             )
         return super().call(inputs=inputs)
 
     def _validate_inputs(self, inputs):
         images = inputs.get("images", None)
         labels = inputs.get("labels", None)
         bounding_boxes = inputs.get("bounding_boxes", None)
-
         if images is None or (labels is None and bounding_boxes is None):
             raise ValueError(
                 "MixUp expects inputs in a dictionary with format "
                 '{"images": images, "labels": labels}. or'
                 '{"images": images, "bounding_boxes": bounding_boxes}'
                 f"Got: inputs = {inputs}."
             )
-
         if bounding_boxes is not None:
             _ = bounding_box.validate_format(bounding_boxes)
 
     def sample_from_beta(self, alpha, beta, shape):
         sample_alpha = tf.random.stateless_gamma(
             shape,
             alpha=alpha,
```

## keras_aug/layers/augmentation/mix/mosaic.py

```diff
@@ -2,14 +2,15 @@
 from keras_cv import bounding_box
 from tensorflow import keras
 
 from keras_aug.layers.base.vectorized_base_random_layer import (
     VectorizedBaseRandomLayer,
 )
 from keras_aug.utils import augmentation as augmentation_utils
+from keras_aug.utils import bounding_box as bounding_box_utils
 from keras_aug.utils.augmentation import BATCHED
 from keras_aug.utils.augmentation import BOUNDING_BOXES
 from keras_aug.utils.augmentation import IMAGES
 from keras_aug.utils.augmentation import LABELS
 
 
 @keras.utils.register_keras_serializable(package="keras_aug")
@@ -108,28 +109,28 @@
 
         return {
             "permutation_order": permutation_order,
             "mosaic_centers": mosaic_centers,
         }
 
     def augment_images(self, images, transformations, **kwargs):
-        is_ragged_input = isinstance(images, tf.RaggedTensor)
         permutation_order = transformations["permutation_order"]
         mosaic_images = tf.gather(images, permutation_order)
         inputs_for_pad_and_mosaic_single_image = {
             "transformations": transformations,
             IMAGES: mosaic_images,
         }
         images = tf.map_fn(
             self.get_mosaic_single_image,
             inputs_for_pad_and_mosaic_single_image,
             fn_output_signature=self.compute_dtype,
         )
-        if is_ragged_input:
-            images = tf.RaggedTensor.from_tensor(images)
+        images = tf.ensure_shape(
+            images, shape=(None, self.height, self.width, None)
+        )
         return images
 
     def augment_labels(self, labels, transformations, images=None, **kwargs):
         is_ragged_labels = isinstance(labels, tf.RaggedTensor)
         if is_ragged_labels:
             labels = labels.to_tensor()
         labels = tf.cast(labels, dtype=self.compute_dtype)
@@ -228,15 +229,15 @@
 
         boxes_for_mosaic = tf.reshape(boxes_for_mosaic, [batch_size, -1, 4])
         classes_for_mosaic = tf.reshape(classes_for_mosaic, [batch_size, -1])
         boxes_for_mosaic = {
             "boxes": boxes_for_mosaic,
             "classes": classes_for_mosaic,
         }
-        boxes_for_mosaic = bounding_box.clip_to_image(
+        boxes_for_mosaic = bounding_box_utils.clip_to_image(
             boxes_for_mosaic,
             bounding_box_format="xyxy",
             image_shape=(self.height, self.width, None),
         )
         boxes_for_mosaic = bounding_box.convert_format(
             boxes_for_mosaic,
             source="xyxy",
```

## keras_aug/layers/augmentation/regularization/random_erase.py

```diff
@@ -148,34 +148,14 @@
             rectangle_fills,
         )
         return images
 
     def augment_labels(self, labels, transformations, **kwargs):
         return labels
 
-    def augment_bounding_boxes(self, bounding_boxes, transformations, **kwargs):
-        raise NotImplementedError(
-            "The effect of RandomErase for bounding boxes is not clear."
-            "Feel free to file the issue if you have the idea about it."
-        )
-
-    def augment_segmentation_masks(
-        self, segmentation_masks, transformations, **kwargs
-    ):
-        raise NotImplementedError(
-            "The effect of RandomErase for segmentation masks is not clear."
-            "Feel free to file the issue if you have the idea about it."
-        )
-
-    def augment_keypoints(self, keypoints, transformations, **kwargs):
-        raise NotImplementedError(
-            "The effect of RandomErase for keypoints is not clear."
-            "Feel free to file the issue if you have the idea about it."
-        )
-
     def compute_rectangle_fills(self, inputs):
         if self.fill_mode == "constant":
             fills = tf.ones(tf.shape(inputs), dtype=self.compute_dtype)
             fills = (
                 fills * self.fill_value[tf.newaxis, tf.newaxis, tf.newaxis, ...]
             )
         else:
```

## keras_aug/layers/augmentation/regularization/random_grid_mask.py

```diff
@@ -208,28 +208,14 @@
 
     def augment_labels(self, labels, transformations, **kwargs):
         return labels
 
     def augment_bounding_boxes(self, bounding_boxes, transformations, **kwargs):
         return bounding_boxes
 
-    def augment_segmentation_masks(
-        self, segmentation_masks, transformations, **kwargs
-    ):
-        raise NotImplementedError(
-            "The effect of RandomGridMask for segmentation masks is not clear."
-            "Feel free to file the issue if you have the idea about it."
-        )
-
-    def augment_keypoints(self, keypoints, transformations, **kwargs):
-        raise NotImplementedError(
-            "The effect of RandomGridMask for keypoints is not clear."
-            "Feel free to file the issue if you have the idea about it."
-        )
-
     def compute_grid_mask_single_image(self, inputs):
         mask_side_len = inputs.get("mask_side_lens", None)[0]
         rectangle_side_len = inputs.get("rectangle_side_lens", None)[0]
         unit_size = inputs.get("unit_sizes", None)[0]
         delta_x = inputs.get("delta_xs", None)[0]
         delta_y = inputs.get("delta_ys", None)[0]
```

## keras_aug/layers/augmentation/utility/random_apply.py

```diff
@@ -111,42 +111,37 @@
     def _batch_augment(self, inputs):
         images = inputs.get(IMAGES, None)
         batch_size = tf.shape(images)[0]
         probs = self.get_random_transformation_batch(batch_size)
         if self.batchwise:
             result = self.layer(inputs) if probs[0] < self.rate else inputs
         else:
+            # make bounding_boxes to dense first
+            if BOUNDING_BOXES in inputs:
+                inputs[BOUNDING_BOXES] = bounding_box.to_dense(
+                    inputs[BOUNDING_BOXES]
+                )
             inputs_for_augment = {"inputs": inputs, "probs": probs}
             result = tf.map_fn(
                 self.augment,
                 inputs_for_augment,
                 fn_output_signature=self.compute_inputs_signature(inputs),
             )
-
-        # workaround: force bounding_boxes to be ragged
-        # sometimes tf will output tf.Tensor instead of tf.RaggedTensor
-        # the root cause is not clear right now
-        bounding_boxes = result.get(BOUNDING_BOXES, None)
-        if bounding_boxes is not None:
-            bounding_boxes = bounding_box.to_dense(bounding_boxes)
-            bounding_boxes = bounding_box.to_ragged(bounding_boxes)
-            result[BOUNDING_BOXES] = bounding_boxes
-
         return result
 
     def augment(self, inputs):
         input = inputs.get("inputs", None)
         prob = inputs.get("probs", None)
         if prob < self.rate:
             result = self.layer(input)
         else:
             result = input
         if BOUNDING_BOXES in result:
             result[BOUNDING_BOXES] = bounding_box.to_ragged(
-                result[BOUNDING_BOXES]
+                result[BOUNDING_BOXES], dtype=self.compute_dtype
             )
         return result
 
     def get_config(self):
         config = super().get_config()
         config.update(
             {
```

## keras_aug/layers/augmentation/utility/random_choice.py

```diff
@@ -3,14 +3,15 @@
 import tensorflow as tf
 from keras_cv import bounding_box
 from tensorflow import keras
 
 from keras_aug.layers.base.vectorized_base_random_layer import (
     VectorizedBaseRandomLayer,
 )
+from keras_aug.utils import augmentation as augmentation_utils
 from keras_aug.utils.augmentation import BOUNDING_BOXES
 from keras_aug.utils.augmentation import CUSTOM_ANNOTATIONS
 from keras_aug.utils.augmentation import IMAGES
 from keras_aug.utils.augmentation import KEYPOINTS
 from keras_aug.utils.augmentation import LABELS
 from keras_aug.utils.augmentation import SEGMENTATION_MASKS
 
@@ -115,48 +116,44 @@
         transformations = self.get_random_transformation_batch(batch_size)
         if self.batchwise:
             selected_op_idx = transformations[0]
             result = self.augment(
                 {"inputs": inputs, "transformations": selected_op_idx}
             )
         else:
+            # make bounding_boxes to dense first
+            if BOUNDING_BOXES in inputs:
+                inputs[BOUNDING_BOXES] = bounding_box.to_dense(
+                    inputs[BOUNDING_BOXES]
+                )
             inputs_for_random_choice_single_input = {
                 "inputs": inputs,
                 "transformations": transformations,
             }
             result = tf.map_fn(
                 self.augment,
                 inputs_for_random_choice_single_input,
                 fn_output_signature=self.compute_inputs_signature(inputs),
             )
-
-        # workaround: force bounding_boxes to be ragged
-        # sometimes tf will output tf.Tensor instead of tf.RaggedTensor
-        # the root cause is not clear right now
-        bounding_boxes = result.get(BOUNDING_BOXES, None)
-        if bounding_boxes is not None:
-            bounding_boxes = bounding_box.to_dense(bounding_boxes)
-            bounding_boxes = bounding_box.to_ragged(bounding_boxes)
-            result[BOUNDING_BOXES] = bounding_boxes
-
         return result
 
     def augment(self, inputs):
         input = inputs.get("inputs")
         selected_op_idx = inputs.get("transformations")
         # construct branch_fns
         branch_fns = {}
         for idx, layer in enumerate(self.layers):
             branch_fns[idx] = partial(layer, input)
         # augment
         result = tf.switch_case(selected_op_idx, branch_fns=branch_fns)
         if BOUNDING_BOXES in result:
             result[BOUNDING_BOXES] = bounding_box.to_ragged(
-                result[BOUNDING_BOXES]
+                result[BOUNDING_BOXES], dtype=self.compute_dtype
             )
+        result = augmentation_utils.cast_to(result, dtype=self.compute_dtype)
         return result
 
     def get_config(self):
         config = super().get_config()
         config.update(
             {
                 "layers": self.layers,
```

## keras_aug/layers/base/vectorized_base_random_layer.py

```diff
@@ -74,26 +74,24 @@
     structure as the inputs.
 
     The ``call()`` will unpack the inputs, forward to the correct function, and
     pack the output back to the same structure as the inputs.
 
     By default, the dense or ragged status of the output will be preserved.
     However, you can override this behavior by setting
-    ``self.force_output_dense_images = True``,
-    ``self.force_output_dense_segmentation_masks = True`` in your ``__init__()``
+    ``self.force_output_dense_images = True`` in your ``__init__()``
     method. When enabled, images and segmentation masks will be converted to
     dense tensor by ``to_tensor()`` if ragged.
 
     .. code-block:: python
 
         class SubclassLayer(VectorizedBaseImageAugmentationLayer):
             def __init__(self):
                 super().__init__()
                 self.force_output_dense_images = True
-                self.force_output_dense_segmentation_masks = True
 
     Note that since the randomness is also a common functionality, this layer
     also includes a keras.backend.RandomGenerator, which can be used to
     produce the random numbers. The random number generator is stored in the
     `self._random_generator` attribute.
 
     References:
@@ -129,27 +127,14 @@
         """Control whether to force outputting of dense images."""
         return getattr(self, "_force_output_dense_images", False)
 
     @force_output_dense_images.setter
     def force_output_dense_images(self, force_output_dense_images):
         self._force_output_dense_images = force_output_dense_images
 
-    @property
-    def force_output_dense_segmentation_masks(self):
-        """Control whether to force outputting of dense segmentation masks."""
-        return getattr(self, "_force_output_dense_segmentation_masks", False)
-
-    @force_output_dense_segmentation_masks.setter
-    def force_output_dense_segmentation_masks(
-        self, force_output_dense_segmentation_masks
-    ):
-        self._force_output_dense_segmentation_masks = (
-            force_output_dense_segmentation_masks
-        )
-
     def get_random_transformation_batch(
         self,
         batch_size,
         images=None,
         labels=None,
         bounding_boxes=None,
         keypoints=None,
@@ -175,31 +160,45 @@
             `augment_labels` and `augment_bounding_boxes` as the
             `transformations` parameter.
         """
         # Required to work with map_fn in the ragged cast.
         return tf.zeros((batch_size))
 
     def compute_ragged_image_signature(self, images):
-        """Computes the output image signature for the `augment_image()`
-        function.
+        """Computes the output image signature for the
+        `_unwrap_ragged_image_call()` function.
 
         Must be overridden to return tensors with different shapes than the
         input images. By default, returns either a `tf.RaggedTensorSpec`
         matching the input image spec, or a `tf.TensorSpec` matching the input
         image spec.
         """
-        ragged_spec = tf.RaggedTensorSpec(
+        return tf.RaggedTensorSpec(
             shape=images.shape[1:],
             ragged_rank=1,
             dtype=self.compute_dtype,
         )
-        return ragged_spec
+
+    def compute_ragged_segmentation_mask_signature(self, segmentation_maks):
+        """Computes the output segmentation_mask signature for the
+        `_unwrap_ragged_segmentation_call()` function.
+
+        Must be overridden to return tensors with different shapes than the
+        input images. By default, returns either a `tf.RaggedTensorSpec`
+        matching the input image spec, or a `tf.TensorSpec` matching the input
+        image spec.
+        """
+        return tf.RaggedTensorSpec(
+            shape=segmentation_maks.shape[1:],
+            ragged_rank=1,
+            dtype=self.compute_dtype,
+        )
 
     def augment_ragged_image(self, image, transformation, **kwargs):
-        """Augment an image from a ragged image batch during training.
+        """Augment an image from a ragged image batch.
 
         This method accepts a single Dense image Tensor, and returns a Dense
         image. The resulting images are then stacked back into a ragged image
         batch. The behavior of this method should be identical to that of
         `augment_images()` but is to operate on a batch-wise basis.
 
         Args:
@@ -211,15 +210,15 @@
 
         Returns:
             Augmented image.
         """
         raise NotImplementedError(
             "A ragged image batch was passed to layer of type "
             f"`{type(self).__name__}`. This layer does not implement "
-            "`augment_ragged_image()`. If this is a `keras_cv`, open a GitHub "
+            "`augment_ragged_image()`. If this is a `keras_aug`, open a GitHub "
             "issue requesting Ragged functionality on the layer titled: "
             f"'`{type(self).__name__}`: ragged image support'. If this is a "
             "custom layer, implement the `augment_ragged_image()` method."
         )
 
     def augment_images(self, images, transformations, **kwargs):
         """Augment a batch of images.
@@ -282,14 +281,36 @@
                 mask.
 
         Returns:
             output 3D tensor, which will be forward to `layer.call()`.
         """
         raise NotImplementedError()
 
+    def augment_ragged_segmentation_mask(
+        self, segmentation_mask, transformation, **kwargs
+    ):
+        """Augment an image from a ragged segmentation mask batch.
+
+        This method accepts a single Dense image Tensor, and returns a Dense
+        image. The resulting images are then stacked back into a ragged image
+        batch. The behavior of this method should be identical to that of
+        `augment_segmentation_masks()` but is to operate on a batch-wise basis.
+
+        Args:
+            segmentation_mask: a single image from the batch
+            transformation: a single transformation sampled from
+                `get_random_transformations()`.
+            kwargs: all the other call arguments (i.e. bounding_boxes, labels,
+                etc.).
+
+        Returns:
+            Augmented segmentation mask.
+        """
+        return segmentation_mask
+
     def augment_segmentation_masks(
         self, segmentation_masks, transformations, **kwargs
     ):
         """Augment a batch of images' segmentation masks.
 
         Args:
             segmentation_masks: 4D segmentation mask input tensor to the layer.
@@ -327,26 +348,44 @@
 
     def _unwrap_ragged_image_call(self, inputs):
         images = inputs.get(IMAGES, None)
         labels = inputs.get(LABELS, None)
         bounding_boxes = inputs.get(BOUNDING_BOXES, None)
         keypoints = inputs.get(KEYPOINTS, None)
         segmentation_masks = inputs.get(SEGMENTATION_MASKS, None)
-        transformation = inputs.get("transformations")
+        transformations = inputs.get("transformations")
         images = images.to_tensor()
         images = self.augment_ragged_image(
             image=images,
             label=labels,
             bounding_boxes=bounding_boxes,
             keypoints=keypoints,
             segmentation_mask=segmentation_masks,
-            transformation=transformation,
+            transformation=transformations,
         )
         return tf.RaggedTensor.from_tensor(images)
 
+    def _unwrap_ragged_segmentation_mask_call(self, inputs):
+        segmentation_masks = inputs.get(SEGMENTATION_MASKS, None)
+        transformations = inputs.get("transformations")
+        labels = inputs.get(LABELS, None)
+        bounding_boxes = inputs.get(BOUNDING_BOXES, None)
+        images = inputs.get(IMAGES, None)
+        raw_images = inputs.get("raw_images", None)
+        segmentation_masks = segmentation_masks.to_tensor()
+        segmentation_masks = self.augment_ragged_segmentation_mask(
+            segmentation_mask=segmentation_masks,
+            transformation=transformations,
+            label=labels,
+            bounding_boxes=bounding_boxes,
+            image=images,
+            raw_image=raw_images,
+        )
+        return tf.RaggedTensor.from_tensor(segmentation_masks)
+
     def _batch_augment(self, inputs):
         images = inputs.get(IMAGES, None)
         raw_images = images
         labels = inputs.get(LABELS, None)
         bounding_boxes = inputs.get(BOUNDING_BOXES, None)
         keypoints = inputs.get(KEYPOINTS, None)
         segmentation_masks = inputs.get(SEGMENTATION_MASKS, None)
@@ -401,40 +440,59 @@
             bounding_boxes = self.augment_bounding_boxes(
                 bounding_boxes,
                 transformations=transformations,
                 labels=labels,
                 images=images,
                 raw_images=raw_images,
             )
-            bounding_boxes = bounding_box.to_ragged(bounding_boxes)
+            bounding_boxes = bounding_box.to_ragged(
+                bounding_boxes, dtype=self.compute_dtype
+            )
             result[BOUNDING_BOXES] = bounding_boxes
 
         if keypoints is not None:
             keypoints = self.augment_keypoints(
                 keypoints,
                 transformations=transformations,
                 labels=labels,
                 bounding_boxes=bounding_boxes,
                 images=images,
                 raw_images=raw_images,
             )
             result[KEYPOINTS] = keypoints
 
         if segmentation_masks is not None:
-            segmentation_masks = self.augment_segmentation_masks(
-                segmentation_masks,
-                transformations=transformations,
-                labels=labels,
-                bounding_boxes=bounding_boxes,
-                images=images,
-                raw_images=raw_images,
-            )
             if (
-                isinstance(images, tf.RaggedTensor)
-                and self.force_output_dense_segmentation_masks
+                isinstance(segmentation_masks, tf.RaggedTensor)
+                and not self.force_no_unwrap_ragged_image_call
+            ):
+                inputs_for_raggeds = {
+                    "transformations": transformations,
+                    "raw_images": raw_images,
+                    **inputs,
+                }
+                segmentation_masks = tf.map_fn(
+                    self._unwrap_ragged_segmentation_mask_call,
+                    inputs_for_raggeds,
+                    fn_output_signature=self.compute_ragged_segmentation_mask_signature(  # noqa: E501
+                        segmentation_masks
+                    ),
+                )
+            else:
+                segmentation_masks = self.augment_segmentation_masks(
+                    segmentation_masks,
+                    transformations=transformations,
+                    labels=labels,
+                    bounding_boxes=bounding_boxes,
+                    images=images,
+                    raw_images=raw_images,
+                )
+            if (
+                isinstance(segmentation_masks, tf.RaggedTensor)
+                and self.force_output_dense_images
             ):
                 segmentation_masks = segmentation_masks.to_tensor()
             result[SEGMENTATION_MASKS] = segmentation_masks
 
         if custom_annotations is not None:
             custom_annotations = self.augment_custom_annotations(
                 custom_annotations,
```

## keras_aug/layers/base/vectorized_base_random_layer_test.py

```diff
@@ -9,24 +9,24 @@
 
 class VectorizedRandomAddLayer(VectorizedBaseRandomLayer):
     def __init__(self, add_range=(0.0, 1.0), fixed_value=None, **kwargs):
         super().__init__(**kwargs)
         self.add_range = add_range
         self.fixed_value = fixed_value
 
-    def augment_ragged_image(self, image, transformation, **kwargs):
-        return image + transformation[None, None]
-
     def get_random_transformation_batch(self, batch_size, **kwargs):
         if self.fixed_value:
             return tf.ones((batch_size,)) * self.fixed_value
         return self._random_generator.random_uniform(
             (batch_size,), minval=self.add_range[0], maxval=self.add_range[1]
         )
 
+    def augment_ragged_image(self, image, transformation, **kwargs):
+        return image + transformation[None, None, None]
+
     def augment_images(self, images, transformations, **kwargs):
         return images + transformations[:, None, None, None]
 
     def augment_labels(self, labels, transformations, **kwargs):
         return labels + transformations[:, None]
 
     def augment_bounding_boxes(self, bounding_boxes, transformations, **kwargs):
@@ -34,27 +34,50 @@
             "boxes": bounding_boxes["boxes"] + transformations[:, None, None],
             "classes": bounding_boxes["classes"] + transformations[:, None],
         }
 
     def augment_keypoints(self, keypoints, transformations, **kwargs):
         return keypoints + transformations[:, None, None]
 
+    def augment_ragged_segmentation_mask(
+        self, segmentation_mask, transformation, **kwargs
+    ):
+        return segmentation_mask + transformation[None, None, None]
+
     def augment_segmentation_masks(
         self, segmentation_masks, transformations, **kwargs
     ):
         return segmentation_masks + transformations[:, None, None, None]
 
 
 TF_ALL_TENSOR_TYPES = (tf.Tensor, tf.RaggedTensor, tf.SparseTensor)
 
 
 class VectorizedAssertionLayer(VectorizedBaseRandomLayer):
     def __init__(self, **kwargs):
         super().__init__(**kwargs)
 
+    def get_random_transformation_batch(
+        self,
+        batch_size,
+        images=None,
+        labels=None,
+        bounding_boxes=None,
+        keypoints=None,
+        segmentation_masks=None,
+        **kwargs
+    ):
+        assert isinstance(images, TF_ALL_TENSOR_TYPES)
+        assert isinstance(labels, TF_ALL_TENSOR_TYPES)
+        assert isinstance(bounding_boxes["boxes"], TF_ALL_TENSOR_TYPES)
+        assert isinstance(bounding_boxes["classes"], TF_ALL_TENSOR_TYPES)
+        assert isinstance(keypoints, TF_ALL_TENSOR_TYPES)
+        assert isinstance(segmentation_masks, TF_ALL_TENSOR_TYPES)
+        return self._random_generator.random_uniform((batch_size,))
+
     def augment_ragged_image(
         self,
         image,
         label=None,
         bounding_boxes=None,
         keypoints=None,
         segmentation_mask=None,
@@ -66,32 +89,14 @@
         assert isinstance(bounding_boxes["boxes"], TF_ALL_TENSOR_TYPES)
         assert isinstance(bounding_boxes["classes"], TF_ALL_TENSOR_TYPES)
         assert isinstance(keypoints, TF_ALL_TENSOR_TYPES)
         assert isinstance(segmentation_mask, TF_ALL_TENSOR_TYPES)
         assert isinstance(transformation, TF_ALL_TENSOR_TYPES)
         return image
 
-    def get_random_transformation_batch(
-        self,
-        batch_size,
-        images=None,
-        labels=None,
-        bounding_boxes=None,
-        keypoints=None,
-        segmentation_masks=None,
-        **kwargs
-    ):
-        assert isinstance(images, TF_ALL_TENSOR_TYPES)
-        assert isinstance(labels, TF_ALL_TENSOR_TYPES)
-        assert isinstance(bounding_boxes["boxes"], TF_ALL_TENSOR_TYPES)
-        assert isinstance(bounding_boxes["classes"], TF_ALL_TENSOR_TYPES)
-        assert isinstance(keypoints, TF_ALL_TENSOR_TYPES)
-        assert isinstance(segmentation_masks, TF_ALL_TENSOR_TYPES)
-        return self._random_generator.random_uniform((batch_size,))
-
     def augment_images(
         self,
         images,
         transformations=None,
         bounding_boxes=None,
         labels=None,
         **kwargs
@@ -152,14 +157,33 @@
         assert isinstance(labels, TF_ALL_TENSOR_TYPES)
         assert isinstance(bounding_boxes["boxes"], TF_ALL_TENSOR_TYPES)
         assert isinstance(bounding_boxes["classes"], TF_ALL_TENSOR_TYPES)
         assert isinstance(images, TF_ALL_TENSOR_TYPES)
         assert isinstance(raw_images, TF_ALL_TENSOR_TYPES)
         return keypoints
 
+    def augment_ragged_segmentation_mask(
+        self,
+        segmentation_mask,
+        transformation=None,
+        label=None,
+        bounding_boxes=None,
+        image=None,
+        raw_image=None,
+        **kwargs
+    ):
+        assert isinstance(segmentation_mask, TF_ALL_TENSOR_TYPES)
+        assert isinstance(transformation, TF_ALL_TENSOR_TYPES)
+        assert isinstance(label, TF_ALL_TENSOR_TYPES)
+        assert isinstance(bounding_boxes["boxes"], TF_ALL_TENSOR_TYPES)
+        assert isinstance(bounding_boxes["classes"], TF_ALL_TENSOR_TYPES)
+        assert isinstance(image, TF_ALL_TENSOR_TYPES)
+        assert isinstance(raw_image, TF_ALL_TENSOR_TYPES)
+        return segmentation_mask
+
     def augment_segmentation_masks(
         self,
         segmentation_masks,
         transformations=None,
         labels=None,
         bounding_boxes=None,
         images=None,
@@ -549,14 +573,14 @@
         segmentation_masks = tf.ragged.stack(
             [
                 np.random.randint(0, 10, size=(8, 8, 1)).astype("float32"),
                 np.random.randint(0, 10, size=(16, 8, 1)).astype("float32"),
             ]
         )
         add_layer = VectorizedRandomAddLayer(fixed_value=0.5)
-        add_layer.force_output_dense_segmentation_masks = True
+        add_layer.force_output_dense_images = True
 
         result = add_layer(
             {"images": images, "segmentation_masks": segmentation_masks}
         )
 
         self.assertTrue(isinstance(result["segmentation_masks"], tf.Tensor))
```

## keras_aug/layers/preprocessing/__init__.py

```diff
@@ -4,7 +4,10 @@
 from keras_aug.layers.preprocessing.intensity.auto_contrast import AutoContrast
 from keras_aug.layers.preprocessing.intensity.equalize import Equalize
 from keras_aug.layers.preprocessing.intensity.grayscale import Grayscale
 from keras_aug.layers.preprocessing.intensity.identity import Identity
 from keras_aug.layers.preprocessing.intensity.invert import Invert
 from keras_aug.layers.preprocessing.intensity.normalize import Normalize
 from keras_aug.layers.preprocessing.intensity.rescale import Rescale
+from keras_aug.layers.preprocessing.utility.sanitize_bounding_box import (
+    SanitizeBoundingBox,
+)
```

## keras_aug/layers/preprocessing/geometry/center_crop.py

```diff
@@ -53,15 +53,14 @@
         self.bounding_box_min_area_ratio = bounding_box_min_area_ratio
         self.bounding_box_max_aspect_ratio = bounding_box_max_aspect_ratio
         self.seed = seed
 
         # set force_output_dense_images=True because the output images must
         # have same shape (B, height, width, C)
         self.force_output_dense_images = True
-        self.force_output_dense_segmentation_masks = True
 
     def get_random_transformation_batch(
         self, batch_size, images=None, **kwargs
     ):
         heights, widths = augmentation_utils.get_images_shape(images)
 
         tops = tf.where(
@@ -132,14 +131,17 @@
         images = tf.image.crop_to_bounding_box(
             images,
             offset_height,
             offset_width,
             self.height,
             self.width,
         )
+        images = tf.ensure_shape(
+            images, shape=(None, self.height, self.width, None)
+        )
         return images
 
     def augment_labels(self, labels, transformations, **kwargs):
         return labels
 
     def augment_bounding_boxes(
         self,
@@ -180,15 +182,15 @@
         y1s += tf.expand_dims(pad_tops - offset_heights, axis=1)
         x2s += tf.expand_dims(pad_lefts - offset_widths, axis=1)
         y2s += tf.expand_dims(pad_tops - offset_heights, axis=1)
         outputs = tf.concat([x1s, y1s, x2s, y2s], axis=-1)
 
         bounding_boxes = bounding_boxes.copy()
         bounding_boxes["boxes"] = outputs
-        bounding_boxes = bounding_box.clip_to_image(
+        bounding_boxes = bounding_box_utils.clip_to_image(
             bounding_boxes,
             bounding_box_format="xyxy",
             images=images,
         )
         bounding_boxes = bounding_box_utils.sanitize_bounding_boxes(
             bounding_boxes,
             min_area_ratio=self.bounding_box_min_area_ratio,
@@ -203,65 +205,69 @@
             source="xyxy",
             target=self.bounding_box_format,
             dtype=self.compute_dtype,
             images=images,
         )
         return bounding_boxes
 
+    def compute_ragged_segmentation_mask_signature(self, segmentation_masks):
+        return tf.RaggedTensorSpec(
+            shape=(self.height, self.width, segmentation_masks.shape[-1]),
+            ragged_rank=1,
+            dtype=self.compute_dtype,
+        )
+
+    def augment_ragged_segmentation_mask(
+        self, segmentation_mask, transformation, **kwargs
+    ):
+        segmentation_mask = tf.expand_dims(segmentation_mask, axis=0)
+        transformation = augmentation_utils.expand_dict_dims(
+            transformation, axis=0
+        )
+        segmentation_mask = self.augment_segmentation_masks(
+            segmentation_masks=segmentation_mask,
+            transformations=transformation,
+            **kwargs,
+        )
+        return tf.squeeze(segmentation_mask, axis=0)
+
     def augment_segmentation_masks(
         self, segmentation_masks, transformations, **kwargs
     ):
-        if isinstance(segmentation_masks, tf.RaggedTensor):
-            inputs = {
-                augmentation_utils.SEGMENTATION_MASKS: segmentation_masks,
-                "transformation": transformations,
-            }
-            segmentation_masks = tf.map_fn(
-                self.augment_segmentation_mask_single,
-                inputs,
-                fn_output_signature=segmentation_masks.dtype,
-            )
-        else:
-            pad_top = transformations["pad_tops"][0][0]
-            pad_bottom = transformations["pad_bottoms"][0][0]
-            pad_left = transformations["pad_lefts"][0][0]
-            pad_right = transformations["pad_rights"][0][0]
-            paddings = tf.stack(
-                (
-                    tf.zeros(shape=(2,), dtype=pad_top.dtype),
-                    tf.stack((pad_top, pad_bottom)),
-                    tf.stack((pad_left, pad_right)),
-                    tf.zeros(shape=(2,), dtype=pad_top.dtype),
-                )
-            )
-            segmentation_masks = tf.pad(
-                segmentation_masks, paddings=paddings, constant_values=0
-            )
-        return segmentation_masks
-
-    def augment_segmentation_mask_single(self, inputs):
-        segmentation_mask = inputs.get(
-            augmentation_utils.SEGMENTATION_MASKS, None
-        )
-        transformation = inputs.get("transformation", None)
-        pad_top = transformation["pad_tops"][0]
-        pad_bottom = transformation["pad_bottoms"][0]
-        pad_left = transformation["pad_lefts"][0]
-        pad_right = transformation["pad_rights"][0]
+        ori_height = tf.shape(segmentation_masks)[augmentation_utils.H_AXIS]
+        ori_width = tf.shape(segmentation_masks)[augmentation_utils.W_AXIS]
+        pad_top = transformations["pad_tops"][0][0]
+        pad_bottom = transformations["pad_bottoms"][0][0]
+        pad_left = transformations["pad_lefts"][0][0]
+        pad_right = transformations["pad_rights"][0][0]
         paddings = tf.stack(
             (
+                tf.zeros(shape=(2,), dtype=pad_top.dtype),
                 tf.stack((pad_top, pad_bottom)),
                 tf.stack((pad_left, pad_right)),
                 tf.zeros(shape=(2,), dtype=pad_top.dtype),
             )
         )
-        segmentation_mask = tf.pad(
-            segmentation_mask, paddings=paddings, constant_values=0
+        segmentation_masks = tf.pad(
+            segmentation_masks, paddings=paddings, constant_values=0
         )
-        return segmentation_mask
+        # center crop
+        offset_height = (ori_height + pad_top + pad_bottom - self.height) // 2
+        offset_width = (ori_width + pad_left + pad_right - self.width) // 2
+        segmentation_masks = tf.image.crop_to_bounding_box(
+            segmentation_masks,
+            offset_height,
+            offset_width,
+            self.height,
+            self.width,
+        )
+        segmentation_masks = tf.ensure_shape(
+            segmentation_masks, shape=(None, self.height, self.width, None)
+        )
+        return segmentation_masks
 
     def get_config(self):
         config = super().get_config()
         config.update(
             {
                 "height": self.height,
                 "width": self.width,
```

## keras_aug/layers/preprocessing/geometry/center_crop_test.py

```diff
@@ -185,7 +185,50 @@
 
         self.assertAllClose(
             expected_output["boxes"], output["bounding_boxes"]["boxes"]
         )
         self.assertAllClose(
             expected_output["classes"], output["bounding_boxes"]["classes"]
         )
+
+    def test_dense_segmentation_masks(self):
+        images = tf.random.uniform((2, 10, 10, 3))
+        segmentation_masks = tf.random.uniform(
+            (2, 10, 10, 1), minval=0, maxval=10, dtype=tf.int32
+        )
+        args = self.no_aug_args.copy()
+        args.update({"height": 4, "width": 4})
+        layer = layers.CenterCrop(**args)
+
+        result = layer(
+            {"images": images, "segmentation_masks": segmentation_masks}
+        )
+
+        self.assertTrue(isinstance(result["segmentation_masks"], tf.Tensor))
+        self.assertEqual(result["segmentation_masks"].shape[1:3], (4, 4))
+        self.assertAllInSet(result["segmentation_masks"], tf.range(0, 10))
+
+    def test_ragged_segmentation_masks(self):
+        images = tf.ragged.stack(
+            [
+                tf.random.uniform((8, 8, 3), dtype=tf.float32),
+                tf.random.uniform((16, 8, 3), dtype=tf.float32),
+            ]
+        )
+        segmentation_masks = tf.ragged.stack(
+            [
+                tf.random.uniform((8, 8, 1), maxval=10, dtype=tf.int32),
+                tf.random.uniform((16, 8, 1), maxval=10, dtype=tf.int32),
+            ]
+        )
+        segmentation_masks = tf.cast(segmentation_masks, dtype=tf.float32)
+        args = self.no_aug_args.copy()
+        args.update({"height": 4, "width": 4})
+        layer = layers.CenterCrop(**args)
+
+        result = layer(
+            {"images": images, "segmentation_masks": segmentation_masks}
+        )
+
+        self.assertTrue(isinstance(result["segmentation_masks"], tf.Tensor))
+        self.assertEqual(result["segmentation_masks"].shape[1:3], (4, 4))
+        self.assertAllInSet(result["segmentation_masks"], tf.range(0, 10))
```

## keras_aug/layers/preprocessing/geometry/pad_if_needed.py

```diff
@@ -204,43 +204,46 @@
             source="xyxy",
             target=self.bounding_box_format,
             dtype=self.compute_dtype,
             images=images,
         )
         return bounding_boxes
 
+    def augment_ragged_segmentation_mask(
+        self, segmentation_mask, transformation, **kwargs
+    ):
+        segmentation_mask = tf.expand_dims(segmentation_mask, axis=0)
+        transformation = augmentation_utils.expand_dict_dims(
+            transformation, axis=0
+        )
+        segmentation_mask = self.augment_segmentation_masks(
+            segmentation_masks=segmentation_mask,
+            transformations=transformation,
+            **kwargs,
+        )
+        return tf.squeeze(segmentation_mask, axis=0)
+
     def augment_segmentation_masks(
         self, segmentation_masks, transformations, **kwargs
     ):
-        if isinstance(segmentation_masks, tf.RaggedTensor):
-            inputs_for_augment_segmentation_mask_single = {
-                augmentation_utils.SEGMENTATION_MASKS: segmentation_masks,
-                "transformation": transformations,
-            }
-            segmentation_masks = tf.map_fn(
-                self.augment_segmentation_mask_single,
-                inputs_for_augment_segmentation_mask_single,
-                fn_output_signature=segmentation_masks.dtype,
-            )
-        else:
-            pad_top = transformations["pad_tops"][0][0]
-            pad_bottom = transformations["pad_bottoms"][0][0]
-            pad_left = transformations["pad_lefts"][0][0]
-            pad_right = transformations["pad_rights"][0][0]
-            paddings = tf.stack(
-                (
-                    tf.zeros(shape=(2,), dtype=pad_top.dtype),
-                    tf.stack((pad_top, pad_bottom)),
-                    tf.stack((pad_left, pad_right)),
-                    tf.zeros(shape=(2,), dtype=pad_top.dtype),
-                )
-            )
-            segmentation_masks = tf.pad(
-                segmentation_masks, paddings=paddings, constant_values=0
+        pad_top = transformations["pad_tops"][0][0]
+        pad_bottom = transformations["pad_bottoms"][0][0]
+        pad_left = transformations["pad_lefts"][0][0]
+        pad_right = transformations["pad_rights"][0][0]
+        paddings = tf.stack(
+            (
+                tf.zeros(shape=(2,), dtype=pad_top.dtype),
+                tf.stack((pad_top, pad_bottom)),
+                tf.stack((pad_left, pad_right)),
+                tf.zeros(shape=(2,), dtype=pad_top.dtype),
             )
+        )
+        segmentation_masks = tf.pad(
+            segmentation_masks, paddings=paddings, constant_values=0
+        )
         return segmentation_masks
 
     def augment_segmentation_mask_single(self, inputs):
         segmentation_mask = inputs.get(
             augmentation_utils.SEGMENTATION_MASKS, None
         )
         transformation = inputs.get("transformation", None)
```

## keras_aug/layers/preprocessing/geometry/pad_if_needed_test.py

```diff
@@ -219,7 +219,57 @@
         layer = layers.PadIfNeeded(**args)
 
         outputs = layer(inputs)
 
         self.assertEqual(outputs.shape, (1, 8, 8, 3))
         self.assertEqual(tf.reduce_mean(outputs[:, :, 0:4, :]), 0.0)
         self.assertNotEqual(tf.reduce_mean(outputs[:, :, -2:, :]), 0.0)
+
+    def test_dense_segmentation_masks(self):
+        images = tf.random.uniform((2, 10, 10, 3))
+        segmentation_masks = tf.random.uniform(
+            (2, 10, 10, 1), minval=0, maxval=10, dtype=tf.int32
+        )
+        args = self.regular_args.copy()
+        args.update(
+            {"min_height": 16, "min_width": 16, "position": "top_right"}
+        )
+        layer = layers.PadIfNeeded(**args)
+
+        result = layer(
+            {"images": images, "segmentation_masks": segmentation_masks}
+        )
+
+        self.assertTrue(isinstance(result["segmentation_masks"], tf.Tensor))
+        self.assertEqual(result["segmentation_masks"].shape[1:3], (16, 16))
+        self.assertAllInSet(result["segmentation_masks"], tf.range(0, 10))
+
+    def test_ragged_segmentation_masks(self):
+        images = tf.ragged.stack(
+            [
+                tf.random.uniform((8, 8, 3), dtype=tf.float32),
+                tf.random.uniform((16, 8, 3), dtype=tf.float32),
+            ]
+        )
+        segmentation_masks = tf.ragged.stack(
+            [
+                tf.random.uniform((8, 8, 1), maxval=10, dtype=tf.int32),
+                tf.random.uniform((16, 8, 1), maxval=10, dtype=tf.int32),
+            ]
+        )
+        segmentation_masks = tf.cast(segmentation_masks, dtype=tf.float32)
+        args = self.regular_args.copy()
+        args.update(
+            {"min_height": 16, "min_width": 16, "position": "top_right"}
+        )
+        layer = layers.PadIfNeeded(**args)
+
+        result = layer(
+            {"images": images, "segmentation_masks": segmentation_masks}
+        )
+
+        self.assertTrue(
+            isinstance(result["segmentation_masks"], tf.RaggedTensor)
+        )
+        self.assertAllInSet(
+            result["segmentation_masks"].to_tensor(), tf.range(0, 10)
+        )
```

## keras_aug/layers/preprocessing/geometry/resize.py

```diff
@@ -3,14 +3,15 @@
 from keras_cv.utils import preprocessing as preprocessing_utils
 from tensorflow import keras
 
 from keras_aug.layers.base.vectorized_base_random_layer import (
     VectorizedBaseRandomLayer,
 )
 from keras_aug.utils import augmentation as augmentation_utils
+from keras_aug.utils import bounding_box as bounding_box_utils
 
 
 @keras.utils.register_keras_serializable(package="keras_aug")
 class Resize(VectorizedBaseRandomLayer):
     """Resizes the images.
 
     Resize will resize the images to ``(height, width)``. Set
@@ -87,30 +88,28 @@
         self.pad_to_aspect_ratio = pad_to_aspect_ratio
         self.bounding_box_format = bounding_box_format
         self.seed = seed
 
         # set force_output_dense_images=True because the output images must
         # have same shape (B, height, width, C)
         self.force_output_dense_images = True
-        self.force_output_dense_segmentation_masks = True
 
     def get_random_transformation_batch(
         self, batch_size, images=None, **kwargs
     ):
-        if not self.crop_to_aspect_ratio and not self.pad_to_aspect_ratio:
-            return {"dummy": tf.zeros((batch_size,))}
-
         heights, widths = augmentation_utils.get_images_shape(
             images, dtype=tf.float32
         )
         # get scaled_sizes
         if self.crop_to_aspect_ratio:
             scales = tf.maximum(self.height / heights, self.width / widths)
         elif self.pad_to_aspect_ratio:
             scales = tf.minimum(self.height / heights, self.width / widths)
+        else:
+            return {"dummy": tf.zeros((batch_size,))}
         new_heights = tf.cast(tf.round(heights * scales), tf.int32)
         new_widths = tf.cast(tf.round(widths * scales), tf.int32)
         scaled_sizes = tf.concat((new_heights, new_widths), axis=-1)
 
         # get padding values
         if self.crop_to_aspect_ratio:
             tops = tf.where(
@@ -125,15 +124,16 @@
                 new_widths > self.width,
                 tf.cast((new_widths - self.width) / 2, tf.int32),
                 0,
             )
             rights = tf.where(
                 new_widths > self.width, new_widths - self.width - lefts, 0
             )
-        elif self.pad_to_aspect_ratio:
+        else:
+            assert self.pad_to_aspect_ratio
             tops = tf.where(
                 new_heights < self.height,
                 tf.cast((self.height - new_heights) / 2, tf.int32),
                 0,
             )
             bottoms = tf.where(
                 new_heights < self.height, self.height - new_heights - tops, 0
@@ -164,33 +164,34 @@
         )
         image = self.augment_images(
             images=image, transformations=transformation, **kwargs
         )
         return tf.squeeze(image, axis=0)
 
     def augment_images(self, images, transformations, **kwargs):
-        # resize
-        if not self.crop_to_aspect_ratio and not self.pad_to_aspect_ratio:
-            images = tf.image.resize(
-                images,
-                size=(self.height, self.width),
-                method=self.interpolation,
-                antialias=self.antialias,
-            )
-            return tf.cast(images, dtype=self.compute_dtype)
-
         # resize keeping aspect ratio
         if self.crop_to_aspect_ratio:
             images = self.resize_with_crop_to_aspect_ratio(
                 images, transformations, self.interpolation
             )
         elif self.pad_to_aspect_ratio:
             images = self.resize_with_pad_to_aspect_ratio(
                 images, transformations, self.interpolation, self.padding_value
             )
+        else:
+            # resize
+            images = tf.image.resize(
+                images,
+                size=(self.height, self.width),
+                method=self.interpolation,
+                antialias=self.antialias,
+            )
+        images = tf.ensure_shape(
+            images, shape=(None, self.height, self.width, None)
+        )
         return tf.cast(images, dtype=self.compute_dtype)
 
     def augment_labels(self, labels, transformations, **kwargs):
         return labels
 
     def augment_bounding_boxes(
         self,
@@ -252,117 +253,80 @@
 
         x1s, y1s, x2s, y2s = tf.split(bounding_boxes["boxes"], 4, axis=-1)
         if self.crop_to_aspect_ratio:
             x1s = x1s * widths_ratios - lefts
             x2s = x2s * widths_ratios - lefts
             y1s = y1s * height_ratios - tops
             y2s = y2s * height_ratios - tops
-        elif self.pad_to_aspect_ratio:
+        else:
+            assert self.pad_to_aspect_ratio
             x1s = x1s * widths_ratios + lefts
             x2s = x2s * widths_ratios + lefts
             y1s = y1s * height_ratios + tops
             y2s = y2s * height_ratios + tops
         boxes = tf.concat([x1s, y1s, x2s, y2s], axis=-1)
         bounding_boxes = bounding_boxes.copy()
         bounding_boxes["boxes"] = boxes
-        bounding_boxes = bounding_box.clip_to_image(
+        bounding_boxes = bounding_box_utils.clip_to_image(
             bounding_boxes,
             bounding_box_format="xyxy",
             images=images,
         )
         bounding_boxes = bounding_box.convert_format(
             bounding_boxes,
             source="xyxy",
             target=self.bounding_box_format,
             dtype=self.compute_dtype,
             images=images,
         )
         return bounding_boxes
 
+    def compute_ragged_segmentation_mask_signature(self, segmentation_masks):
+        return tf.RaggedTensorSpec(
+            shape=(self.height, self.width, segmentation_masks.shape[-1]),
+            ragged_rank=1,
+            dtype=self.compute_dtype,
+        )
+
+    def augment_ragged_segmentation_mask(
+        self, segmentation_mask, transformation, **kwargs
+    ):
+        segmentation_mask = tf.expand_dims(segmentation_mask, axis=0)
+        transformation = augmentation_utils.expand_dict_dims(
+            transformation, axis=0
+        )
+        segmentation_mask = self.augment_segmentation_masks(
+            segmentation_masks=segmentation_mask,
+            transformations=transformation,
+            **kwargs,
+        )
+        return tf.squeeze(segmentation_mask, axis=0)
+
     def augment_segmentation_masks(
         self, segmentation_masks, transformations, **kwargs
     ):
-        if isinstance(segmentation_masks, tf.RaggedTensor):
-            inputs = {
-                augmentation_utils.SEGMENTATION_MASKS: segmentation_masks,
-                "transformations": transformations,
-            }
-            segmentation_masks = tf.vectorized_map(
-                self.augment_segmentation_mask_single,
-                inputs,
-            )
-            return tf.cast(segmentation_masks, dtype=self.compute_dtype)
-        # resize
-        if not self.crop_to_aspect_ratio and not self.pad_to_aspect_ratio:
-            segmentation_masks = tf.image.resize(
-                segmentation_masks,
-                size=(self.height, self.width),
-                method="nearest",
-            )
-
         # resize keeping aspect ratio
         if self.crop_to_aspect_ratio:
             segmentation_masks = self.resize_with_crop_to_aspect_ratio(
                 segmentation_masks, transformations, "nearest"
             )
         elif self.pad_to_aspect_ratio:
             segmentation_masks = self.resize_with_pad_to_aspect_ratio(
                 segmentation_masks, transformations, "nearest", 0
             )
-        return tf.cast(segmentation_masks, dtype=self.compute_dtype)
-
-    def augment_segmentation_mask_single(self, inputs):
-        segmentation_mask = inputs.get(
-            augmentation_utils.SEGMENTATION_MASKS, None
-        )
-        transformation = inputs.get("transformations", None)
-        # resize
-        if not self.crop_to_aspect_ratio and not self.pad_to_aspect_ratio:
-            return tf.image.resize(
-                segmentation_mask,
+        else:
+            segmentation_masks = tf.image.resize(
+                segmentation_masks,
                 size=(self.height, self.width),
                 method="nearest",
             )
-
-        # resize keeping aspect ratio
-        scaled_size = transformation["scaled_sizes"]
-        new_height = scaled_size[0]
-        new_width = scaled_size[1]
-        segmentation_mask = tf.image.resize(
-            segmentation_mask,
-            size=(new_height, new_width),
-            method="nearest",
+        segmentation_masks = tf.ensure_shape(
+            segmentation_masks, shape=(None, self.height, self.width, None)
         )
-        if self.crop_to_aspect_ratio:
-            # crop
-            top = tf.cast(transformation["tops"][0], dtype=tf.float32)
-            left = tf.cast(transformation["lefts"][0], dtype=tf.float32)
-            segmentation_mask = tf.image.crop_to_bounding_box(
-                segmentation_mask, top, left, self.height, self.width
-            )
-        elif self.pad_to_aspect_ratio:
-            # pad
-            pad_top = transformation["tops"][0]
-            pad_bottom = transformation["bottoms"][0]
-            pad_left = transformation["lefts"][0]
-            pad_right = transformation["rights"][0]
-            paddings = tf.stack(
-                (
-                    tf.stack((pad_top, pad_bottom)),
-                    tf.stack((pad_left, pad_right)),
-                    tf.zeros(shape=(2,), dtype=pad_top.dtype),
-                )
-            )
-            segmentation_mask = tf.pad(
-                segmentation_mask,
-                paddings=paddings,
-                constant_values=0,
-            )
-
-        return segmentation_mask
+        return tf.cast(segmentation_masks, dtype=self.compute_dtype)
 
     def resize_with_crop_to_aspect_ratio(self, images, transformations, method):
         batch_size = tf.shape(images)[0]
         scaled_sizes = transformations["scaled_sizes"]
         new_height = scaled_sizes[0][0]
         new_width = scaled_sizes[0][1]
         # resize
```

## keras_aug/layers/preprocessing/geometry/resize_test.py

```diff
@@ -550,7 +550,50 @@
         layer = layers.Resize(**args)
 
         outputs = layer(inputs)
 
         self.assertEqual(outputs.shape, (1, 8, 8, 3))
         self.assertEqual(tf.reduce_mean(outputs[:, :, 0:4, :]), 0.0)
         self.assertNotEqual(tf.reduce_mean(outputs[:, :, -2:, :]), 0.0)
+
+    def test_dense_segmentation_masks(self):
+        images = tf.random.uniform((2, 10, 10, 3))
+        segmentation_masks = tf.random.uniform(
+            (2, 10, 10, 1), minval=0, maxval=10, dtype=tf.int32
+        )
+        args = self.resize_with_pad_args.copy()
+        args.update({"height": 8, "width": 8, "position": "top_right"})
+        layer = layers.Resize(**args)
+
+        result = layer(
+            {"images": images, "segmentation_masks": segmentation_masks}
+        )
+
+        self.assertTrue(isinstance(result["segmentation_masks"], tf.Tensor))
+        self.assertEqual(result["segmentation_masks"].shape[1:3], (8, 8))
+        self.assertAllInSet(result["segmentation_masks"], tf.range(0, 10))
+
+    def test_ragged_segmentation_masks(self):
+        images = tf.ragged.stack(
+            [
+                tf.random.uniform((8, 8, 3), dtype=tf.float32),
+                tf.random.uniform((16, 8, 3), dtype=tf.float32),
+            ]
+        )
+        segmentation_masks = tf.ragged.stack(
+            [
+                tf.random.uniform((8, 8, 1), maxval=10, dtype=tf.int32),
+                tf.random.uniform((16, 8, 1), maxval=10, dtype=tf.int32),
+            ]
+        )
+        segmentation_masks = tf.cast(segmentation_masks, dtype=tf.float32)
+        args = self.resize_with_pad_args.copy()
+        args.update({"height": 8, "width": 8, "position": "top_right"})
+        layer = layers.Resize(**args)
+
+        result = layer(
+            {"images": images, "segmentation_masks": segmentation_masks}
+        )
+
+        self.assertTrue(isinstance(result["segmentation_masks"], tf.Tensor))
+        self.assertEqual(result["segmentation_masks"].shape[1:3], (8, 8))
+        self.assertAllInSet(result["segmentation_masks"], tf.range(0, 10))
```

## keras_aug/utils/augmentation.py

```diff
@@ -100,14 +100,47 @@
             f"Value not recognized for `position`: {position}. Supported "
             f"values are: {PaddingPosition._value2member_map_.keys()}"
         )
 
     return tops, bottoms, lefts, rights
 
 
+def parse_factor(
+    param,
+    min_value=0.0,
+    max_value=1.0,
+    center_value=0.5,
+    param_name="factor",
+    seed=None,
+):
+    if isinstance(param, FactorSampler):
+        return param
+
+    if isinstance(param, float) or isinstance(param, int):
+        param = (center_value - param, center_value + param)
+
+    if param[0] > param[1]:
+        raise ValueError(
+            f"`{param_name}[0] > {param_name}[1]`, `{param_name}[0]` must be "
+            f"<= `{param_name}[1]`. Got `{param_name}={param}`"
+        )
+    if (min_value is not None and param[0] < min_value) or (
+        max_value is not None and param[1] > max_value
+    ):
+        raise ValueError(
+            f"`{param_name}` should be inside of range "
+            f"[{min_value}, {max_value}]. Got {param_name}={param}"
+        )
+
+    if param[0] == param[1]:
+        return ConstantFactorSampler(param[0])
+
+    return UniformFactorSampler(param[0], param[1], seed=seed)
+
+
 def is_factor_working(factor, not_working_value=0.0):
     """Check whether ``factor`` is working or not.
 
     Args:
         factor (int|float|Sequence[int|float]|keras_aug.FactorSampler): The
             factor to check whether it is working or not.
         not_working_value (float, optional): The value indicating not working
@@ -136,14 +169,22 @@
     else:
         raise ValueError(
             f"Cannot recognize factor type: {factor} with type {type(factor)}"
         )
     return True
 
 
+def expand_dict_dims(dicts, axis):
+    new_dicts = {}
+    for key in dicts.keys():
+        tensor = dicts[key]
+        new_dicts[key] = tf.expand_dims(tensor, axis=axis)
+    return new_dicts
+
+
 def get_images_shape(images, dtype=tf.int32):
     """Get ``heights`` and ``widths`` of the input images.
 
     Input images can be ``tf.Tensor`` or ``tf.RaggedTensor`` with the shape of
     [B, H|None, W|None, C].
 
     Args:
@@ -161,53 +202,88 @@
         heights = tf.repeat(tf.shape(images)[H_AXIS], repeats=[batch_size])
         heights = tf.reshape(heights, shape=(-1, 1))
         widths = tf.repeat(tf.shape(images)[W_AXIS], repeats=[batch_size])
         widths = tf.reshape(widths, shape=(-1, 1))
     return tf.cast(heights, dtype=dtype), tf.cast(widths, dtype=dtype)
 
 
-def expand_dict_dims(dicts, axis):
-    new_dicts = {}
-    for key in dicts.keys():
-        tensor = dicts[key]
-        new_dicts[key] = tf.expand_dims(tensor, axis=axis)
-    return new_dicts
-
-
-def parse_factor(
-    param,
-    min_value=0.0,
-    max_value=1.0,
-    center_value=0.5,
-    param_name="factor",
-    seed=None,
-):
-    if isinstance(param, FactorSampler):
-        return param
-
-    if isinstance(param, float) or isinstance(param, int):
-        param = (center_value - param, center_value + param)
-
-    if param[0] > param[1]:
-        raise ValueError(
-            f"`{param_name}[0] > {param_name}[1]`, `{param_name}[0]` must be "
-            f"<= `{param_name}[1]`. Got `{param_name}={param}`"
-        )
-    if (min_value is not None and param[0] < min_value) or (
-        max_value is not None and param[1] > max_value
-    ):
-        raise ValueError(
-            f"`{param_name}` should be inside of range "
-            f"[{min_value}, {max_value}]. Got {param_name}={param}"
-        )
-
-    if param[0] == param[1]:
-        return ConstantFactorSampler(param[0])
-
-    return UniformFactorSampler(param[0], param[1], seed=seed)
+def cast_to(inputs, dtype):
+    if IMAGES in inputs:
+        inputs[IMAGES] = tf.cast(inputs[IMAGES], dtype)
+    if LABELS in inputs:
+        inputs[LABELS] = tf.cast(inputs[LABELS], dtype)
+    if BOUNDING_BOXES in inputs:
+        inputs[BOUNDING_BOXES]["boxes"] = tf.cast(
+            inputs[BOUNDING_BOXES]["boxes"], dtype
+        )
+        inputs[BOUNDING_BOXES]["classes"] = tf.cast(
+            inputs[BOUNDING_BOXES]["classes"], dtype
+        )
+    if SEGMENTATION_MASKS in inputs:
+        inputs[SEGMENTATION_MASKS] = tf.cast(inputs[SEGMENTATION_MASKS], dtype)
+    if KEYPOINTS in inputs:
+        inputs[KEYPOINTS] = tf.cast(inputs[KEYPOINTS], dtype)
+    if CUSTOM_ANNOTATIONS in inputs:
+        raise NotImplementedError()
+    return inputs
+
+
+def compute_signature(inputs, dtype):
+    fn_output_signature = {}
+    if IMAGES in inputs:
+        if isinstance(inputs[IMAGES], tf.Tensor):
+            fn_output_signature[IMAGES] = tf.TensorSpec(
+                inputs[IMAGES].shape[1:], dtype
+            )
+        else:
+            fn_output_signature[IMAGES] = tf.RaggedTensorSpec(
+                shape=inputs[IMAGES].shape[1:],
+                ragged_rank=1,
+                dtype=dtype,
+            )
+    if LABELS in inputs:
+        fn_output_signature[LABELS] = tf.TensorSpec(
+            inputs[LABELS].shape[1:], dtype
+        )
+    if BOUNDING_BOXES in inputs:
+        fn_output_signature[BOUNDING_BOXES] = {
+            "boxes": tf.RaggedTensorSpec(
+                shape=[None, 4],
+                ragged_rank=1,
+                dtype=dtype,
+            ),
+            "classes": tf.RaggedTensorSpec(
+                shape=[None], ragged_rank=0, dtype=dtype
+            ),
+        }
+    if SEGMENTATION_MASKS in inputs:
+        if isinstance(inputs[SEGMENTATION_MASKS], tf.Tensor):
+            fn_output_signature[SEGMENTATION_MASKS] = tf.TensorSpec(
+                inputs[SEGMENTATION_MASKS].shape[1:], dtype
+            )
+        else:
+            fn_output_signature[SEGMENTATION_MASKS] = tf.RaggedTensorSpec(
+                shape=inputs[SEGMENTATION_MASKS].shape[1:],
+                ragged_rank=1,
+                dtype=dtype,
+            )
+    if KEYPOINTS in inputs:
+        if isinstance(inputs[KEYPOINTS], tf.Tensor):
+            fn_output_signature[KEYPOINTS] = tf.TensorSpec(
+                inputs[KEYPOINTS].shape[1:], dtype
+            )
+        else:
+            fn_output_signature[KEYPOINTS] = tf.RaggedTensorSpec(
+                shape=inputs[KEYPOINTS].shape[1:],
+                ragged_rank=1,
+                dtype=dtype,
+            )
+    if CUSTOM_ANNOTATIONS in inputs:
+        raise NotImplementedError()
+    return fn_output_signature
 
 
 def blend(images_1, images_2, factors, value_range=None):
     """Blend image1 and image2 using 'factors'. Can be batched inputs.
 
     Factor can be above ``0.0``.  A value of ``0.0`` means only image1 is used.
     A value of ``1.0`` means only image2 is used.  A value between ``0.0`` and
@@ -286,21 +362,21 @@
             [
                 tf.cos(angles),
                 -tf.sin(angles),
                 x_offset,
                 tf.sin(angles),
                 tf.cos(angles),
                 y_offset,
-                tf.zeros((num_angles, 2), tf.float32),
+                tf.zeros((num_angles, 2), angles.dtype),
             ],
             axis=1,
         )
         if to_square:
             matrix = tf.concat(
-                [matrix, tf.ones((num_angles, 1), tf.float32)], axis=1
+                [matrix, tf.ones((num_angles, 1), angles.dtype)], axis=1
             )
             matrix = tf.reshape(matrix, (num_angles, 3, 3))
         return matrix
 
 
 def get_translation_matrix(
     translations, image_height, image_width, to_square=False, name=None
@@ -325,27 +401,28 @@
         #     [[1 0 -dx]
         #      [0 1 -dy]
         #      [0 0 1]]
         # where the last entry is implicit.
         # Translation matrices are always float32.
         matrix = tf.concat(
             values=[
-                tf.ones((num_translations, 1), tf.float32),
-                tf.zeros((num_translations, 1), tf.float32),
+                tf.ones((num_translations, 1), translations.dtype),
+                tf.zeros((num_translations, 1), translations.dtype),
                 -translations[:, 0, tf.newaxis] * image_width,
-                tf.zeros((num_translations, 1), tf.float32),
-                tf.ones((num_translations, 1), tf.float32),
+                tf.zeros((num_translations, 1), translations.dtype),
+                tf.ones((num_translations, 1), translations.dtype),
                 -translations[:, 1, tf.newaxis] * image_height,
-                tf.zeros((num_translations, 2), tf.float32),
+                tf.zeros((num_translations, 2), translations.dtype),
             ],
             axis=1,
         )
         if to_square:
             matrix = tf.concat(
-                [matrix, tf.ones((num_translations, 1), tf.float32)], axis=1
+                [matrix, tf.ones((num_translations, 1), translations.dtype)],
+                axis=1,
             )
             matrix = tf.reshape(matrix, (num_translations, 3, 3))
         return matrix
 
 
 def get_zoom_matrix(
     zooms, image_height, image_width, to_square=False, name=None
@@ -375,26 +452,26 @@
         x_offset = ((image_width - 1.0) / 2.0) * (1.0 - zooms[:, 0, tf.newaxis])
         y_offset = ((image_height - 1.0) / 2.0) * (
             1.0 - zooms[:, 1, tf.newaxis]
         )
         matrix = tf.concat(
             values=[
                 zooms[:, 0, tf.newaxis],
-                tf.zeros((num_zooms, 1), tf.float32),
+                tf.zeros((num_zooms, 1), zooms.dtype),
                 x_offset,
-                tf.zeros((num_zooms, 1), tf.float32),
+                tf.zeros((num_zooms, 1), zooms.dtype),
                 zooms[:, 1, tf.newaxis],
                 y_offset,
-                tf.zeros((num_zooms, 2), tf.float32),
+                tf.zeros((num_zooms, 2), zooms.dtype),
             ],
             axis=1,
         )
         if to_square:
             matrix = tf.concat(
-                [matrix, tf.ones((num_zooms, 1), tf.float32)], axis=1
+                [matrix, tf.ones((num_zooms, 1), zooms.dtype)], axis=1
             )
             matrix = tf.reshape(matrix, (num_zooms, 3, 3))
         return matrix
 
 
 def get_shear_matrix(shears, to_square=False, name=None):
     """Returns projective transforms for the given shears.
@@ -414,22 +491,22 @@
         # The transform matrix looks like:
         # (1, x, 0)
         # (y, 1, 0)
         # (0, 0, 1)
         # where the last entry is implicit.
         matrix = tf.concat(
             values=[
-                tf.ones((num_shears, 1), tf.float32),
+                tf.ones((num_shears, 1), shears.dtype),
                 shears[:, 0, tf.newaxis],
-                tf.zeros((num_shears, 1), tf.float32),
+                tf.zeros((num_shears, 1), shears.dtype),
                 shears[:, 1, tf.newaxis],
-                tf.ones((num_shears, 1), tf.float32),
-                tf.zeros((num_shears, 3), tf.float32),
+                tf.ones((num_shears, 1), shears.dtype),
+                tf.zeros((num_shears, 3), shears.dtype),
             ],
             axis=1,
         )
         if to_square:
             matrix = tf.concat(
-                [matrix, tf.ones((num_shears, 1), tf.float32)], axis=1
+                [matrix, tf.ones((num_shears, 1), shears.dtype)], axis=1
             )
             matrix = tf.reshape(matrix, (num_shears, 3, 3))
         return matrix
```

## keras_aug/utils/augmentation_test.py

```diff
@@ -113,14 +113,23 @@
         self.assertEqual(
             augmentation_utils.is_factor_working(
                 core.UniformFactorSampler(0, 1), not_working_value=0
             ),
             True,
         )
 
+    def test_expand_dict_dims(self):
+        key = "factor"
+        shape = [3, 3]
+        transformation = {key: tf.random.uniform(shape=shape)}
+
+        result = augmentation_utils.expand_dict_dims(transformation, axis=0)
+
+        self.assertEqual(result[key].shape, [1] + [3, 3])
+
     def test_get_images_shape_dense(self):
         height = 5
         width = 6
         images = tf.random.uniform(shape=(2, 5, 6, 3))
 
         heights, widths = augmentation_utils.get_images_shape(images)
 
@@ -136,22 +145,83 @@
         )
 
         heights, widths = augmentation_utils.get_images_shape(images)
 
         self.assertAllEqual(heights, [[5], [8]])
         self.assertAllEqual(widths, [[5], [8]])
 
-    def test_expand_dict_dims(self):
-        key = "factor"
-        shape = [3, 3]
-        transformation = {key: tf.random.uniform(shape=shape)}
+    def test_cast_to_float16(self):
+        inputs = {
+            augmentation_utils.IMAGES: tf.random.uniform((2, 4, 4, 3)),
+            augmentation_utils.LABELS: tf.random.uniform((2, 1)),
+            augmentation_utils.BOUNDING_BOXES: {
+                "boxes": tf.zeros((2, 2, 4)),
+                "classes": tf.zeros((2, 2)),
+            },
+            augmentation_utils.SEGMENTATION_MASKS: tf.random.uniform(
+                (2, 4, 4, 10)
+            ),
+            augmentation_utils.KEYPOINTS: tf.random.uniform((2, 4, 17)),
+        }
 
-        result = augmentation_utils.expand_dict_dims(transformation, axis=0)
+        result = augmentation_utils.cast_to(inputs, dtype=tf.float16)
 
-        self.assertEqual(result[key].shape, [1] + [3, 3])
+        self.assertDTypeEqual(result[augmentation_utils.IMAGES], tf.float16)
+        self.assertDTypeEqual(result[augmentation_utils.LABELS], tf.float16)
+        self.assertDTypeEqual(
+            result[augmentation_utils.BOUNDING_BOXES]["boxes"], tf.float16
+        )
+        self.assertDTypeEqual(
+            result[augmentation_utils.BOUNDING_BOXES]["classes"], tf.float16
+        )
+        self.assertDTypeEqual(result[augmentation_utils.KEYPOINTS], tf.float16)
+
+    def test_cast_to_int8(self):
+        inputs = {
+            augmentation_utils.IMAGES: tf.random.uniform((2, 4, 4, 3)),
+            augmentation_utils.LABELS: tf.random.uniform((2, 1)),
+            augmentation_utils.BOUNDING_BOXES: {
+                "boxes": tf.zeros((2, 2, 4)),
+                "classes": tf.zeros((2, 2)),
+            },
+            augmentation_utils.SEGMENTATION_MASKS: tf.random.uniform(
+                (2, 4, 4, 10)
+            ),
+            augmentation_utils.KEYPOINTS: tf.random.uniform((2, 4, 17)),
+        }
+
+        result = augmentation_utils.cast_to(inputs, dtype=tf.int8)
+
+        self.assertDTypeEqual(result[augmentation_utils.IMAGES], tf.int8)
+        self.assertDTypeEqual(result[augmentation_utils.LABELS], tf.int8)
+        self.assertDTypeEqual(
+            result[augmentation_utils.BOUNDING_BOXES]["boxes"], tf.int8
+        )
+        self.assertDTypeEqual(
+            result[augmentation_utils.BOUNDING_BOXES]["classes"], tf.int8
+        )
+        self.assertDTypeEqual(result[augmentation_utils.KEYPOINTS], tf.int8)
+
+    def test_compute_signature(self):
+        inputs = {
+            augmentation_utils.IMAGES: tf.random.uniform((2, 4, 4, 3)),
+            augmentation_utils.LABELS: tf.random.uniform((2, 1)),
+            augmentation_utils.BOUNDING_BOXES: {
+                "boxes": tf.zeros((2, 2, 4)),
+                "classes": tf.zeros((2, 2)),
+            },
+            augmentation_utils.SEGMENTATION_MASKS: tf.random.uniform(
+                (2, 4, 4, 10)
+            ),
+            augmentation_utils.KEYPOINTS: tf.random.uniform((2, 4, 17)),
+        }
+
+        signatures = augmentation_utils.compute_signature(inputs, tf.float16)
+
+        self.assertTrue(inputs.keys() == signatures.keys())
 
     def test_blend(self):
         ones = tf.ones(shape=(2, 4, 4, 3))
         twos = tf.ones(shape=(2, 4, 4, 3)) * 2
         ratios = tf.ones(shape=(2, 1, 1, 1)) * 0.3
         expected_result = ratios * ones + (1.0 - ratios) * twos
```

## keras_aug/utils/bounding_box.py

```diff
@@ -1,10 +1,103 @@
 import tensorflow as tf
 from keras_cv import bounding_box
+from keras_cv.bounding_box.formats import XYWH
 from keras_cv.bounding_box.iou import _compute_area
+from keras_cv.bounding_box.utils import _format_inputs
+from keras_cv.bounding_box.utils import _format_outputs
+
+
+def _relative_area(boxes, bounding_box_format):
+    boxes = bounding_box.convert_format(
+        boxes,
+        source=bounding_box_format,
+        target="rel_xywh",
+        dtype=boxes.dtype,
+    )
+    widths = boxes[..., XYWH.WIDTH]
+    heights = boxes[..., XYWH.HEIGHT]
+    # handle corner case where shear performs a full inversion.
+    return tf.where(
+        tf.math.logical_and(widths > 0, heights > 0), widths * heights, 0.0
+    )
+
+
+def clip_to_image(
+    bounding_boxes,
+    bounding_box_format,
+    images=None,
+    image_shape=None,
+):
+    """clips bounding boxes to image boundaries.
+
+    `clip_to_image()` clips bounding boxes that have coordinates out of bounds
+    of an image down to the boundaries of the image. This is done by converting
+    the bounding box to relative formats, then clipping them to the `[0, 1]`
+    range. Additionally, bounding boxes that end up with a zero area have their
+    class ID set to -1, indicating that there is no object present in them.
+
+    Args:
+        bounding_boxes: bounding box tensor to clip.
+        bounding_box_format: the KerasCV bounding box format the bounding boxes
+            are in.
+        images: list of images to clip the bounding boxes to.
+        image_shape: the shape of the images to clip the bounding boxes to.
+    """
+    boxes, classes = bounding_boxes["boxes"], bounding_boxes["classes"]
+
+    boxes = bounding_box.convert_format(
+        boxes,
+        source=bounding_box_format,
+        target="rel_xyxy",
+        images=images,
+        image_shape=image_shape,
+        dtype=boxes.dtype,
+    )
+    boxes, classes, images, squeeze = _format_inputs(boxes, classes, images)
+    x1, y1, x2, y2 = tf.split(boxes, [1, 1, 1, 1], axis=-1)
+    clipped_bounding_boxes = tf.concat(
+        [
+            tf.clip_by_value(x1, clip_value_min=0, clip_value_max=1),
+            tf.clip_by_value(y1, clip_value_min=0, clip_value_max=1),
+            tf.clip_by_value(x2, clip_value_min=0, clip_value_max=1),
+            tf.clip_by_value(y2, clip_value_min=0, clip_value_max=1),
+        ],
+        axis=-1,
+    )
+    areas = _relative_area(
+        clipped_bounding_boxes, bounding_box_format="rel_xyxy"
+    )
+    clipped_bounding_boxes = bounding_box.convert_format(
+        clipped_bounding_boxes,
+        source="rel_xyxy",
+        target=bounding_box_format,
+        images=images,
+        image_shape=image_shape,
+        dtype=clipped_bounding_boxes.dtype,
+    )
+    clipped_bounding_boxes = tf.where(
+        tf.expand_dims(areas > 0.0, axis=-1),
+        clipped_bounding_boxes,
+        tf.constant(-1, dtype=clipped_bounding_boxes.dtype),
+    )
+    classes = tf.where(areas > 0.0, classes, tf.constant(-1, classes.dtype))
+    nan_indices = tf.math.reduce_any(
+        tf.math.is_nan(clipped_bounding_boxes), axis=-1
+    )
+    classes = tf.where(nan_indices, tf.constant(-1, classes.dtype), classes)
+
+    # TODO update dict and return
+    clipped_bounding_boxes, classes = _format_outputs(
+        clipped_bounding_boxes, classes, squeeze
+    )
+
+    result = bounding_boxes.copy()
+    result["boxes"] = clipped_bounding_boxes
+    result["classes"] = classes
+    return result
 
 
 def sanitize_bounding_boxes(
     bounding_boxes,
     min_size=None,
     min_area_ratio=None,
     max_aspect_ratio=None,
@@ -59,14 +152,15 @@
             )
         boxes = bounding_boxes["boxes"]
         boxes = bounding_box.convert_format(
             boxes,
             source=bounding_box_format,
             target="xywh",
             images=images,
+            dtype=boxes.dtype,
         )
         _, _, widths, heights = tf.split(boxes, 4, axis=-1)
         min_sides = tf.minimum(widths, heights)
         min_sides = tf.squeeze(min_sides, axis=-1)
         sanitize_mask = tf.math.logical_or(sanitize_mask, min_sides < min_size)
 
     if min_area_ratio is not None:
@@ -84,21 +178,23 @@
             )
         ref_boxes = reference_bounding_boxes["boxes"]
         ref_boxes = bounding_box.convert_format(
             ref_boxes,
             source=bounding_box_format,
             target="xyxy",
             images=reference_images,
+            dtype=ref_boxes.dtype,
         )
         boxes = bounding_boxes["boxes"]
         boxes = bounding_box.convert_format(
             boxes,
             source=bounding_box_format,
             target="xyxy",
             images=images,
+            dtype=boxes.dtype,
         )
         ref_areas = _compute_area(ref_boxes)
         areas = _compute_area(boxes)
         area_ratios = tf.math.divide_no_nan(areas, ref_areas)
         sanitize_mask = tf.math.logical_or(
             sanitize_mask, area_ratios < min_area_ratio
         )
@@ -112,14 +208,15 @@
             )
         boxes = bounding_boxes["boxes"]
         boxes = bounding_box.convert_format(
             boxes,
             source=bounding_box_format,
             target="xywh",
             images=images,
+            dtype=boxes.dtype,
         )
         _, _, widths, heights = tf.split(boxes, 4, axis=-1)
         max_aspect_ratios = tf.squeeze(
             tf.maximum(
                 tf.math.divide_no_nan(widths, heights),
                 tf.math.divide_no_nan(heights, widths),
             ),
@@ -129,11 +226,11 @@
             sanitize_mask, max_aspect_ratios > max_aspect_ratio
         )
 
     # set classes == -1
     bounding_boxes = bounding_boxes.copy()
     bounding_boxes["classes"] = tf.where(
         sanitize_mask,
-        -1.0,
+        tf.constant(-1, bounding_boxes["classes"].dtype),
         bounding_boxes["classes"],
     )
     return bounding_boxes
```

## keras_aug/utils/demo.py

```diff
@@ -51,15 +51,15 @@
 
 def load_oxford_dataset(
     name="oxford_flowers102",
     batch_size=9,
     img_size=(224, 224),
     as_supervised=True,
 ):
-    assert_tfds_installed("load_voc_dataset")
+    assert_tfds_installed("oxford_dataset")
 
     def preprocess_oxford(image, label, img_size=(224, 224), num_classes=10):
         image = tf.image.resize(image, img_size)
         label = tf.one_hot(label, num_classes)
         return {"images": image, "labels": label}
 
     data, ds_info = tfds.load(
@@ -73,14 +73,45 @@
         ),
         num_parallel_calls=tf.data.AUTOTUNE,
     )
     dataset = dataset.batch(batch_size)
     return dataset
 
 
+def load_oxford_iiit_pet_dataset(
+    name="oxford_iiit_pet:3.*.*",
+    batch_size=9,
+    img_size=(224, 224),
+):
+    assert_tfds_installed("oxford_iiit_pet_dataset")
+
+    def preprocess_oxford_iiit_pet(data):
+        img_size = (224, 224)
+
+        input_image = tf.image.resize(data["image"], img_size)
+        input_mask = tf.image.resize(
+            data["segmentation_mask"],
+            img_size,
+            method="nearest",
+        )
+        input_image = tf.image.convert_image_dtype(input_image, tf.float32)
+        input_mask -= 1
+        input_mask = tf.cast(input_mask, tf.float32)
+        return {"images": input_image, "segmentation_masks": input_mask}
+
+    data = tfds.load(name)
+    dataset = data["train"]
+    dataset = dataset.map(
+        preprocess_oxford_iiit_pet,
+        num_parallel_calls=tf.data.AUTOTUNE,
+    )
+    dataset = dataset.batch(batch_size)
+    return dataset
+
+
 def visualize_data(
     data, value_range=(0, 255), bounding_box_format=None, output_path=None
 ):
     data = next(iter(data))
     images = data["images"]
     if isinstance(images, tf.RaggedTensor):
         images = images.to_tensor(0)
@@ -141,7 +172,30 @@
             images,
             value_range=value_range,
             path=output_path,
             rows=1,
             cols=1,
             dpi=300,
         )
+
+
+def visualize_segmentation_masks(
+    data,
+    image_value_range=(0, 255),
+    mask_value_range=None,
+    output_path=None,
+):
+    data = next(iter(data))
+    images = data["images"]
+    masks = data["segmentation_masks"]
+    masks = keras_cv.utils.transform_value_range(
+        masks, mask_value_range, (0, 255)
+    )
+    masks = tf.concat([masks, masks, masks], axis=-1)
+    display_images = tf.concat([images, masks], axis=2)  # B, H, W, C
+
+    keras_cv.visualization.plot_image_gallery(
+        display_images,
+        value_range=image_value_range,
+        path=output_path,
+        dpi=100,
+    )
```

## Comparing `keras_aug-0.5.1.dist-info/LICENSE` & `keras_aug-0.5.2.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `keras_aug-0.5.1.dist-info/RECORD` & `keras_aug-0.5.2.dist-info/RECORD`

 * *Files 4% similar despite different names*

```diff
@@ -1,54 +1,54 @@
-keras_aug/__init__.py,sha256=ERSVsrb9vrHlXL_UNqSBZzN945PPibjb9eQB3h_iccE,373
+keras_aug/__init__.py,sha256=RpPSacsBATm4W-gxUwwZdNQHPhxMvCdYyxCGwV2Fxvo,373
 keras_aug/conftest.py,sha256=avtORNn5lKJpdUDRtv2TEpRSRzK5AqxgD4Jkp8tNTfs,174
 keras_aug/core/__init__.py,sha256=su93JAWbd6gzGUCUk_JOrMvEj-wfMjeH6cz_Mv9co0I,572
 keras_aug/core/factor_sampler/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 keras_aug/core/factor_sampler/constant_factor_sampler.py,sha256=VV9uG0s3hnOl6SttPouC-gHn9xw5V7ImG6_I9_hRJYY,727
 keras_aug/core/factor_sampler/constant_factor_sampler_test.py,sha256=-DVb7zOpqCC9A686eWf67-QR1ZDsextVSwr16z8e7Vs,666
 keras_aug/core/factor_sampler/factor_sampler.py,sha256=125dXun9jKo1BnWYBQ9YU6mYcreEv2SBIeGoqxYbEwU,944
 keras_aug/core/factor_sampler/normal_factor_sampler.py,sha256=XKQpXmFzTxHxKa7ihy0PD3eyB8tMEQgxxkGvlo6P-tQ,1585
 keras_aug/core/factor_sampler/normal_factor_sampler_test.py,sha256=5rl5WwP_Jr9Edq833h7h-UB3vcRymNd1qqLQdXUE1eI,949
 keras_aug/core/factor_sampler/signed_constant_factor_sampler.py,sha256=1A4S9Zl-s65k3utT5vOBjk4i_qwzvwWXFf-9HL2IyLk,1666
 keras_aug/core/factor_sampler/signed_constant_factor_sampler_test.py,sha256=Kw4ORN8dZOTA5emIuvRhaTILZKxniHLglaX9ISinON8,739
 keras_aug/core/factor_sampler/signed_normal_factor_sampler.py,sha256=b8MGpNXfUjwdXUu_y1BTESBL1Lp3RumnLZOQK4UrSs8,2556
 keras_aug/core/factor_sampler/signed_normal_factor_sampler_test.py,sha256=KQSyZYvKNOpHltE0Ml4AmYVZ6JTEmqsZniM6fZBJ8L8,1284
 keras_aug/core/factor_sampler/uniform_factor_sampler.py,sha256=-84aO6gJyWlIPcF6UmiVtkvaR-oFZupywH8HLwzbmM4,1204
 keras_aug/core/factor_sampler/uniform_factor_sampler_test.py,sha256=uvgBbbBN366kt8k56dppdSS3Vy09BORUYpX9n_9TJ90,778
-keras_aug/layers/__init__.py,sha256=wmuKqbjCPJAkF5Uu_1AaanUZTqRct2YLFrIU_IMATf0,3539
+keras_aug/layers/__init__.py,sha256=SMUjTK4pYg7gKX7L56Nvcj8sEmMoK3zNk1RWjFFfHk8,3641
 keras_aug/layers/__internal__/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 keras_aug/layers/__internal__/base_layer.py,sha256=hxTmf_U5jaXDoM1Af15MNlNFn10cexh1LL6OMdiswNc,2641
 keras_aug/layers/__internal__/base_layer_test.py,sha256=2_pAbKJg07fqbAcDM9tma3YfU29Fz9UAar5qsIuCWfE,1260
-keras_aug/layers/__internal__/config_test.py,sha256=dlNuZwnEl2_YZOn7Fun5e-YjOXrlkXq7bWHeAEH2VD0,7270
-keras_aug/layers/__internal__/graph_xla_mode_test.py,sha256=wswuNUeGTpIKlTxgtllF6b_LvSiCPU0YEReXxuumCl0,8579
-keras_aug/layers/__internal__/mixed_precision_test.py,sha256=br1N2dzDXfdnIwJbGDafOb_GFqOp17a7bgUhH9VZ2os,8756
-keras_aug/layers/__internal__/output_common_test.py,sha256=8C3OugI5jubR7rDSKfiafIfnknh46vt-xqdzqTuUQ4o,8205
-keras_aug/layers/__internal__/with_ragged_image_test.py,sha256=mekW9oU9vcBiDAlkh4KJO99E7MPImwMPiBB25ARBD_s,8236
+keras_aug/layers/__internal__/config_test.py,sha256=E4Z7MViAl_tZ0SRi1N12bSf53X7bey5k86J9TpCRT7w,7763
+keras_aug/layers/__internal__/graph_xla_mode_test.py,sha256=v61hmqkDRzv_5owJp5PhxEKYIeBVNY7q605ia74qMRA,10731
+keras_aug/layers/__internal__/mixed_precision_test.py,sha256=TuG65ItEvYytSNeJ7Dlr10SZdZ51QlVaKhzPbcC0QIU,10954
+keras_aug/layers/__internal__/output_common_test.py,sha256=h4w4sL83ocnXvVAIPQf-qfiZRBCe1UbyEl0ZFM98npU,16428
+keras_aug/layers/__internal__/with_ragged_image_test.py,sha256=C2itJM7RlCigvO2a-Lxkvl60GbXTVrGZpodIIUMBKVI,11480
 keras_aug/layers/augmentation/__init__.py,sha256=tw0qOvF7qlo89cH1yzXjU461gguVoFjz36ER_z13b5g,2718
 keras_aug/layers/augmentation/auto/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-keras_aug/layers/augmentation/auto/aug_mix.py,sha256=hWsfkA5qAv2R-FP4KbRj5ZP9ShHtXrtXrfoCWUFDmRI,12027
+keras_aug/layers/augmentation/auto/aug_mix.py,sha256=HG6qMbL9fj-dNFLBh0YgOilB9DQpPldiu6CqWkrjOIY,12271
 keras_aug/layers/augmentation/auto/aug_mix_test.py,sha256=S-RwDK_do8uvD1o_2Kfb4vuSLToQadqb3Wi0MVkKb_M,815
-keras_aug/layers/augmentation/auto/rand_augment.py,sha256=xW2ipB5V2HxK_t_DnDdxx0M4SSJVER3StZe2EkPFtk4,16866
-keras_aug/layers/augmentation/auto/rand_augment_test.py,sha256=4GD8vrcGE2qR5BUcyOYq9SdNXk28zOnrexgc6715pkc,609
-keras_aug/layers/augmentation/auto/trivial_augment_wide.py,sha256=9mt71Dh1GPOZhwVgq24BQGbVSET_ngo3A6Pg-tKDXgM,13055
+keras_aug/layers/augmentation/auto/rand_augment.py,sha256=xWle5W8gTPczHikgXoJbKfdjuaBHLxcP2pnrQCn1VOY,18413
+keras_aug/layers/augmentation/auto/rand_augment_test.py,sha256=TXdQ61Pyh-4o6VvNr5NB660NAQhVVv7NUi_8WH2ebWo,1281
+keras_aug/layers/augmentation/auto/trivial_augment_wide.py,sha256=vMchjaYnDu0yHYuDcK3hKfPa9JdCinewUIF5x0_Yd7U,14525
 keras_aug/layers/augmentation/auto/trivial_augment_wide_test.py,sha256=pD2R4-IMcJ-pvCLWA_q-AkawFvSuM5RDFfVD1eobMpc,368
 keras_aug/layers/augmentation/geometry/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-keras_aug/layers/augmentation/geometry/random_affine.py,sha256=Kwq_CtuSuHdU3VnQiTzPos2tJLwJTWrSOe-TksdhIss,21644
-keras_aug/layers/augmentation/geometry/random_affine_test.py,sha256=69ks671X64GpSy5xk-T3rdwBlxfs6scUgT099KJzs_g,13608
-keras_aug/layers/augmentation/geometry/random_crop.py,sha256=1ZQNJi04c03ZDrv-CcQbkFf6g3Zyiz2xKmeY9f7_Plk,10957
-keras_aug/layers/augmentation/geometry/random_crop_and_resize.py,sha256=Hx0DUqCql4NHpHsNMOUZsnt8P-JCXwRq1QlRGdDZCTM,10794
-keras_aug/layers/augmentation/geometry/random_crop_and_resize_test.py,sha256=QtnCAAjiljyRKK2Neu6nxmItzlBP7KV22q8YezdbdSA,7874
-keras_aug/layers/augmentation/geometry/random_crop_test.py,sha256=2cFLfETnfMTb1enSne-m_SEu4ZVWDsJRWHgoXP9yEOk,6189
-keras_aug/layers/augmentation/geometry/random_flip.py,sha256=aPUMB8zctP2SFyR76BfkDAYdiNkpGRVN6IxRUy6HRGs,7403
-keras_aug/layers/augmentation/geometry/random_flip_test.py,sha256=oqvIM9YC9HIHx1j_EU-cYpRbb-8w0UMJlE_n6t1Uqcc,9717
-keras_aug/layers/augmentation/geometry/random_resize.py,sha256=-vvWFa0hJf1z1JXIz3V8eN_XieoeCYKF2LuXmQPvfyA,7721
-keras_aug/layers/augmentation/geometry/random_resize_test.py,sha256=CN80FGtWaPoLzo3n0CXCiOiLBui1nn3Flpv50Lr4Zl4,6596
-keras_aug/layers/augmentation/geometry/random_rotate.py,sha256=4kv4LrpmvyVg40T2ppTazl8xIQo5JavQdfiCFBI0qBU,8303
-keras_aug/layers/augmentation/geometry/random_rotate_test.py,sha256=gb-10rjuh4jW5iiWH1UVR_8M_jO_z07ftUrnzOcQTPs,5788
-keras_aug/layers/augmentation/geometry/random_zoom_and_crop.py,sha256=yMmPeXIviB0yr_IJcv2j4e5EwtAwOVnYSd35Yeu0QZA,10026
-keras_aug/layers/augmentation/geometry/random_zoom_and_crop_test.py,sha256=JnENUKNZhNVv4PLNlZXdYH8E0b2v_PExd8lzM4_E8U0,4844
+keras_aug/layers/augmentation/geometry/random_affine.py,sha256=QujAA1cL9pPE-MDZ0a3aieWYn7Cydkrw8D6myribScU,23246
+keras_aug/layers/augmentation/geometry/random_affine_test.py,sha256=gu_IRjevYpAenWLkH6_q49eia8LpeMXHXQfFdhLg2Tw,15409
+keras_aug/layers/augmentation/geometry/random_crop.py,sha256=4qBe7oH1yiYXvNFdYBPAAGgVLfNZzSqE8uYMwtpMXd8,12054
+keras_aug/layers/augmentation/geometry/random_crop_and_resize.py,sha256=0eEqlqJa9xK1pBQhrzGjbWP_lDLMpgwZzbGUWZtMb1k,11758
+keras_aug/layers/augmentation/geometry/random_crop_and_resize_test.py,sha256=1Dj0nDtszmfZxbwyJu5yigLhSdg-aLkD0HtafQXSLQY,9817
+keras_aug/layers/augmentation/geometry/random_crop_test.py,sha256=Dn4Jila_FH4rYHgghS6euWX5EDYjAyUT_TrR8bGffNw,7738
+keras_aug/layers/augmentation/geometry/random_flip.py,sha256=Gp_MYa9mCg3z7MP2_cd57yRWMQC4Nlkg1FvLLcv4PsQ,7997
+keras_aug/layers/augmentation/geometry/random_flip_test.py,sha256=ES_GVA5S3aRur99rykVlUclyyuqxU1q6qa4IEhup1es,11147
+keras_aug/layers/augmentation/geometry/random_resize.py,sha256=P9QJ1eQdGMeTvZbWJaNro6hXaObqd1_pVgXYPqyBGDM,7186
+keras_aug/layers/augmentation/geometry/random_resize_test.py,sha256=7Y81M0ZQtwfqHnYSlwJd_YHXAvb6GbKAJ9y3BBGX7VI,8591
+keras_aug/layers/augmentation/geometry/random_rotate.py,sha256=0NI1yxmzihUkwqaeOq5EmQi1MunfS1DR0jt4FwX4E5k,9239
+keras_aug/layers/augmentation/geometry/random_rotate_test.py,sha256=mMS6xB_KyWHnWak0Pb31VkkruF30VAp7MIm3rMD7FPk,7395
+keras_aug/layers/augmentation/geometry/random_zoom_and_crop.py,sha256=ebSBt4_ES6gAofiIQaC7TZ019url8yRAR9a62BJ_gm0,12633
+keras_aug/layers/augmentation/geometry/random_zoom_and_crop_test.py,sha256=AS_71ko8qtWw2cdyNtQsUFmoD-4CS2EX4yP_WrfSbyM,6808
 keras_aug/layers/augmentation/intensity/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 keras_aug/layers/augmentation/intensity/channel_shuffle.py,sha256=E35wT-ogq3zGo7zdRN51hkfCCspPlTVhrJ_D3kyKgRs,3356
 keras_aug/layers/augmentation/intensity/channel_shuffle_test.py,sha256=iIecfbCnfx6sq8WyO-mbO5b38E4bE4wQ0ZldGf_yc8M,1633
 keras_aug/layers/augmentation/intensity/random_blur.py,sha256=HUB47YZj9I_UKK31R_c7LALcaEa5hFB7vZg5FyaMu_w,4167
 keras_aug/layers/augmentation/intensity/random_blur_test.py,sha256=lyTbq2csU01kbQqrx0YkBsXHFK7u-T7s9zILDcuwR_Q,1010
 keras_aug/layers/augmentation/intensity/random_channel_shift.py,sha256=sOp34yRyufS8qEWCRnvM21vduK-43YTcSZO40yefs4U,3481
 keras_aug/layers/augmentation/intensity/random_channel_shift_test.py,sha256=E9TERzTBqz4ENh2TaFBEoXG3nUh6r0zRRCsWHIKE5Jg,1506
@@ -67,47 +67,47 @@
 keras_aug/layers/augmentation/intensity/random_posterize.py,sha256=D3MGbjWfZV-k0y6Fi0_7Rc5pRPCcs0NFe66WTwuj9VE,4388
 keras_aug/layers/augmentation/intensity/random_posterize_test.py,sha256=mYsi57joSP_f4ZB5h0ywq3GQTlKWw-tamlSlEhvobQ0,2768
 keras_aug/layers/augmentation/intensity/random_sharpness.py,sha256=y7R9WjYqLNbIg8EDMzeOjlc4fL33Dex4FrqJNhaXEr8,5116
 keras_aug/layers/augmentation/intensity/random_sharpness_test.py,sha256=Sl-RwdORHIP_nFPzpmircSkRwDfIfFznHLdX7SNQF7s,1366
 keras_aug/layers/augmentation/intensity/random_solarize.py,sha256=PiqPlO4UNjS8WwPoCabxlegKiyK4vGohJ5kEfb1dDBE,5125
 keras_aug/layers/augmentation/intensity/random_solarize_test.py,sha256=wGv4CMkqSHSQQQcxNFaK5JhlfLnL0by06gdfUwr5XMc,2269
 keras_aug/layers/augmentation/mix/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-keras_aug/layers/augmentation/mix/cut_mix.py,sha256=XympyM7LF11ZtYjjSl5pyRlalOhKtQuXhvHp8ZNKqCc,6278
-keras_aug/layers/augmentation/mix/cut_mix_test.py,sha256=aeRKn78xXa9sfrdt98FwO0vtKDGb7-dXUxXmOFeyZpQ,3212
-keras_aug/layers/augmentation/mix/mix_up.py,sha256=jREvYP1QGRfMb8QWMp8jPw9vTJ64uDVEhpdQwWKhUo4,5955
+keras_aug/layers/augmentation/mix/cut_mix.py,sha256=v8eQr17L0Ia370g6z89JdxNRN18GyyLDwHyMH7mpBOo,7143
+keras_aug/layers/augmentation/mix/cut_mix_test.py,sha256=ovlqGpZhwm1upzXfPcaK3qgLXhqB2qc91-7f-1wbjgs,4258
+keras_aug/layers/augmentation/mix/mix_up.py,sha256=uoGWTXLzzXsHNcFoCI3eEY2HsA67ikqpBXYCbIXMkzc,6149
 keras_aug/layers/augmentation/mix/mix_up_test.py,sha256=KEkin-aR2z0AhiKwJxRS5bL1JDF73gAy-GJ3oUV19KE,2947
-keras_aug/layers/augmentation/mix/mosaic.py,sha256=XGmjhhWXyKeEARqZJBwDAdazfANwob5qG86wZKLCbsQ,16258
+keras_aug/layers/augmentation/mix/mosaic.py,sha256=LeR2K6AwT4nHqrQKoxY7A4qinuh9faGMXH4gaAPRJdI,16288
 keras_aug/layers/augmentation/mix/mosaic_test.py,sha256=IeL4RqoH7koON71vUV4wgJT0iNTl-m6YBTOXFrnYio4,2297
 keras_aug/layers/augmentation/regularization/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 keras_aug/layers/augmentation/regularization/random_channel_dropout.py,sha256=FEVeDXfaPL4ZMT5a_SYLkbhwNExq9EZzJ-G7rprh5WU,3737
 keras_aug/layers/augmentation/regularization/random_channel_dropout_test.py,sha256=WD_dn-QPsj5XouGp-DG38TZgpPUhgmWRbfwMc1KmBuY,706
 keras_aug/layers/augmentation/regularization/random_cutout.py,sha256=EF3WYSjybFwgD0vjAE-T9Xbsz3MYx-upkI5AL6VDu7c,9425
 keras_aug/layers/augmentation/regularization/random_cutout_test.py,sha256=0qq8LouUR0Km9ulqFcA5aHbMrQK8F2K2IFbsn6S0Ho4,3189
-keras_aug/layers/augmentation/regularization/random_erase.py,sha256=dK_njFvbD5jKrlqe6gbwIPuy8eOLI1kifiIYqJ2aiAs,8126
+keras_aug/layers/augmentation/regularization/random_erase.py,sha256=N-_0j2v9PCSKAL2ogmeI8L9qMQB0j6aNiv5cBjjBc3Y,7296
 keras_aug/layers/augmentation/regularization/random_erase_test.py,sha256=d53rMfqVNVvz44nEQ-YnjisUbP1towMXFjad_yVfmHw,3236
-keras_aug/layers/augmentation/regularization/random_grid_mask.py,sha256=JAnrHk14s1EC9WJ__qhDiBPJvwTca01e8A8HigMWsGE,11490
+keras_aug/layers/augmentation/regularization/random_grid_mask.py,sha256=g9VvlYRHtQAa0zBp3FrMRwnQVPkCfHqRvyncoJD1eI8,10927
 keras_aug/layers/augmentation/regularization/random_grid_mask_test.py,sha256=2v4styEiep1EE5WujsDueoUW_FT_aWtZVJKaChz9Lqk,2161
 keras_aug/layers/augmentation/utility/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-keras_aug/layers/augmentation/utility/random_apply.py,sha256=vSz__QXkF97D6G1tbI829CvkwmrVkphqTS4USf4NPLE,6301
+keras_aug/layers/augmentation/utility/random_apply.py,sha256=a62pFsOCuY90cnMUw7yE06nvcDDpspnZzQzdHiT4iGY,6080
 keras_aug/layers/augmentation/utility/random_apply_test.py,sha256=aSycm6w77fAmbjwxx_jlGcVGL9p77bfztMMr1ykBbms,2792
-keras_aug/layers/augmentation/utility/random_choice.py,sha256=UtOUJVPUWbTqE3FVe80hNy4qdda-bEjRXmOli6CHsO4,6537
+keras_aug/layers/augmentation/utility/random_choice.py,sha256=I7qREwRkTmffHxB8JInqlwRyFlXfm-UwAw70rcWGMZc,6457
 keras_aug/layers/augmentation/utility/random_choice_test.py,sha256=CtATBligXBzrrBtSTgNzs8ny_ueiEiBQ7Nz0vyJ5PU0,2732
 keras_aug/layers/augmentation/utility/repeated_augment.py,sha256=wtR-oAo8gi09JTdjmCfr8IfkJAx4r931JyjBWq7CBFE,3588
 keras_aug/layers/augmentation/utility/repeated_augment_test.py,sha256=2VJXo_X9dW4gGRRibknhWxkNyoD4kgamrhxTHLVEcFE,1106
 keras_aug/layers/base/__init__.py,sha256=MaYYjGjqxMesKTnNAJyjQi97ZRM7CM2F5KA-BfpiMxM,98
-keras_aug/layers/base/vectorized_base_random_layer.py,sha256=nLhbEJWsJ6H6mIy2pEONG5PLNFFayPsUfST6BW4bEKc,21658
-keras_aug/layers/base/vectorized_base_random_layer_test.py,sha256=NniZ8ZfEKeVjQ50-Hmqzkz4ztBnB4gKs2GfA9lHnmuc,21212
-keras_aug/layers/preprocessing/__init__.py,sha256=eNdDMLGIk7lRZWUT--f7LcM01eNBQh5-fXNFAH-W-2U,723
+keras_aug/layers/base/vectorized_base_random_layer.py,sha256=nVUM0XdUwASkST7-YJoOWeBEV8GPzKkwbtmQxAyMZ_Q,24094
+keras_aug/layers/base/vectorized_base_random_layer_test.py,sha256=YZotN9fBol5iKI7PFpJqQg388WBDFiLBv4HwL1taax4,22086
+keras_aug/layers/preprocessing/__init__.py,sha256=71fAwRUtZVKkRNbQrDgJ5gOhgDzvOTS8RMLMGr3FoM8,825
 keras_aug/layers/preprocessing/geometry/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-keras_aug/layers/preprocessing/geometry/center_crop.py,sha256=f20M6UcmcMjprV8or3zR06-NTM-40rs0URkK8jWrprg,10646
-keras_aug/layers/preprocessing/geometry/center_crop_test.py,sha256=8j371XeiaP7HueXPj8mJJ_LJo7GsPsnQ8OzqUho-KKc,6669
-keras_aug/layers/preprocessing/geometry/pad_if_needed.py,sha256=QpVyQKNrtOO8gfLQnLXjUMjXbXDi1mKA1IOW1kQu42U,10878
-keras_aug/layers/preprocessing/geometry/pad_if_needed_test.py,sha256=Iufj25dVc0HeakyT70YZ2whCdXkcMe4AEy5WzbGiQK8,8071
-keras_aug/layers/preprocessing/geometry/resize.py,sha256=jlZr00-VZ6B1JTfzleo9XWAkJI1r22vmWCCH37ouRKs,17026
-keras_aug/layers/preprocessing/geometry/resize_test.py,sha256=uZn1k60hOucidbqsLWJ2LgN2p3z-QUmAdogtePtKACM,20408
+keras_aug/layers/preprocessing/geometry/center_crop.py,sha256=vUAl5EpMnFP0Bvk4vnt6E7WEjEDO3XhPVd5zVS5VJZU,10864
+keras_aug/layers/preprocessing/geometry/center_crop_test.py,sha256=9-PFSgp4Qz2YSMk61fwInFUxrmBAPk-V9rpZNQRRnq8,8368
+keras_aug/layers/preprocessing/geometry/pad_if_needed.py,sha256=w2QwQkAR_S4qg0KIZanPs-OV6mXyNOK5-xuKsZxkZzk,10833
+keras_aug/layers/preprocessing/geometry/pad_if_needed_test.py,sha256=n3eFxoA-B92eRKT-hAwFwanvHFsZZsPaMBYvAAuuIUc,9878
+keras_aug/layers/preprocessing/geometry/resize.py,sha256=vSNDnkQblm3w6zCeLVNReZ5Gjhs2tBnfIBsNFf5lGII,15545
+keras_aug/layers/preprocessing/geometry/resize_test.py,sha256=g1o2U1X6keQEDL5aa40Qzw_bYTKkfnsvhMPWPz6ZUW0,22167
 keras_aug/layers/preprocessing/intensity/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 keras_aug/layers/preprocessing/intensity/auto_contrast.py,sha256=s-o7Iv_cBpbeyQOLtK3Rz3vkQWAih8_1c9vCd8tiZrI,2878
 keras_aug/layers/preprocessing/intensity/auto_contrast_test.py,sha256=MP-rK8KaALldUhdZ0m05E9brf7JAOJGQXz52UyxcM2E,2698
 keras_aug/layers/preprocessing/intensity/equalize.py,sha256=CBuOK6fiPXkk5bBeCQLcZPRARyzb4G8_B8UkJ51nB9k,4513
 keras_aug/layers/preprocessing/intensity/equalize_test.py,sha256=KyPNwIUt2CzxJxMhmqSx6_Zqrr2336oJbMublXUMg8M,1529
 keras_aug/layers/preprocessing/intensity/grayscale.py,sha256=x4PfC-VHFiTkpdgA9Etk-k2_HAx9rm9NCZ4Z3MH9yIE,2376
 keras_aug/layers/preprocessing/intensity/grayscale_test.py,sha256=GQCq1YcKtibK5jaczt3izY5-aQdXBfjPrpY4O6al8SA,1224
@@ -116,18 +116,18 @@
 keras_aug/layers/preprocessing/intensity/invert.py,sha256=HonGomgRkstpmqLCsNcDo8hXI0WTKNQby3VqxYsySfA,1653
 keras_aug/layers/preprocessing/intensity/invert_test.py,sha256=R5dMDK3xEXRHnUkoglhPSH9-NX27l8Q_xdVwqiX6ED0,459
 keras_aug/layers/preprocessing/intensity/normalize.py,sha256=_K5Z4Agk6ccm3miDIiHfNCmu1cnLyyrzOS8CVrnHupk,2931
 keras_aug/layers/preprocessing/intensity/normalize_test.py,sha256=t_pKz0tAXd4K2wpOqZOY8AFfsxtX7Czv9soyEFiXjzA,1483
 keras_aug/layers/preprocessing/intensity/rescale.py,sha256=DQsimIZrdtDFcQNuTfS3ibG-4LhLeahTqk-ePcd5G7o,1923
 keras_aug/layers/preprocessing/intensity/rescale_test.py,sha256=AHYYlcfLN7EDCoQKEKVcHzy7wzLbZPrkdMB808miATU,1365
 keras_aug/utils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-keras_aug/utils/augmentation.py,sha256=XAxg_d7iAWmjEV-ymAKU7GIq-QQnsG1byo3qdKHV01M,15362
-keras_aug/utils/augmentation_test.py,sha256=QCO2YtBZkhdrO8rjvVP2T3dy1LS4yXDy0INhqkpparQ,4990
-keras_aug/utils/bounding_box.py,sha256=SaIep1Mt8HlVFgE1nb81pfg4hIp2aHK_MdFkGtnoHA8,5197
+keras_aug/utils/augmentation.py,sha256=tXuaz46A-Qy7ny6Xmok93xK24-OKU4mq78FZ_3TZfCE,18127
+keras_aug/utils/augmentation_test.py,sha256=dC1PrcuSZZIUAa3tY4SEKjIsnpAgswf9HCaNItaogKQ,7832
+keras_aug/utils/bounding_box.py,sha256=6--joJSNVjoivaGndngzfL1SbfygJDDQtTdx8iLOJgs,8682
 keras_aug/utils/bounding_box_test.py,sha256=q3NicuCAB_0vai1OCGXXCfkpziqcivK_vl_-fu00Jqg,3235
 keras_aug/utils/conditional_imports.py,sha256=90U2Wj_Fuvfn01ipGtnZdYvd9MO2THDZMhZq6Os_ErE,373
-keras_aug/utils/demo.py,sha256=Wz-44958Mrx_m0VZvSLoRa2oJ53S_vZyMzxnVJdZq48,4596
-keras_aug-0.5.1.dist-info/LICENSE,sha256=xktsWk7LDJmjQ7sU46fqqpB4cWW9iXjs85qc_fRAxSg,11456
-keras_aug-0.5.1.dist-info/METADATA,sha256=KWCXYFwAVDjrsyl-HepuxujrICRoJva_EyrAbf-q9oo,9858
-keras_aug-0.5.1.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-keras_aug-0.5.1.dist-info/top_level.txt,sha256=fR_dHLAAVS4WR1ywYPQARPvXVCtPMeCSd6T_OqIgj28,10
-keras_aug-0.5.1.dist-info/RECORD,,
+keras_aug/utils/demo.py,sha256=V5Jt-6RPaXEFDl0MCIrBxSZD8vaIvKFcvL8Igb7K0cQ,6101
+keras_aug-0.5.2.dist-info/LICENSE,sha256=xktsWk7LDJmjQ7sU46fqqpB4cWW9iXjs85qc_fRAxSg,11456
+keras_aug-0.5.2.dist-info/METADATA,sha256=mXGx36fFncDlzZbNTJ5n3N384yDUgXWinivmw3n5FiM,13601
+keras_aug-0.5.2.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+keras_aug-0.5.2.dist-info/top_level.txt,sha256=fR_dHLAAVS4WR1ywYPQARPvXVCtPMeCSd6T_OqIgj28,10
+keras_aug-0.5.2.dist-info/RECORD,,
```

