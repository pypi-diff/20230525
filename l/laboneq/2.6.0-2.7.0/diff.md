# Comparing `tmp/laboneq-2.6.0-py3-none-any.whl.zip` & `tmp/laboneq-2.7.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,248 +1,250 @@
-Zip file size: 932038 bytes, number of entries: 246
--rw-rw-rw-  2.0 unx        5 b- defN 23-May-11 13:50 laboneq/VERSION.txt
--rw-r--r--  2.0 unx      306 b- defN 23-Feb-02 07:13 laboneq/__init__.py
+Zip file size: 939609 bytes, number of entries: 248
+-rw-rw-rw-  2.0 unx        5 b- defN 23-May-25 13:25 laboneq/VERSION.txt
+-rw-r--r--  2.0 unx      239 b- defN 23-May-24 14:34 laboneq/__init__.py
 -rw-r--r--  2.0 unx     2829 b- defN 23-Feb-02 07:13 laboneq/_token.py
--rw-r--r--  2.0 unx      928 b- defN 23-May-10 12:50 laboneq/_utils.py
+-rw-r--r--  2.0 unx      928 b- defN 23-May-17 00:03 laboneq/_utils.py
 -rw-r--r--  2.0 unx      238 b- defN 23-Feb-02 07:13 laboneq/_version.py
--rw-r--r--  2.0 unx     1525 b- defN 23-May-11 13:51 laboneq/simple.py
+-rw-r--r--  2.0 unx     1538 b- defN 23-May-25 13:25 laboneq/simple.py
 -rw-r--r--  2.0 unx      184 b- defN 23-Feb-02 07:13 laboneq/_observability/__init__.py
 -rw-r--r--  2.0 unx      538 b- defN 23-Feb-02 07:13 laboneq/_observability/tracing/__init__.py
 -rw-r--r--  2.0 unx      893 b- defN 23-Feb-16 12:45 laboneq/_observability/tracing/_noop_tracer.py
 -rw-r--r--  2.0 unx     2309 b- defN 23-Feb-16 12:45 laboneq/_observability/tracing/_tracer.py
 -rw-r--r--  2.0 unx      444 b- defN 23-Feb-02 07:13 laboneq/compiler/__init__.py
 -rw-r--r--  2.0 unx      204 b- defN 23-Feb-02 07:13 laboneq/compiler/fastlogging.py
--rw-rw-rw-  2.0 unx    22524 b- defN 23-Apr-28 11:39 laboneq/compiler/qccs-schema_2_5_0.json
+-rw-rw-rw-  2.0 unx    22524 b- defN 23-May-17 00:03 laboneq/compiler/qccs-schema_2_5_0.json
 -rw-r--r--  2.0 unx      666 b- defN 23-Feb-02 07:13 laboneq/compiler/remote.py
 -rw-r--r--  2.0 unx      654 b- defN 23-Apr-06 14:15 laboneq/compiler/code_generator/__init__.py
--rw-r--r--  2.0 unx    18645 b- defN 23-Apr-06 14:15 laboneq/compiler/code_generator/analyze_events.py
--rw-r--r--  2.0 unx    26665 b- defN 23-May-10 12:50 laboneq/compiler/code_generator/analyze_playback.py
--rw-r--r--  2.0 unx    71375 b- defN 23-May-11 07:18 laboneq/compiler/code_generator/code_generator.py
--rw-r--r--  2.0 unx     4026 b- defN 23-Apr-06 14:15 laboneq/compiler/code_generator/command_table_tracker.py
--rw-r--r--  2.0 unx     2880 b- defN 23-Apr-28 11:39 laboneq/compiler/code_generator/compressor.py
+-rw-r--r--  2.0 unx    18645 b- defN 23-May-24 13:41 laboneq/compiler/code_generator/analyze_events.py
+-rw-r--r--  2.0 unx    26665 b- defN 23-May-24 13:41 laboneq/compiler/code_generator/analyze_playback.py
+-rw-r--r--  2.0 unx    72652 b- defN 23-May-25 13:25 laboneq/compiler/code_generator/code_generator.py
+-rw-r--r--  2.0 unx     4026 b- defN 23-May-17 00:03 laboneq/compiler/code_generator/command_table_tracker.py
+-rw-r--r--  2.0 unx     2880 b- defN 23-May-17 00:03 laboneq/compiler/code_generator/compressor.py
 -rw-r--r--  2.0 unx     1414 b- defN 23-Apr-06 14:15 laboneq/compiler/code_generator/feedback_register_allocator.py
 -rw-r--r--  2.0 unx    10355 b- defN 23-Apr-06 14:15 laboneq/compiler/code_generator/interval_calculator.py
--rw-r--r--  2.0 unx    17825 b- defN 23-May-09 12:30 laboneq/compiler/code_generator/measurement_calculator.py
--rw-r--r--  2.0 unx    30333 b- defN 23-May-10 12:50 laboneq/compiler/code_generator/sampled_event_handler.py
--rw-r--r--  2.0 unx    19239 b- defN 23-May-10 12:50 laboneq/compiler/code_generator/seq_c_generator.py
--rw-r--r--  2.0 unx     6333 b- defN 23-May-10 12:50 laboneq/compiler/code_generator/seqc_tracker.py
--rw-r--r--  2.0 unx     7741 b- defN 23-Apr-06 14:15 laboneq/compiler/code_generator/signatures.py
+-rw-r--r--  2.0 unx    17825 b- defN 23-May-17 00:03 laboneq/compiler/code_generator/measurement_calculator.py
+-rw-r--r--  2.0 unx    30380 b- defN 23-May-25 07:57 laboneq/compiler/code_generator/sampled_event_handler.py
+-rw-r--r--  2.0 unx    19239 b- defN 23-May-25 13:25 laboneq/compiler/code_generator/seq_c_generator.py
+-rw-r--r--  2.0 unx     6333 b- defN 23-May-17 00:03 laboneq/compiler/code_generator/seqc_tracker.py
+-rw-r--r--  2.0 unx     9915 b- defN 23-May-25 07:57 laboneq/compiler/code_generator/signatures.py
 -rw-r--r--  2.0 unx     3500 b- defN 23-Feb-28 13:10 laboneq/compiler/code_generator/utils.py
--rw-r--r--  2.0 unx     3737 b- defN 23-May-10 12:50 laboneq/compiler/code_generator/wave_compressor.py
+-rw-r--r--  2.0 unx     7697 b- defN 23-May-25 07:57 laboneq/compiler/code_generator/wave_compressor.py
 -rw-r--r--  2.0 unx     1476 b- defN 23-Feb-28 13:10 laboneq/compiler/code_generator/wave_index_tracker.py
 -rw-r--r--  2.0 unx       77 b- defN 23-Feb-02 07:13 laboneq/compiler/common/__init__.py
 -rw-r--r--  2.0 unx     1093 b- defN 23-Apr-06 14:15 laboneq/compiler/common/awg_info.py
--rw-r--r--  2.0 unx     1926 b- defN 23-May-10 12:50 laboneq/compiler/common/awg_sampled_event.py
+-rw-r--r--  2.0 unx     1926 b- defN 23-May-17 00:03 laboneq/compiler/common/awg_sampled_event.py
 -rw-r--r--  2.0 unx      480 b- defN 23-Feb-02 07:13 laboneq/compiler/common/awg_signal_type.py
--rw-r--r--  2.0 unx     4015 b- defN 23-May-10 12:50 laboneq/compiler/common/compiler_settings.py
--rw-r--r--  2.0 unx     6058 b- defN 23-May-05 14:53 laboneq/compiler/common/device_type.py
--rw-r--r--  2.0 unx     1532 b- defN 23-May-11 07:18 laboneq/compiler/common/event_type.py
+-rw-r--r--  2.0 unx     4015 b- defN 23-May-17 00:03 laboneq/compiler/common/compiler_settings.py
+-rw-r--r--  2.0 unx     6058 b- defN 23-May-17 00:03 laboneq/compiler/common/device_type.py
+-rw-r--r--  2.0 unx     1624 b- defN 23-May-23 08:56 laboneq/compiler/common/event_type.py
 -rw-r--r--  2.0 unx      229 b- defN 23-Mar-07 13:19 laboneq/compiler/common/play_wave_type.py
--rw-r--r--  2.0 unx      580 b- defN 23-Apr-06 14:15 laboneq/compiler/common/pulse_parameters.py
--rw-r--r--  2.0 unx     2594 b- defN 23-Apr-28 11:39 laboneq/compiler/common/signal_obj.py
+-rw-r--r--  2.0 unx      580 b- defN 23-May-17 00:03 laboneq/compiler/common/pulse_parameters.py
+-rw-r--r--  2.0 unx     2594 b- defN 23-May-24 13:41 laboneq/compiler/common/signal_obj.py
 -rw-r--r--  2.0 unx      400 b- defN 23-Feb-02 07:13 laboneq/compiler/common/trigger_mode.py
 -rw-r--r--  2.0 unx      154 b- defN 23-Feb-02 07:13 laboneq/compiler/experiment_access/__init__.py
 -rw-r--r--  2.0 unx      222 b- defN 23-Apr-06 14:15 laboneq/compiler/experiment_access/acquire_info.py
--rw-r--r--  2.0 unx      349 b- defN 23-Apr-28 11:39 laboneq/compiler/experiment_access/device_info.py
--rw-r--r--  2.0 unx    44928 b- defN 23-May-11 07:18 laboneq/compiler/experiment_access/dsl_loader.py
--rw-r--r--  2.0 unx    16509 b- defN 23-May-11 07:18 laboneq/compiler/experiment_access/experiment_dao.py
--rw-r--r--  2.0 unx    14106 b- defN 23-May-11 07:18 laboneq/compiler/experiment_access/json_dumper.py
--rw-r--r--  2.0 unx    21004 b- defN 23-May-11 07:18 laboneq/compiler/experiment_access/json_loader.py
--rw-r--r--  2.0 unx     6182 b- defN 23-Apr-28 11:39 laboneq/compiler/experiment_access/loader_base.py
+-rw-r--r--  2.0 unx      349 b- defN 23-May-17 00:03 laboneq/compiler/experiment_access/device_info.py
+-rw-r--r--  2.0 unx    45262 b- defN 23-May-25 13:25 laboneq/compiler/experiment_access/dsl_loader.py
+-rw-r--r--  2.0 unx    16767 b- defN 23-May-23 08:56 laboneq/compiler/experiment_access/experiment_dao.py
+-rw-r--r--  2.0 unx    14264 b- defN 23-May-23 08:56 laboneq/compiler/experiment_access/json_dumper.py
+-rw-r--r--  2.0 unx    21043 b- defN 23-May-23 08:56 laboneq/compiler/experiment_access/json_loader.py
+-rw-r--r--  2.0 unx     6182 b- defN 23-May-22 15:14 laboneq/compiler/experiment_access/loader_base.py
 -rw-r--r--  2.0 unx      270 b- defN 23-Apr-06 14:15 laboneq/compiler/experiment_access/marker.py
--rw-r--r--  2.0 unx      286 b- defN 23-Apr-28 11:39 laboneq/compiler/experiment_access/oscillator_info.py
+-rw-r--r--  2.0 unx      286 b- defN 23-May-17 00:03 laboneq/compiler/experiment_access/oscillator_info.py
 -rw-r--r--  2.0 unx      197 b- defN 23-Apr-06 14:15 laboneq/compiler/experiment_access/param_ref.py
--rw-r--r--  2.0 unx     1311 b- defN 23-May-10 12:50 laboneq/compiler/experiment_access/pulse_def.py
+-rw-r--r--  2.0 unx     1311 b- defN 23-May-17 00:03 laboneq/compiler/experiment_access/pulse_def.py
 -rw-r--r--  2.0 unx      851 b- defN 23-Apr-06 14:15 laboneq/compiler/experiment_access/section_info.py
 -rw-r--r--  2.0 unx     1069 b- defN 23-Apr-06 14:15 laboneq/compiler/experiment_access/section_signal_pulse.py
 -rw-r--r--  2.0 unx      387 b- defN 23-Apr-06 14:15 laboneq/compiler/experiment_access/signal_info.py
 -rw-r--r--  2.0 unx       77 b- defN 23-Feb-02 07:13 laboneq/compiler/scheduler/__init__.py
--rw-r--r--  2.0 unx     3265 b- defN 23-May-04 12:22 laboneq/compiler/scheduler/case_schedule.py
--rw-r--r--  2.0 unx     7439 b- defN 23-May-04 12:22 laboneq/compiler/scheduler/interval_schedule.py
--rw-r--r--  2.0 unx     3327 b- defN 23-May-04 12:22 laboneq/compiler/scheduler/loop_iteration_schedule.py
--rw-r--r--  2.0 unx     8576 b- defN 23-May-04 12:22 laboneq/compiler/scheduler/loop_schedule.py
--rw-r--r--  2.0 unx     9267 b- defN 23-May-11 07:18 laboneq/compiler/scheduler/match_schedule.py
--rw-r--r--  2.0 unx     2248 b- defN 23-May-04 12:22 laboneq/compiler/scheduler/oscillator_schedule.py
--rw-r--r--  2.0 unx     1761 b- defN 23-May-04 12:22 laboneq/compiler/scheduler/phase_reset_schedule.py
--rw-r--r--  2.0 unx     1808 b- defN 23-May-04 12:22 laboneq/compiler/scheduler/preorder_map.py
--rw-r--r--  2.0 unx     3821 b- defN 23-May-04 12:22 laboneq/compiler/scheduler/pulse_phase.py
--rw-r--r--  2.0 unx     6958 b- defN 23-May-04 12:22 laboneq/compiler/scheduler/pulse_schedule.py
--rw-r--r--  2.0 unx      621 b- defN 23-May-04 12:22 laboneq/compiler/scheduler/reserve_schedule.py
--rw-r--r--  2.0 unx     1367 b- defN 23-May-04 12:22 laboneq/compiler/scheduler/root_schedule.py
+-rw-r--r--  2.0 unx     3265 b- defN 23-May-17 00:03 laboneq/compiler/scheduler/case_schedule.py
+-rw-r--r--  2.0 unx     7439 b- defN 23-May-17 00:03 laboneq/compiler/scheduler/interval_schedule.py
+-rw-r--r--  2.0 unx     3327 b- defN 23-May-17 00:03 laboneq/compiler/scheduler/loop_iteration_schedule.py
+-rw-r--r--  2.0 unx     8576 b- defN 23-May-17 00:03 laboneq/compiler/scheduler/loop_schedule.py
+-rw-r--r--  2.0 unx    10452 b- defN 23-May-25 07:57 laboneq/compiler/scheduler/match_schedule.py
+-rw-r--r--  2.0 unx     2248 b- defN 23-May-17 00:03 laboneq/compiler/scheduler/oscillator_schedule.py
+-rw-r--r--  2.0 unx     1761 b- defN 23-May-17 00:03 laboneq/compiler/scheduler/phase_reset_schedule.py
+-rw-r--r--  2.0 unx     1808 b- defN 23-May-17 00:03 laboneq/compiler/scheduler/preorder_map.py
+-rw-r--r--  2.0 unx     3821 b- defN 23-May-17 00:03 laboneq/compiler/scheduler/pulse_phase.py
+-rw-r--r--  2.0 unx     6958 b- defN 23-May-17 00:03 laboneq/compiler/scheduler/pulse_schedule.py
+-rw-r--r--  2.0 unx      621 b- defN 23-May-17 00:03 laboneq/compiler/scheduler/reserve_schedule.py
+-rw-r--r--  2.0 unx     1367 b- defN 23-May-17 00:03 laboneq/compiler/scheduler/root_schedule.py
 -rw-r--r--  2.0 unx     1949 b- defN 23-Feb-09 09:31 laboneq/compiler/scheduler/sampling_rate_tracker.py
--rw-r--r--  2.0 unx     1012 b- defN 23-May-04 12:22 laboneq/compiler/scheduler/schedule_data.py
--rw-r--r--  2.0 unx    40949 b- defN 23-May-10 12:50 laboneq/compiler/scheduler/scheduler.py
--rw-r--r--  2.0 unx    13191 b- defN 23-May-04 12:22 laboneq/compiler/scheduler/section_schedule.py
--rw-r--r--  2.0 unx      757 b- defN 23-May-04 12:22 laboneq/compiler/scheduler/utils.py
+-rw-r--r--  2.0 unx     1115 b- defN 23-May-25 07:57 laboneq/compiler/scheduler/schedule_data.py
+-rw-r--r--  2.0 unx    41127 b- defN 23-May-25 07:57 laboneq/compiler/scheduler/scheduler.py
+-rw-r--r--  2.0 unx    13191 b- defN 23-May-17 00:03 laboneq/compiler/scheduler/section_schedule.py
+-rw-r--r--  2.0 unx      757 b- defN 23-May-17 00:03 laboneq/compiler/scheduler/utils.py
 -rw-r--r--  2.0 unx       77 b- defN 23-Feb-02 07:13 laboneq/compiler/workflow/__init__.py
--rw-r--r--  2.0 unx    50498 b- defN 23-May-11 07:18 laboneq/compiler/workflow/compiler.py
+-rw-r--r--  2.0 unx    51030 b- defN 23-May-25 13:25 laboneq/compiler/workflow/compiler.py
 -rw-r--r--  2.0 unx    12424 b- defN 23-Feb-28 13:10 laboneq/compiler/workflow/precompensation_helpers.py
--rw-r--r--  2.0 unx    12420 b- defN 23-May-09 12:30 laboneq/compiler/workflow/recipe_generator.py
+-rw-r--r--  2.0 unx    12522 b- defN 23-May-25 13:25 laboneq/compiler/workflow/recipe_generator.py
 -rw-r--r--  2.0 unx       77 b- defN 23-Apr-06 14:15 laboneq/contrib/__init__.py
 -rw-r--r--  2.0 unx       77 b- defN 23-Apr-06 14:15 laboneq/contrib/bloch_simulator_pulse_plotter/__init__.py
 -rw-r--r--  2.0 unx       77 b- defN 23-Apr-06 14:15 laboneq/contrib/bloch_simulator_pulse_plotter/inspector/__init__.py
 -rw-r--r--  2.0 unx     4511 b- defN 23-Apr-06 14:15 laboneq/contrib/bloch_simulator_pulse_plotter/inspector/update_inspect.py
 -rw-r--r--  2.0 unx       77 b- defN 23-Apr-06 14:15 laboneq/contrib/bloch_simulator_pulse_plotter/plotter/__init__.py
 -rw-r--r--  2.0 unx     3379 b- defN 23-Apr-06 14:15 laboneq/contrib/bloch_simulator_pulse_plotter/plotter/plot_funs.py
 -rw-r--r--  2.0 unx       77 b- defN 23-Apr-06 14:15 laboneq/contrib/bloch_simulator_pulse_plotter/pulse_simulator/__init__.py
 -rw-r--r--  2.0 unx     2833 b- defN 23-Apr-06 14:15 laboneq/contrib/bloch_simulator_pulse_plotter/pulse_simulator/bloch_simulator.py
--rw-r--r--  2.0 unx       77 b- defN 23-Apr-06 14:15 laboneq/contrib/example_helpers/__init__.py
--rw-r--r--  2.0 unx     6272 b- defN 23-Apr-06 14:15 laboneq/contrib/example_helpers/example_notebook_helper.py
--rw-r--r--  2.0 unx     4116 b- defN 23-Apr-06 14:15 laboneq/contrib/example_helpers/feedback_helper.py
--rw-r--r--  2.0 unx     3581 b- defN 23-Apr-06 14:15 laboneq/contrib/example_helpers/qubit_helper.py
--rw-r--r--  2.0 unx     8830 b- defN 23-Apr-06 14:15 laboneq/contrib/example_helpers/randomized_benchmarking_helper.py
--rw-r--r--  2.0 unx       77 b- defN 23-Apr-06 14:15 laboneq/contrib/example_helpers/data_analysis/__init__.py
--rw-r--r--  2.0 unx     6670 b- defN 23-Apr-06 14:15 laboneq/contrib/example_helpers/data_analysis/data_analysis.py
--rw-r--r--  2.0 unx       77 b- defN 23-Apr-06 14:15 laboneq/contrib/example_helpers/descriptors/__init__.py
--rw-r--r--  2.0 unx      502 b- defN 23-Apr-06 14:15 laboneq/contrib/example_helpers/descriptors/hdawg.py
--rw-r--r--  2.0 unx      956 b- defN 23-Apr-06 14:15 laboneq/contrib/example_helpers/descriptors/hdawg_uhfqa_pqsc.py
--rw-r--r--  2.0 unx     1887 b- defN 23-May-04 12:22 laboneq/contrib/example_helpers/descriptors/shfqc.py
--rw-r--r--  2.0 unx     1639 b- defN 23-May-04 12:22 laboneq/contrib/example_helpers/descriptors/shfsg.py
--rw-r--r--  2.0 unx     2472 b- defN 23-May-04 12:22 laboneq/contrib/example_helpers/descriptors/shfsg_shfqa_hdawg_pqsc.py
--rw-r--r--  2.0 unx     2160 b- defN 23-May-04 12:22 laboneq/contrib/example_helpers/descriptors/shfsg_shfqa_pqsc.py
--rw-r--r--  2.0 unx     2708 b- defN 23-May-04 12:22 laboneq/contrib/example_helpers/descriptors/shfsg_shfqa_shfqc_hdawg_pqsc.py
--rw-r--r--  2.0 unx       77 b- defN 23-Apr-06 14:15 laboneq/contrib/example_helpers/plotting/__init__.py
--rw-r--r--  2.0 unx    10340 b- defN 23-May-10 12:50 laboneq/contrib/example_helpers/plotting/plot_helpers.py
+-rw-r--r--  2.0 unx       77 b- defN 23-May-17 00:03 laboneq/contrib/example_helpers/__init__.py
+-rw-r--r--  2.0 unx     6272 b- defN 23-May-17 00:03 laboneq/contrib/example_helpers/example_notebook_helper.py
+-rw-r--r--  2.0 unx     4116 b- defN 23-May-17 00:03 laboneq/contrib/example_helpers/feedback_helper.py
+-rw-r--r--  2.0 unx     3581 b- defN 23-May-17 00:03 laboneq/contrib/example_helpers/qubit_helper.py
+-rw-r--r--  2.0 unx     8830 b- defN 23-May-17 00:03 laboneq/contrib/example_helpers/randomized_benchmarking_helper.py
+-rw-r--r--  2.0 unx       77 b- defN 23-May-17 00:03 laboneq/contrib/example_helpers/data_analysis/__init__.py
+-rw-r--r--  2.0 unx     6670 b- defN 23-May-17 00:03 laboneq/contrib/example_helpers/data_analysis/data_analysis.py
+-rw-r--r--  2.0 unx       77 b- defN 23-May-17 00:03 laboneq/contrib/example_helpers/descriptors/__init__.py
+-rw-r--r--  2.0 unx      502 b- defN 23-May-17 00:03 laboneq/contrib/example_helpers/descriptors/hdawg.py
+-rw-r--r--  2.0 unx      956 b- defN 23-May-17 00:03 laboneq/contrib/example_helpers/descriptors/hdawg_uhfqa_pqsc.py
+-rw-r--r--  2.0 unx     1887 b- defN 23-May-17 00:03 laboneq/contrib/example_helpers/descriptors/shfqc.py
+-rw-r--r--  2.0 unx     1639 b- defN 23-May-17 00:03 laboneq/contrib/example_helpers/descriptors/shfsg.py
+-rw-r--r--  2.0 unx     2472 b- defN 23-May-17 00:03 laboneq/contrib/example_helpers/descriptors/shfsg_shfqa_hdawg_pqsc.py
+-rw-r--r--  2.0 unx     2160 b- defN 23-May-17 00:03 laboneq/contrib/example_helpers/descriptors/shfsg_shfqa_pqsc.py
+-rw-r--r--  2.0 unx     2708 b- defN 23-May-17 00:03 laboneq/contrib/example_helpers/descriptors/shfsg_shfqa_shfqc_hdawg_pqsc.py
+-rw-r--r--  2.0 unx       77 b- defN 23-May-17 00:03 laboneq/contrib/example_helpers/plotting/__init__.py
+-rw-r--r--  2.0 unx    11127 b- defN 23-May-23 08:56 laboneq/contrib/example_helpers/plotting/plot_helpers.py
 -rw-r--r--  2.0 unx      308 b- defN 23-Feb-13 10:57 laboneq/controller/__init__.py
+-rw-r--r--  2.0 unx     3380 b- defN 23-May-23 08:56 laboneq/controller/attribute_value_tracker.py
 -rw-r--r--  2.0 unx     1479 b- defN 23-Feb-02 07:13 laboneq/controller/cache.py
--rw-r--r--  2.0 unx    13604 b- defN 23-May-10 12:50 laboneq/controller/communication.py
--rw-r--r--  2.0 unx    34132 b- defN 23-May-11 07:18 laboneq/controller/controller.py
--rw-r--r--  2.0 unx     4600 b- defN 23-May-05 14:53 laboneq/controller/laboneq_logging.py
+-rw-r--r--  2.0 unx    13604 b- defN 23-May-24 09:57 laboneq/controller/communication.py
+-rw-r--r--  2.0 unx    34028 b- defN 23-May-25 13:25 laboneq/controller/controller.py
+-rw-r--r--  2.0 unx     4892 b- defN 23-May-25 07:57 laboneq/controller/laboneq_logging.py
 -rw-r--r--  2.0 unx      337 b- defN 23-Feb-02 07:13 laboneq/controller/protected_session.py
--rw-r--r--  2.0 unx    15088 b- defN 23-May-11 07:18 laboneq/controller/recipe_1_4_0.py
+-rw-r--r--  2.0 unx    15188 b- defN 23-May-25 13:25 laboneq/controller/recipe_1_4_0.py
 -rw-r--r--  2.0 unx      638 b- defN 23-Feb-02 07:13 laboneq/controller/recipe_enums.py
--rw-r--r--  2.0 unx    19876 b- defN 23-May-11 07:18 laboneq/controller/recipe_processor.py
+-rw-r--r--  2.0 unx    21249 b- defN 23-May-25 13:25 laboneq/controller/recipe_processor.py
 -rw-r--r--  2.0 unx     1917 b- defN 23-Feb-02 07:13 laboneq/controller/results.py
 -rw-r--r--  2.0 unx     1594 b- defN 23-Feb-13 10:57 laboneq/controller/toolkit_adapter.py
--rw-r--r--  2.0 unx     1178 b- defN 23-May-09 12:30 laboneq/controller/util.py
+-rw-r--r--  2.0 unx     1178 b- defN 23-May-17 00:03 laboneq/controller/util.py
 -rw-r--r--  2.0 unx      281 b- defN 23-Mar-07 07:28 laboneq/controller/versioning.py
 -rw-r--r--  2.0 unx       77 b- defN 23-Feb-02 07:13 laboneq/controller/devices/__init__.py
--rw-r--r--  2.0 unx    15400 b- defN 23-Apr-28 11:39 laboneq/controller/devices/device_collection.py
--rw-r--r--  2.0 unx     1275 b- defN 23-Apr-28 11:39 laboneq/controller/devices/device_factory.py
--rw-r--r--  2.0 unx    23794 b- defN 23-May-11 07:18 laboneq/controller/devices/device_hdawg.py
--rw-r--r--  2.0 unx      491 b- defN 23-Apr-28 11:39 laboneq/controller/devices/device_nonqc.py
--rw-r--r--  2.0 unx     8115 b- defN 23-Apr-28 11:39 laboneq/controller/devices/device_pqsc.py
--rw-r--r--  2.0 unx     4137 b- defN 23-Apr-28 11:39 laboneq/controller/devices/device_setup_dao.py
--rw-r--r--  2.0 unx     4013 b- defN 23-May-11 07:18 laboneq/controller/devices/device_shfppc.py
--rw-r--r--  2.0 unx    40727 b- defN 23-May-11 07:18 laboneq/controller/devices/device_shfqa.py
--rw-r--r--  2.0 unx    20509 b- defN 23-May-11 07:18 laboneq/controller/devices/device_shfsg.py
--rw-r--r--  2.0 unx    28857 b- defN 23-May-11 07:18 laboneq/controller/devices/device_uhfqa.py
--rw-r--r--  2.0 unx    36238 b- defN 23-May-11 07:18 laboneq/controller/devices/device_zi.py
--rw-r--r--  2.0 unx    29590 b- defN 23-Apr-28 11:39 laboneq/controller/devices/zi_emulator.py
--rw-r--r--  2.0 unx    10358 b- defN 23-Apr-28 11:39 laboneq/controller/devices/zi_node_monitor.py
+-rw-r--r--  2.0 unx    15391 b- defN 23-May-25 13:25 laboneq/controller/devices/device_collection.py
+-rw-r--r--  2.0 unx     1275 b- defN 23-May-17 00:03 laboneq/controller/devices/device_factory.py
+-rw-r--r--  2.0 unx    24523 b- defN 23-May-25 07:57 laboneq/controller/devices/device_hdawg.py
+-rw-r--r--  2.0 unx      491 b- defN 23-May-22 14:36 laboneq/controller/devices/device_nonqc.py
+-rw-r--r--  2.0 unx     8115 b- defN 23-May-17 00:03 laboneq/controller/devices/device_pqsc.py
+-rw-r--r--  2.0 unx     4137 b- defN 23-May-25 13:25 laboneq/controller/devices/device_setup_dao.py
+-rw-r--r--  2.0 unx     4344 b- defN 23-May-23 08:56 laboneq/controller/devices/device_shfppc.py
+-rw-r--r--  2.0 unx    42895 b- defN 23-May-23 08:56 laboneq/controller/devices/device_shfqa.py
+-rw-r--r--  2.0 unx    21719 b- defN 23-May-23 08:56 laboneq/controller/devices/device_shfsg.py
+-rw-r--r--  2.0 unx    29618 b- defN 23-May-23 08:56 laboneq/controller/devices/device_uhfqa.py
+-rw-r--r--  2.0 unx    37660 b- defN 23-May-24 09:57 laboneq/controller/devices/device_zi.py
+-rw-r--r--  2.0 unx    29590 b- defN 23-May-17 00:03 laboneq/controller/devices/zi_emulator.py
+-rw-r--r--  2.0 unx    10358 b- defN 23-May-24 09:57 laboneq/controller/devices/zi_node_monitor.py
 -rw-r--r--  2.0 unx       97 b- defN 23-Feb-02 07:13 laboneq/core/__init__.py
--rw-r--r--  2.0 unx     2015 b- defN 23-Apr-28 11:39 laboneq/core/path.py
+-rw-r--r--  2.0 unx     2015 b- defN 23-May-17 00:03 laboneq/core/path.py
 -rw-r--r--  2.0 unx     1338 b- defN 23-Feb-02 07:13 laboneq/core/validators.py
 -rw-r--r--  2.0 unx      126 b- defN 23-Feb-02 07:13 laboneq/core/exceptions/__init__.py
 -rw-r--r--  2.0 unx      123 b- defN 23-Feb-02 07:13 laboneq/core/exceptions/laboneq_exception.py
 -rw-r--r--  2.0 unx       77 b- defN 23-Feb-02 07:13 laboneq/core/serialization/__init__.py
 -rw-r--r--  2.0 unx    19090 b- defN 23-May-09 12:50 laboneq/core/serialization/simple_serialization.py
 -rw-r--r--  2.0 unx      161 b- defN 23-Feb-02 07:13 laboneq/core/types/__init__.py
--rw-r--r--  2.0 unx     5169 b- defN 23-May-10 12:50 laboneq/core/types/compiled_experiment.py
+-rw-r--r--  2.0 unx     5169 b- defN 23-May-17 00:03 laboneq/core/types/compiled_experiment.py
 -rw-r--r--  2.0 unx     1473 b- defN 23-Feb-02 07:13 laboneq/core/types/uid.py
 -rw-r--r--  2.0 unx      660 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/__init__.py
 -rw-r--r--  2.0 unx      934 b- defN 23-Feb-07 16:25 laboneq/core/types/enums/acquisition_type.py
 -rw-r--r--  2.0 unx      213 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/averaging_mode.py
 -rw-r--r--  2.0 unx      188 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/carrier_type.py
 -rw-r--r--  2.0 unx      227 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/dsl_version.py
 -rw-r--r--  2.0 unx      185 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/execution_type.py
--rw-r--r--  2.0 unx      223 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/high_pass_compensation_clearing.py
+-rw-r--r--  2.0 unx      223 b- defN 23-May-23 07:59 laboneq/core/types/enums/high_pass_compensation_clearing.py
 -rw-r--r--  2.0 unx      157 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/io_direction.py
--rw-r--r--  2.0 unx      268 b- defN 23-Apr-28 11:39 laboneq/core/types/enums/io_signal_type.py
+-rw-r--r--  2.0 unx      268 b- defN 23-May-17 00:03 laboneq/core/types/enums/io_signal_type.py
 -rw-r--r--  2.0 unx      316 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/mixer_type.py
 -rw-r--r--  2.0 unx      200 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/modulation_type.py
 -rw-r--r--  2.0 unx      152 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/port_mode.py
 -rw-r--r--  2.0 unx      188 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/reference_clock_source.py
 -rw-r--r--  2.0 unx      198 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/repetition_mode.py
 -rw-r--r--  2.0 unx      170 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/section_alignment.py
 -rw-r--r--  2.0 unx       77 b- defN 23-Feb-02 07:13 laboneq/core/utilities/__init__.py
--rw-r--r--  2.0 unx     8039 b- defN 23-Apr-06 14:15 laboneq/core/utilities/pulse_sampler.py
--rw-r--r--  2.0 unx     9808 b- defN 23-Apr-06 14:15 laboneq/core/utilities/replace_pulse.py
+-rw-r--r--  2.0 unx     1813 b- defN 23-May-25 07:57 laboneq/core/utilities/compressed_formatter.py
+-rw-r--r--  2.0 unx     8039 b- defN 23-May-17 00:03 laboneq/core/utilities/pulse_sampler.py
+-rw-r--r--  2.0 unx     9808 b- defN 23-May-17 00:03 laboneq/core/utilities/replace_pulse.py
 -rw-r--r--  2.0 unx      178 b- defN 23-May-03 09:34 laboneq/dsl/__init__.py
--rw-r--r--  2.0 unx     2929 b- defN 23-Apr-28 11:39 laboneq/dsl/laboneq_facade.py
+-rw-r--r--  2.0 unx     2929 b- defN 23-May-25 13:25 laboneq/dsl/laboneq_facade.py
 -rw-r--r--  2.0 unx     2552 b- defN 23-Feb-15 13:56 laboneq/dsl/parameter.py
--rw-r--r--  2.0 unx    25670 b- defN 23-Apr-28 11:39 laboneq/dsl/session.py
+-rw-r--r--  2.0 unx    25670 b- defN 23-May-24 09:57 laboneq/dsl/session.py
 -rw-r--r--  2.0 unx     2296 b- defN 23-Feb-02 07:13 laboneq/dsl/utils.py
--rw-r--r--  2.0 unx      529 b- defN 23-Apr-28 11:39 laboneq/dsl/calibration/__init__.py
--rw-r--r--  2.0 unx     1017 b- defN 23-May-11 07:18 laboneq/dsl/calibration/amplifier_pump.py
+-rw-r--r--  2.0 unx      529 b- defN 23-May-17 00:03 laboneq/dsl/calibration/__init__.py
+-rw-r--r--  2.0 unx      946 b- defN 23-May-23 08:56 laboneq/dsl/calibration/amplifier_pump.py
 -rw-r--r--  2.0 unx      545 b- defN 23-Feb-02 07:13 laboneq/dsl/calibration/calibratable.py
--rw-r--r--  2.0 unx     2313 b- defN 23-May-04 12:22 laboneq/dsl/calibration/calibration.py
+-rw-r--r--  2.0 unx     2313 b- defN 23-May-17 00:03 laboneq/dsl/calibration/calibration.py
 -rw-r--r--  2.0 unx      111 b- defN 23-Feb-02 07:13 laboneq/dsl/calibration/calibration_item.py
 -rw-r--r--  2.0 unx      992 b- defN 23-Feb-27 16:33 laboneq/dsl/calibration/mixer_calibration.py
 -rw-r--r--  2.0 unx     3403 b- defN 23-Feb-02 07:13 laboneq/dsl/calibration/observable.py
--rw-r--r--  2.0 unx     1716 b- defN 23-May-11 07:18 laboneq/dsl/calibration/oscillator.py
--rw-r--r--  2.0 unx     2650 b- defN 23-Feb-27 16:33 laboneq/dsl/calibration/precompensation.py
--rw-r--r--  2.0 unx     5607 b- defN 23-May-11 07:18 laboneq/dsl/calibration/signal_calibration.py
+-rw-r--r--  2.0 unx     2134 b- defN 23-May-25 07:57 laboneq/dsl/calibration/oscillator.py
+-rw-r--r--  2.0 unx     2650 b- defN 23-May-23 07:59 laboneq/dsl/calibration/precompensation.py
+-rw-r--r--  2.0 unx     5614 b- defN 23-May-23 08:56 laboneq/dsl/calibration/signal_calibration.py
 -rw-r--r--  2.0 unx      553 b- defN 23-Feb-02 07:13 laboneq/dsl/calibration/units.py
 -rw-r--r--  2.0 unx      363 b- defN 23-Feb-02 07:13 laboneq/dsl/device/__init__.py
--rw-r--r--  2.0 unx    45826 b- defN 23-Apr-28 11:39 laboneq/dsl/device/_device_setup_generator.py
+-rw-r--r--  2.0 unx    45826 b- defN 23-May-17 00:03 laboneq/dsl/device/_device_setup_generator.py
 -rw-r--r--  2.0 unx      601 b- defN 23-Feb-02 07:13 laboneq/dsl/device/connection.py
--rw-r--r--  2.0 unx    13663 b- defN 23-May-09 12:50 laboneq/dsl/device/device_setup.py
+-rw-r--r--  2.0 unx    13663 b- defN 23-May-17 00:03 laboneq/dsl/device/device_setup.py
 -rw-r--r--  2.0 unx     2551 b- defN 23-Apr-06 14:15 laboneq/dsl/device/device_setup_helper.py
--rw-r--r--  2.0 unx     1362 b- defN 23-Apr-28 11:39 laboneq/dsl/device/instrument.py
+-rw-r--r--  2.0 unx     1362 b- defN 23-May-17 00:03 laboneq/dsl/device/instrument.py
 -rw-r--r--  2.0 unx     1893 b- defN 23-Feb-02 07:13 laboneq/dsl/device/logical_signal_group.py
 -rw-r--r--  2.0 unx     1729 b- defN 23-Feb-02 07:13 laboneq/dsl/device/physical_channel_group.py
 -rw-r--r--  2.0 unx      538 b- defN 23-Feb-02 07:13 laboneq/dsl/device/ports.py
--rw-r--r--  2.0 unx     4557 b- defN 23-May-10 12:50 laboneq/dsl/device/qubits.py
--rw-r--r--  2.0 unx     3104 b- defN 23-May-11 13:51 laboneq/dsl/device/quops.py
+-rw-r--r--  2.0 unx     3422 b- defN 23-May-25 12:48 laboneq/dsl/device/quantum_operations.py
+-rw-r--r--  2.0 unx     4557 b- defN 23-May-25 13:25 laboneq/dsl/device/qubits.py
 -rw-r--r--  2.0 unx      215 b- defN 23-Feb-02 07:13 laboneq/dsl/device/server.py
--rw-r--r--  2.0 unx      328 b- defN 23-Apr-28 11:39 laboneq/dsl/device/instruments/__init__.py
+-rw-r--r--  2.0 unx      328 b- defN 23-May-17 00:03 laboneq/dsl/device/instruments/__init__.py
 -rw-r--r--  2.0 unx     1778 b- defN 23-Feb-02 07:13 laboneq/dsl/device/instruments/hdawg.py
 -rw-r--r--  2.0 unx      466 b- defN 23-Feb-13 10:57 laboneq/dsl/device/instruments/nonqc.py
 -rw-r--r--  2.0 unx      948 b- defN 23-Feb-02 07:13 laboneq/dsl/device/instruments/pqsc.py
--rw-r--r--  2.0 unx      927 b- defN 23-Apr-28 11:39 laboneq/dsl/device/instruments/shfppc.py
+-rw-r--r--  2.0 unx      927 b- defN 23-May-17 00:03 laboneq/dsl/device/instruments/shfppc.py
 -rw-r--r--  2.0 unx     2248 b- defN 23-Feb-06 17:42 laboneq/dsl/device/instruments/shfqa.py
 -rw-r--r--  2.0 unx     1659 b- defN 23-Feb-06 17:42 laboneq/dsl/device/instruments/shfsg.py
 -rw-r--r--  2.0 unx     2312 b- defN 23-Feb-16 12:45 laboneq/dsl/device/instruments/uhfqa.py
 -rw-r--r--  2.0 unx      888 b- defN 23-Feb-13 10:57 laboneq/dsl/device/instruments/zi_standard_instrument.py
 -rw-r--r--  2.0 unx      187 b- defN 23-Feb-02 07:13 laboneq/dsl/device/io_units/__init__.py
--rw-r--r--  2.0 unx    12750 b- defN 23-May-03 09:34 laboneq/dsl/device/io_units/logical_signal.py
--rw-r--r--  2.0 unx     3811 b- defN 23-May-03 09:34 laboneq/dsl/device/io_units/physical_channel.py
+-rw-r--r--  2.0 unx    12750 b- defN 23-May-22 15:14 laboneq/dsl/device/io_units/logical_signal.py
+-rw-r--r--  2.0 unx     3828 b- defN 23-May-23 08:56 laboneq/dsl/device/io_units/physical_channel.py
 -rw-r--r--  2.0 unx      114 b- defN 23-Feb-02 07:13 laboneq/dsl/device/servers/__init__.py
 -rw-r--r--  2.0 unx      704 b- defN 23-Feb-02 07:13 laboneq/dsl/device/servers/data_server.py
 -rw-r--r--  2.0 unx      718 b- defN 23-Feb-02 07:13 laboneq/dsl/enums/__init__.py
 -rw-r--r--  2.0 unx      508 b- defN 23-Feb-02 07:13 laboneq/dsl/experiment/__init__.py
--rw-r--r--  2.0 unx      972 b- defN 23-Feb-02 07:13 laboneq/dsl/experiment/acquire.py
+-rw-r--r--  2.0 unx      972 b- defN 23-May-22 15:14 laboneq/dsl/experiment/acquire.py
 -rw-r--r--  2.0 unx      814 b- defN 23-Feb-02 07:13 laboneq/dsl/experiment/call.py
 -rw-r--r--  2.0 unx      780 b- defN 23-Feb-02 07:13 laboneq/dsl/experiment/delay.py
--rw-r--r--  2.0 unx    39779 b- defN 23-May-11 07:18 laboneq/dsl/experiment/experiment.py
--rw-r--r--  2.0 unx     8216 b- defN 23-Apr-28 11:39 laboneq/dsl/experiment/experiment_signal.py
+-rw-r--r--  2.0 unx    39761 b- defN 23-May-23 08:56 laboneq/dsl/experiment/experiment.py
+-rw-r--r--  2.0 unx     8216 b- defN 23-May-22 15:14 laboneq/dsl/experiment/experiment_signal.py
 -rw-r--r--  2.0 unx      401 b- defN 23-Feb-02 07:13 laboneq/dsl/experiment/operation.py
 -rw-r--r--  2.0 unx     1647 b- defN 23-Feb-28 13:10 laboneq/dsl/experiment/play_pulse.py
--rw-r--r--  2.0 unx     3953 b- defN 23-May-10 12:50 laboneq/dsl/experiment/pulse.py
--rw-r--r--  2.0 unx     8194 b- defN 23-May-10 12:50 laboneq/dsl/experiment/pulse_library.py
+-rw-r--r--  2.0 unx     3953 b- defN 23-May-17 00:03 laboneq/dsl/experiment/pulse.py
+-rw-r--r--  2.0 unx     8194 b- defN 23-May-17 00:03 laboneq/dsl/experiment/pulse_library.py
 -rw-r--r--  2.0 unx      890 b- defN 23-Feb-16 12:45 laboneq/dsl/experiment/reserve.py
--rw-r--r--  2.0 unx    11431 b- defN 23-Apr-28 11:39 laboneq/dsl/experiment/section.py
+-rw-r--r--  2.0 unx    11431 b- defN 23-May-22 15:14 laboneq/dsl/experiment/section.py
 -rw-r--r--  2.0 unx      640 b- defN 23-Feb-02 07:13 laboneq/dsl/experiment/set.py
--rw-r--r--  2.0 unx      323 b- defN 23-Apr-28 11:39 laboneq/dsl/experiment/utils.py
+-rw-r--r--  2.0 unx      323 b- defN 23-May-22 15:14 laboneq/dsl/experiment/utils.py
 -rw-r--r--  2.0 unx      151 b- defN 23-Feb-14 15:16 laboneq/dsl/result/__init__.py
 -rw-r--r--  2.0 unx     1766 b- defN 23-Feb-02 07:13 laboneq/dsl/result/acquired_result.py
 -rw-r--r--  2.0 unx     7240 b- defN 23-Feb-02 07:13 laboneq/dsl/result/results.py
 -rw-r--r--  2.0 unx      113 b- defN 23-Feb-02 07:13 laboneq/dsl/serialization/__init__.py
--rw-r--r--  2.0 unx     5379 b- defN 23-May-11 13:51 laboneq/dsl/serialization/serializer.py
+-rw-r--r--  2.0 unx     5392 b- defN 23-May-25 12:48 laboneq/dsl/serialization/serializer.py
 -rw-r--r--  2.0 unx       77 b- defN 23-Feb-02 07:13 laboneq/executor/__init__.py
 -rw-r--r--  2.0 unx     3819 b- defN 23-Feb-16 12:45 laboneq/executor/execution_from_experiment.py
 -rw-r--r--  2.0 unx     8152 b- defN 23-Apr-06 14:15 laboneq/executor/executor.py
 -rw-r--r--  2.0 unx      145 b- defN 23-Feb-14 15:16 laboneq/openqasm3/__init__.py
--rw-r--r--  2.0 unx     8730 b- defN 23-May-11 13:51 laboneq/openqasm3/expression.py
--rw-r--r--  2.0 unx     1604 b- defN 23-May-11 13:51 laboneq/openqasm3/gate_store.py
--rw-r--r--  2.0 unx     2060 b- defN 23-May-11 13:21 laboneq/openqasm3/namespace.py
--rw-r--r--  2.0 unx    13702 b- defN 23-May-11 13:51 laboneq/openqasm3/openqasm3_importer.py
--rw-r--r--  2.0 unx     1732 b- defN 23-Apr-28 11:39 laboneq/openqasm3/openqasm_error.py
--rw-r--r--  2.0 unx     4850 b- defN 23-May-04 12:22 laboneq/openqasm3/reset_gate_factory.py
--rw-r--r--  2.0 unx     1492 b- defN 23-May-11 13:21 laboneq/openqasm3/signal_store.py
+-rw-r--r--  2.0 unx     8903 b- defN 23-May-23 08:56 laboneq/openqasm3/expression.py
+-rw-r--r--  2.0 unx     1671 b- defN 23-May-22 15:14 laboneq/openqasm3/gate_store.py
+-rw-r--r--  2.0 unx     2593 b- defN 23-May-23 08:56 laboneq/openqasm3/namespace.py
+-rw-r--r--  2.0 unx    15459 b- defN 23-May-23 14:08 laboneq/openqasm3/openqasm3_importer.py
+-rw-r--r--  2.0 unx     1732 b- defN 23-May-17 00:03 laboneq/openqasm3/openqasm_error.py
+-rw-r--r--  2.0 unx     4850 b- defN 23-May-22 15:14 laboneq/openqasm3/reset_gate_factory.py
+-rw-r--r--  2.0 unx     1517 b- defN 23-May-23 08:56 laboneq/openqasm3/signal_store.py
 -rw-r--r--  2.0 unx      127 b- defN 23-Feb-02 07:13 laboneq/pulse_sheet_viewer/__init__.py
 -rw-r--r--  2.0 unx     2059 b- defN 23-Feb-16 12:45 laboneq/pulse_sheet_viewer/event_graph_viewer.py
 -rw-r--r--  2.0 unx     2692 b- defN 23-Feb-02 14:48 laboneq/pulse_sheet_viewer/interactive_psv.py
 -rw-r--r--  2.0 unx     3288 b- defN 23-Feb-02 14:48 laboneq/pulse_sheet_viewer/pulse_sheet_viewer.py
--rw-rw-rw-  2.0 unx  1443040 b- defN 23-Apr-06 14:15 laboneq/pulse_sheet_viewer/pulse_sheet_viewer_template.html
+-rw-rw-rw-  2.0 unx  1443040 b- defN 23-May-17 00:03 laboneq/pulse_sheet_viewer/pulse_sheet_viewer_template.html
 -rw-r--r--  2.0 unx      152 b- defN 23-Feb-14 15:16 laboneq/simulator/__init__.py
 -rw-r--r--  2.0 unx     5904 b- defN 23-Feb-02 14:48 laboneq/simulator/output_simulator.py
--rw-r--r--  2.0 unx    40863 b- defN 23-May-10 12:50 laboneq/simulator/seqc_parser.py
--rw-r--r--  2.0 unx    12500 b- defN 23-May-10 12:50 laboneq/simulator/wave_scroller.py
--rw-rw-rw-  2.0 unx       22 b- defN 23-May-11 13:51 laboneq-2.6.0.dist-info/AUTHORS
--rw-rw-rw-  2.0 unx    11358 b- defN 23-May-11 13:51 laboneq-2.6.0.dist-info/LICENSE
--rw-r--r--  2.0 unx     3188 b- defN 23-May-11 13:51 laboneq-2.6.0.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-May-11 13:51 laboneq-2.6.0.dist-info/WHEEL
--rw-r--r--  2.0 unx        8 b- defN 23-May-11 13:51 laboneq-2.6.0.dist-info/top_level.txt
--rw-rw-r--  2.0 unx    23965 b- defN 23-May-11 13:51 laboneq-2.6.0.dist-info/RECORD
-246 files, 2852565 bytes uncompressed, 893164 bytes compressed:  68.7%
+-rw-r--r--  2.0 unx    40863 b- defN 23-May-25 13:25 laboneq/simulator/seqc_parser.py
+-rw-r--r--  2.0 unx    12500 b- defN 23-May-24 14:34 laboneq/simulator/wave_scroller.py
+-rw-rw-rw-  2.0 unx       22 b- defN 23-May-25 13:27 laboneq-2.7.0.dist-info/AUTHORS
+-rw-rw-rw-  2.0 unx    11358 b- defN 23-May-25 13:27 laboneq-2.7.0.dist-info/LICENSE
+-rw-r--r--  2.0 unx     3188 b- defN 23-May-25 13:27 laboneq-2.7.0.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-May-25 13:27 laboneq-2.7.0.dist-info/WHEEL
+-rw-r--r--  2.0 unx        8 b- defN 23-May-25 13:27 laboneq-2.7.0.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx    24183 b- defN 23-May-25 13:27 laboneq-2.7.0.dist-info/RECORD
+248 files, 2880660 bytes uncompressed, 900375 bytes compressed:  68.8%
```

## zipnote {}

```diff
@@ -306,14 +306,17 @@
 
 Filename: laboneq/contrib/example_helpers/plotting/plot_helpers.py
 Comment: 
 
 Filename: laboneq/controller/__init__.py
 Comment: 
 
+Filename: laboneq/controller/attribute_value_tracker.py
+Comment: 
+
 Filename: laboneq/controller/cache.py
 Comment: 
 
 Filename: laboneq/controller/communication.py
 Comment: 
 
 Filename: laboneq/controller/controller.py
@@ -462,14 +465,17 @@
 
 Filename: laboneq/core/types/enums/section_alignment.py
 Comment: 
 
 Filename: laboneq/core/utilities/__init__.py
 Comment: 
 
+Filename: laboneq/core/utilities/compressed_formatter.py
+Comment: 
+
 Filename: laboneq/core/utilities/pulse_sampler.py
 Comment: 
 
 Filename: laboneq/core/utilities/replace_pulse.py
 Comment: 
 
 Filename: laboneq/dsl/__init__.py
@@ -543,18 +549,18 @@
 
 Filename: laboneq/dsl/device/physical_channel_group.py
 Comment: 
 
 Filename: laboneq/dsl/device/ports.py
 Comment: 
 
-Filename: laboneq/dsl/device/qubits.py
+Filename: laboneq/dsl/device/quantum_operations.py
 Comment: 
 
-Filename: laboneq/dsl/device/quops.py
+Filename: laboneq/dsl/device/qubits.py
 Comment: 
 
 Filename: laboneq/dsl/device/server.py
 Comment: 
 
 Filename: laboneq/dsl/device/instruments/__init__.py
 Comment: 
@@ -714,26 +720,26 @@
 
 Filename: laboneq/simulator/seqc_parser.py
 Comment: 
 
 Filename: laboneq/simulator/wave_scroller.py
 Comment: 
 
-Filename: laboneq-2.6.0.dist-info/AUTHORS
+Filename: laboneq-2.7.0.dist-info/AUTHORS
 Comment: 
 
-Filename: laboneq-2.6.0.dist-info/LICENSE
+Filename: laboneq-2.7.0.dist-info/LICENSE
 Comment: 
 
-Filename: laboneq-2.6.0.dist-info/METADATA
+Filename: laboneq-2.7.0.dist-info/METADATA
 Comment: 
 
-Filename: laboneq-2.6.0.dist-info/WHEEL
+Filename: laboneq-2.7.0.dist-info/WHEEL
 Comment: 
 
-Filename: laboneq-2.6.0.dist-info/top_level.txt
+Filename: laboneq-2.7.0.dist-info/top_level.txt
 Comment: 
 
-Filename: laboneq-2.6.0.dist-info/RECORD
+Filename: laboneq-2.7.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## laboneq/VERSION.txt

```diff
@@ -1 +1 @@
-2.6.0
+2.7.0
```

## laboneq/__init__.py

```diff
@@ -2,13 +2,10 @@
 # SPDX-License-Identifier: Apache-2.0
 
 # pylint: disable=wrong-import-order
 
 
 """Main functionality of the LabOne Q Software."""
 
-import pkgutil
-
 from laboneq._version import get_version
 
-__path__ = pkgutil.extend_path(__path__, __name__)
 __version__ = get_version()
```

## laboneq/simple.py

```diff
@@ -21,16 +21,16 @@
     Oscillator,
     Precompensation,
     SignalCalibration,
     units,
 )
 from laboneq.dsl.device import DeviceSetup
 from laboneq.dsl.device.device_setup_helper import DeviceSetupHelper
+from laboneq.dsl.device.quantum_operations import QuantumOperation
 from laboneq.dsl.device.qubits import QuantumElement, Qubit
-from laboneq.dsl.device.quops import QuantumOperation
 from laboneq.dsl.enums import (
     AcquisitionType,
     AveragingMode,
     CarrierType,
     ExecutionType,
     HighPassCompensationClearing,
     ModulationType,
```

## laboneq/compiler/code_generator/code_generator.py

```diff
@@ -42,14 +42,15 @@
 from laboneq.compiler.code_generator.seq_c_generator import (
     SeqCGenerator,
     merge_generators,
 )
 from laboneq.compiler.code_generator.seqc_tracker import SeqCTracker
 from laboneq.compiler.code_generator.signatures import (
     PlaybackSignature,
+    SamplesSignature,
     WaveformSignature,
 )
 from laboneq.compiler.code_generator.utils import normalize_phase
 from laboneq.compiler.code_generator.wave_compressor import (
     PlayHold,
     PlaySamples,
     WaveCompressor,
@@ -63,15 +64,15 @@
 )
 from laboneq.compiler.common.awg_signal_type import AWGSignalType
 from laboneq.compiler.common.compiler_settings import (
     CompilerSettings,
     round_min_playwave_hint,
 )
 from laboneq.compiler.common.device_type import DeviceType
-from laboneq.compiler.common.event_type import EventType
+from laboneq.compiler.common.event_type import EventList, EventType
 from laboneq.compiler.common.pulse_parameters import decode_pulse_parameters
 from laboneq.compiler.common.signal_obj import SignalObj
 from laboneq.compiler.common.trigger_mode import TriggerMode
 from laboneq.compiler.experiment_access import ExperimentDAO
 from laboneq.compiler.experiment_access.pulse_def import PulseDef
 from laboneq.compiler.experiment_access.section_info import SectionInfo
 from laboneq.core.exceptions import LabOneQException
@@ -261,15 +262,15 @@
             if isinstance(settings, CompilerSettings):
                 self._settings = settings
             else:
                 self._settings = CompilerSettings(**settings)
         else:
             self._settings = CompilerSettings()
 
-        self._signals: Dict[str, SignalObj] = {}
+        self._signals: dict[str, SignalObj] = {}
         self._code = {}
         self._src = []
         self._wave_indices_all = []
         self._waves = []
         self._command_tables: List[Dict[str, Any]] = []
         self._pulse_map: Dict[str, PulseMapEntry] = {}
         self._sampled_signatures: Dict[str, Dict[WaveformSignature, Dict]] = {}
@@ -489,15 +490,15 @@
             assert all(np.all(group[0][1] == g[1]) for g in group[1:])
 
         if _logger.getEffectiveLevel() == logging.DEBUG:
             _logger.debug("Sampled signatures: %s", self._sampled_signatures)
 
             _logger.debug(self._waves)
 
-    def gen_acquire_map(self, events: List[Any], sections: ExperimentDAO):
+    def gen_acquire_map(self, events: EventList, sections: ExperimentDAO):
         # todo (PW): this can EASILY be factored out into a separate file
         loop_events = [
             e
             for e in events
             if e["event_type"] == "LOOP_ITERATION_END" and not e.get("shadow")
         ]
         averaging_loop_info: SectionInfo = None
@@ -693,14 +694,15 @@
             [(s, EngNumber(d)) for s, d in all_relevant_delays.items()],
         )
 
         return global_sampling_rate, global_delay
 
     def _emit_new_awg_events(self, old_event, new_events):
         new_awg_events = []
+        pulse_name_mapping = {}
         time = old_event.start
         for new_event in new_events:
             if isinstance(new_event, PlayHold):
                 new_awg_events.append(
                     AWGEvent(
                         type=AWGEventType.PLAY_HOLD,
                         start=time,
@@ -708,133 +710,148 @@
                     )
                 )
                 time += new_event.num_samples
             if isinstance(new_event, PlaySamples):
                 new_params = copy.deepcopy(old_event.params)
                 new_length = len(next(iter(new_event.samples.values())))
 
-                new_params["playback_signature"].waveform.length = new_length
+                for pulse in new_params["playback_signature"].waveform.pulses:
+                    pulse_name_mapping[pulse.pulse] = (
+                        pulse.pulse + f"_compr_{new_event.label}"
+                    )
 
-                assert len(new_params["playback_signature"].waveform.pulses) == 1
-                new_params["playback_signature"].waveform.pulses[0].length = new_length
-                new_params["playback_signature"].waveform.pulses[
-                    0
-                ].pulse += f"_compr_{new_event.label}"
+                new_params["playback_signature"].waveform.length = new_length
+                new_params["playback_signature"].waveform.pulses = None
+                new_params["playback_signature"].waveform.samples = SamplesSignature(
+                    "compr", new_event.samples
+                )
 
                 new_awg_events.append(
                     AWGEvent(
                         type=AWGEventType.PLAY_WAVE,
                         start=time,
                         end=time + new_length,
                         params=new_params,
                     )
                 )
 
                 time += new_length
-        return new_awg_events
+        return new_awg_events, pulse_name_mapping
 
     def _compress_waves(
-        self, sampled_events, sampled_signatures, signal_obj, pulse_defs
+        self, sampled_events, sampled_signatures, signal_id, min_play_wave, pulse_defs
     ):
         compressed_waveform_signatures = set()
         for event_group in sampled_events.sequence.values():
             event_replacement = {}
             for i, event in enumerate(event_group):
                 if event.type == AWGEventType.PLAY_WAVE:
                     wave_form = event.params["playback_signature"].waveform
-                    if wave_form.pulses[0].pulse not in pulse_defs:
-                        assert (
-                            wave_form.pulses[0].pulse is None
-                            or wave_form.pulses[0].pulse == "dummy_precomp_reset"
-                        )
-                        continue
-                    if not pulse_defs[wave_form.pulses[0].pulse].can_compress:
+                    pulses_not_in_pulsedef = [
+                        pulse.pulse
+                        for pulse in wave_form.pulses
+                        if pulse.pulse not in pulse_defs
+                    ]
+                    assert all(
+                        pulse is None or pulse == "dummy_precomp_reset"
+                        for pulse in pulses_not_in_pulsedef
+                    )
+                    if len(pulses_not_in_pulsedef) > 0:
                         continue
-                    if len(wave_form.pulses) > 1:
-                        _logger.info(
-                            "Requested to compress wave which features more than one pulse. Skipping compression."
-                        )
+
+                    if any(
+                        not pulse_defs[pulse.pulse].can_compress
+                        for pulse in wave_form.pulses
+                    ):
                         continue
                     sampled_signature = sampled_signatures[wave_form]
                     sample_dict = {
                         k: sampled_signature[k]
                         for k in (
                             "samples_i",
                             "samples_q",
                             "samples_marker1",
                             "samples_marker2",
                         )
                         if k in sampled_signature
                     }
                     new_events = self._wave_compressor.compress_wave(
-                        sample_dict, signal_obj.device_type.min_play_wave
+                        sample_dict, min_play_wave
                     )
+                    pulse_names = [pulse.pulse for pulse in wave_form.pulses]
                     if new_events is None:
                         _logger.info(
-                            "Requested to compress pulse %s which has either no, or too short, constant sections. Skipping compression",
-                            wave_form.pulses[0].pulse,
+                            "Requested to compress pulse(s) %s which has(have) either no, or too short, constant sections. Skipping compression",
+                            ",".join(pulse_names),
                         )
                         continue
                     event_replacement[i] = new_events
-                    _logger.info(
-                        "Compressing pulse %s using %d PlayWave and %d PlayHold events",
-                        wave_form.pulses[0].pulse,
+                    _logger.debug(
+                        "Compressing pulse(s) %s using %d PlayWave and %d PlayHold events",
+                        ",".join(pulse_names),
                         sum(
                             1 for event in new_events if isinstance(event, PlaySamples)
                         ),
                         sum(1 for event in new_events if isinstance(event, PlayHold)),
                     )
             for idx, new_events in event_replacement.items():
-                new_awg_events = self._emit_new_awg_events(event_group[idx], new_events)
+                new_awg_events, pulse_name_mapping = self._emit_new_awg_events(
+                    event_group[idx], new_events
+                )
 
                 old_event = event_group[idx]
                 event_group[idx : idx + 1] = new_awg_events
 
                 old_waveform = old_event.params["playback_signature"].waveform
-                for new_event, new_awg_event in zip(new_events, new_awg_events):
+                for new_awg_event in new_awg_events:
                     if new_awg_event.type == AWGEventType.PLAY_WAVE:
                         new_waveform = new_awg_event.params[
                             "playback_signature"
                         ].waveform
-                        new_length = len(next(iter(new_event.samples.values())))
+                        new_length = len(
+                            next(iter(new_waveform.samples.samples_map.values()))
+                        )
 
-                        old_sampled_signature = self._sampled_signatures[signal_obj.id][
+                        old_sampled_signature = self._sampled_signatures[signal_id][
                             old_waveform
                         ]
-                        compressed_waveform_signatures.add(old_waveform)
                         new_sampled_signature = copy.deepcopy(old_sampled_signature)
 
+                        # save old waveform such that we can clean the sampled signatures later on
+                        compressed_waveform_signatures.add(old_waveform)
+
                         new_sampled_signature = (
-                            new_sampled_signature | new_event.samples
+                            new_sampled_signature | new_waveform.samples.samples_map
                         )
                         new_signature_pulse_map = new_sampled_signature[
                             "signature_pulse_map"
                         ]
 
-                        old_pulse_name = old_waveform.pulses[0].pulse
-                        new_pulse_name = new_waveform.pulses[0].pulse
-
-                        new_signature_pulse_map[
-                            new_pulse_name
-                        ] = new_signature_pulse_map.pop(old_pulse_name)
-                        new_signature_pulse_map[
-                            new_pulse_name
-                        ].length_samples = new_length
-
-                        new_signature_pulse_map[new_pulse_name].instances[
-                            0
-                        ].length = new_length
+                        # update 3 things in samples signatures
+                        #   - name of pulses that have been compressed
+                        #   - length_samples entry in signature pulse map
+                        #   - length entry in the instances stored in the signature pulse map
+
+                        for old_name, new_name in pulse_name_mapping.items():
+                            new_signature_pulse_map[
+                                new_name
+                            ] = new_signature_pulse_map.pop(old_name)
+
+                        for map in new_signature_pulse_map.values():
+                            map.length_samples = new_length
+                            for signature in map.instances:
+                                signature.length = new_length
 
-                        self._sampled_signatures[signal_obj.id][
+                        self._sampled_signatures[signal_id][
                             new_waveform
                         ] = new_sampled_signature
 
         # evict waveforms that have been compressed, and thus replaced with one or more, shorter, waves
         for waveform_signature in compressed_waveform_signatures:
-            self._sampled_signatures[signal_obj.id].pop(waveform_signature)
+            self._sampled_signatures[signal_id].pop(waveform_signature)
 
     def _gen_seq_c_per_awg(
         self,
         awg: AWGInfo,
         events: List[Any],
         pulse_defs: Dict[str, PulseDef],
     ):
@@ -1016,18 +1033,25 @@
                 multi_iq_signal=True,
                 mixer_type=mixer_type,
             )
 
             self._sampled_signatures[virtual_signal_id] = sampled_signatures
             sampled_events.merge(interval_events)
 
+            min_play_waves = [
+                signal.device_type.min_play_wave for signal in awg.signals
+            ]
+            assert all(
+                min_play_wave == min_play_waves[0] for min_play_wave in min_play_waves
+            )
             self._compress_waves(
                 sampled_events=sampled_events,
                 sampled_signatures=sampled_signatures,
-                signal_obj=signal_obj,
+                signal_id=virtual_signal_id,
+                min_play_wave=min_play_waves[0],
                 pulse_defs=pulse_defs,
             )
 
             if virtual_signal_id in self._sampled_signatures:
                 for sig, sampled in self._sampled_signatures[virtual_signal_id].items():
                     if not sampled:
                         continue
@@ -1077,15 +1101,16 @@
 
                 self._sampled_signatures[signal_obj.id] = sampled_signatures
                 sampled_events.merge(interval_events)
 
                 self._compress_waves(
                     sampled_events=sampled_events,
                     sampled_signatures=sampled_signatures,
-                    signal_obj=signal_obj,
+                    signal_id=signal_obj.id,
+                    min_play_wave=signal_obj.device_type.min_play_wave,
                     pulse_defs=pulse_defs,
                 )
 
                 if signal_obj.id in self._sampled_signatures:
                     signature_infos = []
                     for sig, sampled in self._sampled_signatures[signal_obj.id].items():
                         has_marker1 = False
@@ -1136,18 +1161,23 @@
                 device_type=signal_a.device_type,
                 mixer_type=signal_a.mixer_type,
             )
 
             self._sampled_signatures[virtual_signal_id] = sampled_signatures
             sampled_events.merge(interval_events)
 
+            assert (
+                signal_a.device_type.min_play_wave == signal_b.device_type.min_play_wave
+            )
+
             self._compress_waves(
                 sampled_events=sampled_events,
                 sampled_signatures=sampled_signatures,
-                signal_obj=signal_obj,
+                signal_id=virtual_signal_id,
+                min_play_wave=signal_a.device_type.min_play_wave,
                 pulse_defs=pulse_defs,
             )
 
             if virtual_signal_id in self._sampled_signatures:
                 for sig, sampled in self._sampled_signatures[virtual_signal_id].items():
                     if not sampled:
                         continue
```

## laboneq/compiler/code_generator/sampled_event_handler.py

```diff
@@ -178,15 +178,16 @@
             self.awg.signal_type.value
             if self.device_type.supports_binary_waves
             else "csv"
             # Include CSV waves into the index to keep track of waves-AWG mapping
         )
         sig_string = signature.waveform.signature_string()
         if (
-            all(p.pulse is None for p in signature.waveform.pulses)
+            not signature.waveform.samples
+            and all(p.pulse is None for p in signature.waveform.pulses)
             and self.use_command_table
         ):
             # all-zero pulse is played via play-zero command table entry
             wave_index = None
         else:
             wave_index = self.wave_indices.lookup_index_by_wave_id(sig_string)
             if wave_index is None:
```

## laboneq/compiler/code_generator/signatures.py

```diff
@@ -2,16 +2,16 @@
 # SPDX-License-Identifier: Apache-2.0
 
 from __future__ import annotations
 
 import hashlib
 import math
 from copy import deepcopy
-from dataclasses import dataclass
-from typing import Any, FrozenSet, Optional, Tuple
+from dataclasses import dataclass, field
+from typing import Any, Dict, FrozenSet, Optional, Tuple
 
 import numpy as np
 from orjson import orjson
 
 from laboneq.compiler.code_generator.seq_c_generator import string_sanitize
 from laboneq.compiler.code_generator.utils import normalize_phase
 
@@ -32,53 +32,105 @@
     baseband_phase: Optional[float]  #: phase offsets from `set_oscillator_phase`
     channel: Optional[int]  #: the channel of the pulse (for HDAWG)
     sub_channel: Optional[int]  #: the sub-channel of the pulse (for SHFQA)
     pulse_parameters: FrozenSet[Tuple[str, str]]  #: additional user pulse parameters
     markers: Any  #: markers played during this pulse
 
 
+@dataclass(frozen=True)
+class SamplesSignature:
+    """A collection of samples. Defines a WaveformSignature after compression. See also docstring of WaveformSignature"""
+
+    label: str
+    samples_map: Dict[str, np.ndarray]
+
+    def __hash__(self):
+        samples_tup = tuple(
+            str(sample) for sample in self.samples_map.values()
+        ) + tuple(self.label)
+        return hash(samples_tup)
+
+    def __eq__(self, other: SamplesSignature):
+        return (
+            self.label == other.label
+            and self.samples_map.keys() == other.samples_map.keys()
+            and all(
+                np.array_equal(self.samples_map[key], other.samples_map[key])
+                for key in self.samples_map
+            )
+        )
+
+
 @dataclass(unsafe_hash=True)
 class WaveformSignature:
     """Signature of a waveform as stored in waveform memory.
 
     The underlying promise is that two waveforms with the same signature are
     guaranteed to resolve to the same samples, so we need only store one of them and
-    can use them interchangeably."""
+    can use them interchangeably.
+
+    Alternatively, after compression it makes no sense to associate a WaveformSignature to
+    PulseSignatures anymore, since compression can cause a single pulse to be replaced with
+    any number of PlayWave and PlayHold statements. In this case, a WaveformSignature is best
+    understood as a collection of samples, with the implied promise that equal samples are only
+    uploaded to the device once.
+    """
 
     length: int
-    pulses: Tuple[PulseSignature, ...]
+    pulses: Optional[Tuple[PulseSignature, ...]]
+    samples: Optional[SamplesSignature] = field(default=None)
 
     def signature_string(self):
         retval = "p_" + str(self.length).zfill(4)
-        for pulse_entry in self.pulses:
-            retval += "_"
-            retval += pulse_entry.pulse or ""
-            for key, separator, scale, fill in (
-                ("start", "_", 1, 2),
-                ("amplitude", "_a", 1e9, 10),
-                ("length", "_l", 1, 3),
-                ("baseband_phase", "_bb", 1, 7),
-                ("channel", "_c", 1, 0),
-                ("sub_channel", "_sc", 1, 0),
-                ("phase", "_ap", 1, 0),
-            ):
-                value = getattr(pulse_entry, key)
-                if value is not None:
-                    sign = ""
-                    if value < 0:
-                        sign = "m"
-                    new_part = (
-                        separator + sign + str(abs(round(scale * value))).zfill(fill)
-                    )
-                    if len(retval + new_part) > 56:
-                        break
-                    retval += new_part
-            else:  # allow inner break to exit outer loop
-                continue
-            break
+        if self.pulses is not None:
+            for pulse_entry in self.pulses:
+                retval += "_"
+                retval += pulse_entry.pulse or ""
+                for key, separator, scale, fill in (
+                    ("start", "_", 1, 2),
+                    ("amplitude", "_a", 1e9, 10),
+                    ("length", "_l", 1, 3),
+                    ("baseband_phase", "_bb", 1, 7),
+                    ("channel", "_c", 1, 0),
+                    ("sub_channel", "_sc", 1, 0),
+                    ("phase", "_ap", 1, 0),
+                ):
+                    value = getattr(pulse_entry, key)
+                    if value is not None:
+                        sign = ""
+                        if value < 0:
+                            sign = "m"
+                        new_part = (
+                            separator
+                            + sign
+                            + str(abs(round(scale * value))).zfill(fill)
+                        )
+                        if len(retval + new_part) > 56:
+                            break
+                        retval += new_part
+                else:  # allow inner break to exit outer loop
+                    continue
+                break
+        if self.samples is not None:
+            sample_to_shorthand = {
+                "samples_i": "si",
+                "samples_q": "sq",
+                "samples_marker1": "m1",
+                "samples_marker2": "m2",
+            }
+            for sample_name in self.samples.samples_map.keys():
+                new_part = (
+                    sample_to_shorthand[sample_name]
+                    if sample_name in sample_to_shorthand
+                    else sample_name
+                )
+                if len(retval + new_part) > 56:
+                    break
+                retval += new_part
+            retval += f"_{self.samples.label}_"
 
         retval = string_sanitize(retval)
         hashed_signature = self.stable_hash().hexdigest()[:7]
         retval += "_" + hashed_signature
         return retval
 
     def stable_hash(self):
@@ -117,35 +169,38 @@
     clear_precompensation: bool = False
 
     def quantize_phase(self, phase_resolution_range: int):
         """Quantize the phase of all pulses in the waveform.
 
         For the phase that is baked into the samples, we can quantize to the precision
         given by `phase_resolution_range`. For the phase specified by registers on the
-        device (e.g. command table) we quantize to a fixed precision of 48 bits. This
+        device (e.g. command table) we quantize to a fixed precision of 32 bits. This
         serves to avoid rounding errors leading to multiple command table entries."""
+
+        PHASE_RESOLUTION_CT = 1 << 32
+
         for pulse in self.waveform.pulses:
             if pulse.phase is not None:
                 pulse.phase = normalize_phase(
                     round(pulse.phase / 2 / math.pi * phase_resolution_range)
                     / phase_resolution_range
                     * 2
                     * math.pi
                 )
         if self.set_phase is not None:
             self.set_phase = normalize_phase(
-                round(self.set_phase / 2 / math.pi * (1 << 48))
-                / (1 << 48)
+                round(self.set_phase / 2 / math.pi * PHASE_RESOLUTION_CT)
+                / PHASE_RESOLUTION_CT
                 * 2
                 * math.pi
             )
         if self.increment_phase is not None:
             self.increment_phase = normalize_phase(
-                round(self.increment_phase / 2 / math.pi * (1 << 48))
-                / (1 << 48)
+                round(self.increment_phase / 2 / math.pi * PHASE_RESOLUTION_CT)
+                / PHASE_RESOLUTION_CT
                 * 2
                 * math.pi
             )
 
 
 def reduce_signature_phase(
     signature: PlaybackSignature,
```

## laboneq/compiler/code_generator/wave_compressor.py

```diff
@@ -1,13 +1,13 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from dataclasses import dataclass
 from itertools import groupby
-from typing import Dict, List, Union
+from typing import Dict, List, Tuple, Union
 
 import numpy as np
 
 
 @dataclass
 class PlayHold:
     num_samples: int
@@ -25,14 +25,22 @@
 
     def _samples_constant(self, samples: np.ndarray) -> bool:
         return np.all(samples[0] == samples)
 
     def _sample_dict_constant(self, sample_dict: Dict[str, np.array]) -> bool:
         return all(self._samples_constant(sample) for sample in sample_dict.values())
 
+    def _stacked_samples_constant(self, stacked_samples: np.ndarray, lo: int, hi: int):
+        return np.all(
+            np.all(
+                stacked_samples[:, lo + 1 : hi] == stacked_samples[:, lo : hi - 1],
+                axis=0,
+            )
+        )
+
     def _frames_compatible(
         self, last_vals_frame: Dict[str, np.array], sample_dict: Dict[str, np.array]
     ) -> bool:
         return all(
             last_vals_frame[k] == sample_dict[k][0] for k in last_vals_frame.keys()
         )
 
@@ -50,33 +58,115 @@
     def _get_frame(
         self, sample_dict: Dict[str, np.array], size: int, i: int, num_frames: int
     ) -> Dict[str, np.array]:
         if i == num_frames - 1:
             return {k: sample_dict[k][i * size :] for k in sample_dict}
         return {k: v[i * size : (i + 1) * size] for k, v in sample_dict.items()}
 
-    def compress_wave(
-        self, samples: Dict[str, np.array], sample_multiple: int
-    ) -> Union[List, None]:
-        ref_length = len(list(samples.values())[0])
-        if not all(len(v) == ref_length for v in samples.values()):
-            raise ValueError("All sample arrays must have the same length")
-        num_frames = int(ref_length / sample_multiple)
+    def _get_frame_idx(
+        self, sample_dict: Dict[str, np.array], size: int, i: int, num_frames: int
+    ) -> Tuple[int, int]:
+        if i == num_frames - 1:
+            return (i * size, len(list(sample_dict.values())[0]))
+        return (i * size, (i + 1) * size)
+
+    def _runs_longer_than_threshold(self, stacked_samples: np.ndarray, threshold: int):
+        runs = []
 
-        last_vals = []
+        # Calculate differences between consecutive columns
+        diffs = np.diff(stacked_samples, axis=1)
+
+        # Find the indices where consecutive columns change
+        changes = np.nonzero(diffs != 0)[1] + 1
+
+        # Add the first and last indices for runs longer than the threshold
+        if stacked_samples.shape[1] > threshold:
+            changes = np.concatenate(([0], changes, [stacked_samples.shape[1]]))
+
+        # Compute the lengths of each run
+        run_lengths = np.diff(changes)
+
+        # Find indices of runs longer than the threshold
+        long_runs_indices = np.where(run_lengths > threshold)[0]
+
+        # Compute the start and end indices of long runs
+        start_indices = changes[long_runs_indices]
+        end_indices = start_indices + run_lengths[long_runs_indices] - 1
+
+        # Create a list of tuples (start, end) for each long run
+        runs = list(zip(start_indices, end_indices))
+
+        return runs
+
+    def _compress_wave_simple(
+        self,
+        samples: Dict[str, np.array],
+        sample_multiple: int,
+        ref_length: int,
+        run: Tuple[int, int],
+    ) -> Union[List[Union[PlayHold, PlaySamples]], None]:
+        start_run, end_run = run
+
+        start_run_on_grid = (start_run // sample_multiple + 1) * sample_multiple
+        end_run_on_grid = (end_run // sample_multiple - 1) * sample_multiple
+
+        compression_length = (
+            end_run - start_run_on_grid
+            if end_run == ref_length
+            else end_run_on_grid - start_run_on_grid
+        )
+
+        if compression_length < sample_multiple:
+            return None
+
+        events = []
+        events.append(
+            PlaySamples(
+                samples={k: v[0:start_run_on_grid] for k, v in samples.items()},
+                label=self.wave_number,
+            )
+        )
+        self.wave_number += 1
+        if end_run == ref_length - 1:
+            events.append(PlayHold(num_samples=int(ref_length - start_run_on_grid)))
+            return events
+        else:
+            events.append(
+                PlayHold(num_samples=int(end_run_on_grid - start_run_on_grid))
+            )
+            events.append(
+                PlaySamples(
+                    samples={
+                        k: v[end_run_on_grid:ref_length] for k, v in samples.items()
+                    },
+                    label=self.wave_number,
+                )
+            )
+            self.wave_number += 1
+            return events
+
+    def _compress_wave_general(
+        self,
+        samples: Dict[str, np.array],
+        stacked_samples: np.ndarray,
+        num_sample_channles: int,
+        num_frames: int,
+        sample_multiple: int,
+    ) -> Union[List[Union[PlayHold, PlaySamples]], None]:
+        last_vals = np.zeros((num_sample_channles, num_frames))
         for i in range(0, num_frames):
-            sample_frame = self._get_frame(samples, sample_multiple, i, num_frames)
-            last_vals.append({k: sample_frame[k][-1] for k in sample_frame})
+            _, hi = self._get_frame_idx(samples, sample_multiple, i, num_frames)
+            last_vals[:, i] = stacked_samples[:, hi - 1]
 
         can_compress = [False] * num_frames
         for i in range(1, num_frames):
-            sample_frame = self._get_frame(samples, sample_multiple, i, num_frames)
-            can_compress[i] = self._sample_dict_constant(
-                sample_frame
-            ) and self._frames_compatible(last_vals[i - 1], sample_frame)
+            lo, hi = self._get_frame_idx(samples, sample_multiple, i, num_frames)
+            can_compress[i] = self._stacked_samples_constant(
+                stacked_samples, lo, hi
+            ) and np.all(last_vals[:, i - 1] == stacked_samples[:, lo])
 
         if not any(can_compress):
             return None
 
         events = []
         sequences = [
             (key, list(group))
@@ -85,18 +175,18 @@
             )
         ]
 
         for can_compress, sequence in sequences:
             if can_compress:
                 num_samples = 0
                 for frame_idx in sequence:
-                    frame = self._get_frame(
+                    lo, hi = self._get_frame_idx(
                         samples, sample_multiple, frame_idx, num_frames
                     )
-                    num_samples += len(frame[next(iter(frame.keys()))])
+                    num_samples += hi - lo
                 events.append(PlayHold(num_samples=num_samples))
             else:
                 play_samples = []
                 for frame_idx in sequence:
                     play_samples.append(
                         self._get_frame(samples, sample_multiple, frame_idx, num_frames)
                     )
@@ -105,7 +195,29 @@
                         samples=self._merge_samples(samples=play_samples),
                         label=self.wave_number,
                     )
                 )
                 self.wave_number += 1
 
         return events
+
+    def compress_wave(
+        self, samples: Dict[str, np.array], sample_multiple: int
+    ) -> Union[List[Union[PlayHold, PlaySamples]], None]:
+        ref_length = len(list(samples.values())[0])
+        num_sample_channles = len(list(samples.values()))
+        if not all(len(v) == ref_length for v in samples.values()):
+            raise ValueError("All sample arrays must have the same length")
+        num_frames = int(ref_length / sample_multiple)
+
+        stacked_samples = np.array(list(samples.values()))
+
+        runs = self._runs_longer_than_threshold(stacked_samples, 32)
+        if len(runs) == 0:
+            return None
+        if len(runs) == 1:
+            return self._compress_wave_simple(
+                samples, sample_multiple, ref_length, runs[0]
+            )
+        return self._compress_wave_general(
+            samples, stacked_samples, num_sample_channles, num_frames, sample_multiple
+        )
```

## laboneq/compiler/common/event_type.py

```diff
@@ -1,11 +1,14 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 
+from typing import Any
+
+
 class EventType:
     SECTION_START = "SECTION_START"
     SECTION_END = "SECTION_END"
     PLAY_START = "PLAY_START"
     PLAY_END = "PLAY_END"
     ACQUIRE_START = "ACQUIRE_START"
     ACQUIRE_END = "ACQUIRE_END"
@@ -30,7 +33,11 @@
     SET_OSCILLATOR_FREQUENCY_END = "SET_OSCILLATOR_FREQUENCY_END"
     SPECTROSCOPY_END = "SPECTROSCOPY_END"
     SUBSECTION_START = "SUBSECTION_START"
     SUBSECTION_END = "SUBSECTION_END"
     SECTION_SKELETON = "SECTION_SKELETON"
     RELATIVE_TIMING = "RELATIVE_TIMING"
     DIGITAL_SIGNAL_STATE_CHANGE = "DIGITAL_SIGNAL_STATE_CHANGE"
+
+
+SchedulerEvent = dict[str, Any]
+EventList = list[SchedulerEvent]
```

## laboneq/compiler/experiment_access/dsl_loader.py

```diff
@@ -3,16 +3,17 @@
 
 from __future__ import annotations
 
 import copy
 import logging
 import typing
 import uuid
+from numbers import Number
 from types import SimpleNamespace
-from typing import Any, Callable, Dict, Tuple, Union
+from typing import Any, Callable, Dict, Tuple
 
 from laboneq.compiler.experiment_access.acquire_info import AcquireInfo
 from laboneq.compiler.experiment_access.loader_base import LoaderBase
 from laboneq.compiler.experiment_access.marker import Marker
 from laboneq.compiler.experiment_access.param_ref import ParamRef
 from laboneq.compiler.experiment_access.pulse_def import PulseDef
 from laboneq.compiler.experiment_access.section_info import SectionInfo
@@ -25,14 +26,15 @@
     IOSignalType,
 )
 
 if typing.TYPE_CHECKING:
     from laboneq.dsl.device import DeviceSetup
     from laboneq.dsl.device.io_units import LogicalSignal
     from laboneq.dsl.experiment import Experiment, ExperimentSignal
+    from laboneq.dsl.parameter import Parameter
 
 _logger = logging.getLogger(__name__)
 
 
 def find_value_or_parameter_attr(entity: Any, attr: str, value_types: Tuple[type, ...]):
     param = None
     value = getattr(entity, attr, None)
@@ -137,31 +139,38 @@
         ls_lo_frequencies = {}
         ls_ranges = {}
         ls_range_units = {}
         ls_port_delays = {}
         ls_delays_signal = {}
         ls_port_modes = {}
         ls_thresholds = {}
+        ls_amplitudes = {}
         ls_amplifier_pumps = {}
         self._nt_only_params = []
 
         all_logical_signals = [
             ls
             for lsg in device_setup.logical_signal_groups.values()
             for ls in lsg.logical_signals.values()
         ]
         for ls in all_logical_signals:
             ls_map[ls.path] = ls
 
-        mapped_logical_signals: Dict["LogicalSignal", "ExperimentSignal"] = {
+        mapped_logical_signals: Dict["LogicalSignal", "ExperimentSignal"] = {}
+        for signal in experiment.signals.values():
             # Need to create copy here as we'll possibly patch those ExperimentSignals
             # that touch the same PhysicalChannel
-            ls_map[signal.mapped_logical_signal_path]: copy.deepcopy(signal)
-            for signal in experiment.signals.values()
-        }
+            try:
+                mapped_logical_signals[
+                    ls_map[signal.mapped_logical_signal_path]
+                ] = copy.deepcopy(signal)
+            except KeyError:
+                raise LabOneQException(
+                    f"Experiment signal '{signal.uid}' has no mapping to a logical signal."
+                )
 
         experiment_signals_by_physical_channel = {}
         for ls, exp_signal in mapped_logical_signals.items():
             experiment_signals_by_physical_channel.setdefault(
                 ls.physical_channel, []
             ).append(exp_signal)
 
@@ -213,16 +222,23 @@
                         experiment_signal_calibration,
                     )
                     calibration = AttributeOverrider(
                         calibration, experiment_signal_calibration
                     )
 
             if calibration is not None:
+
+                def opt_param(val: float | Parameter | None) -> float | str | None:
+                    if val is None or isinstance(val, Number):
+                        return val
+                    self._nt_only_params.append(val.uid)
+                    return val.uid
+
                 if hasattr(calibration, "port_delay"):
-                    ls_port_delays[ls.path] = calibration.port_delay
+                    ls_port_delays[ls.path] = opt_param(calibration.port_delay)
 
                 if hasattr(calibration, "delay_signal"):
                     ls_delays_signal[ls.path] = calibration.delay_signal
 
                 if hasattr(calibration, "oscillator"):
                     if calibration.oscillator is not None:
                         oscillator = calibration.oscillator
@@ -309,19 +325,18 @@
                     if precomp.FIR is not None:
                         precomp_dict["FIR"] = {
                             "coefficients": copy.deepcopy(precomp.FIR.coefficients),
                         }
                     if precomp_dict:
                         ls_precompensations[ls.path] = precomp_dict
 
-                ls_local_oscillator = getattr(calibration, "local_oscillator")
-                if ls_local_oscillator is not None:
-                    ls_lo_frequencies[ls.path] = getattr(
-                        ls_local_oscillator, "frequency"
-                    )
+                local_oscillator = calibration.local_oscillator
+                if local_oscillator is not None:
+                    ls_lo_frequencies[ls.path] = opt_param(local_oscillator.frequency)
+
                 signal_range = getattr(calibration, "range")
                 if signal_range is not None:
                     if hasattr(signal_range, "unit"):
                         ls_ranges[ls.path] = signal_range.value
                         ls_range_units[ls.path] = str(signal_range.unit)
                     else:
                         ls_ranges[ls.path] = signal_range
@@ -331,32 +346,18 @@
                     hasattr(calibration, "port_mode")
                     and calibration.port_mode is not None
                 ):
                     ls_port_modes[ls.path] = calibration.port_mode.value
 
                 ls_thresholds[ls.path] = getattr(calibration, "threshold", None)
 
-                def amplifier_pump_to_dict(amplifier_pump) -> Dict[str, Any]:
-                    def opt_param(val) -> Union[str, float]:
-                        if val is None or isinstance(val, float):
-                            return val
-                        self._nt_only_params.append(val.uid)
-                        return val.uid
-
-                    return {
-                        "pump_freq": opt_param(amplifier_pump.pump_freq),
-                        "pump_power": opt_param(amplifier_pump.pump_power),
-                        "cancellation": amplifier_pump.cancellation,
-                        "alc_engaged": amplifier_pump.alc_engaged,
-                        "use_probe": amplifier_pump.use_probe,
-                        "probe_frequency": opt_param(amplifier_pump.probe_frequency),
-                        "probe_power": opt_param(amplifier_pump.probe_power),
-                    }
+                ls_amplitudes[ls.path] = opt_param(calibration.amplitude)
 
-                if calibration.amplifier_pump is not None:
+                amp_pump = calibration.amplifier_pump
+                if amp_pump is not None:
                     if ls.direction != IODirection.IN:
                         _logger.warning(
                             "'amplifier_pump' calibration for logical signal %s will be ignored - "
                             "only applicable to acquire lines",
                             ls.path,
                         )
                     elif ls.path not in ppc_connections:
@@ -364,15 +365,23 @@
                             "'amplifier_pump' calibration for logical signal %s will be ignored - "
                             "no PPC is connected to it",
                             ls.path,
                         )
                     else:
                         ls_amplifier_pumps[ls.path] = (
                             *ppc_connections[ls.path],
-                            amplifier_pump_to_dict(calibration.amplifier_pump),
+                            {
+                                "pump_freq": opt_param(amp_pump.pump_freq),
+                                "pump_power": opt_param(amp_pump.pump_power),
+                                "cancellation": amp_pump.cancellation,
+                                "alc_engaged": amp_pump.alc_engaged,
+                                "use_probe": amp_pump.use_probe,
+                                "probe_frequency": opt_param(amp_pump.probe_frequency),
+                                "probe_power": opt_param(amp_pump.probe_power),
+                            },
                         )
 
         for signal in sorted(experiment.signals.values(), key=lambda x: x.uid):
             dev_sig_types = []
             if signal.mapped_logical_signal_path is not None:
                 dev_sig_types = dest_path_devices[signal.mapped_logical_signal_path][
                     "types"
@@ -461,14 +470,15 @@
                     "lo_frequency": ls_lo_frequencies.get(lsuid),
                     "range": ls_ranges.get(lsuid),
                     "range_unit": ls_range_units.get(lsuid),
                     "port_delay": ls_port_delays.get(lsuid),
                     "delay_signal": ls_delays_signal.get(lsuid),
                     "port_mode": ls_port_modes.get(lsuid),
                     "threshold": ls_thresholds.get(lsuid),
+                    "amplitude": ls_amplitudes.get(lsuid),
                     "amplifier_pump": ls_amplifier_pumps.get(lsuid),
                 },
             )
 
         open_inputs = {}
         for instrument in device_setup.instruments:
             for input_obj in instrument.ports:
```

## laboneq/compiler/experiment_access/experiment_dao.py

```diff
@@ -2,15 +2,15 @@
 # SPDX-License-Identifier: Apache-2.0
 
 from __future__ import annotations
 
 import copy
 import logging
 from collections import deque
-from typing import List, Optional
+from typing import Any, List, Optional
 
 from jsonschema import ValidationError
 
 from laboneq._utils import cached_method
 from laboneq.compiler.experiment_access import json_dumper
 from laboneq.compiler.experiment_access.device_info import DeviceInfo
 from laboneq.compiler.experiment_access.dsl_loader import DSLLoader
@@ -64,14 +64,15 @@
             "lo_frequency": None,
             "range": None,
             "range_unit": None,
             "port_delay": None,
             "delay_signal": None,
             "port_mode": None,
             "threshold": None,
+            "amplitude": None,
             "amplifier_pump": None,
         }
 
     def _load_experiment(self, experiment):
         loader = JsonLoader()
         try:
             validator = loader.schema_validator()
@@ -97,15 +98,15 @@
     @property
     def acquisition_type(self) -> AcquisitionType:
         return self._acquisition_type
 
     def server_infos(self):
         return copy.deepcopy(list(self._data["servers"].values()))
 
-    def signals(self):
+    def signals(self) -> list[str]:
         return sorted([s["signal_id"] for s in self._data["signals"].values()])
 
     def devices(self) -> List[str]:
         return [d["id"] for d in self._data["devices"].values()]
 
     def global_leader_device(self) -> str:
         try:
@@ -181,15 +182,15 @@
             "channels",
             "delay_signal",
             "modulation",
             "offset",
         ]
 
     @cached_method()
-    def signal_info(self, signal_id):
+    def signal_info(self, signal_id) -> SignalInfo:
         signal_info = self._data["signals"].get(signal_id)
         if signal_info is not None:
             signal_info_copy = copy.deepcopy(signal_info)
             signal_connection = self._data["signal_connections"][signal_id]
 
             for k in ["device_id", "connection_type", "channels", "delay_signal"]:
                 signal_info_copy[k] = signal_connection[k]
@@ -372,24 +373,27 @@
     def lo_frequency(self, signal_id):
         return self._data["signal_connections"][signal_id]["lo_frequency"]
 
     def signal_range(self, signal_id):
         sc = self._data["signal_connections"][signal_id]
         return sc["range"], sc["range_unit"]
 
-    def port_delay(self, signal_id):
+    def port_delay(self, signal_id) -> float | str | None:
         return self._data["signal_connections"][signal_id]["port_delay"]
 
     def port_mode(self, signal_id):
         return self._data["signal_connections"][signal_id]["port_mode"]
 
     def threshold(self, signal_id):
         return self._data["signal_connections"][signal_id]["threshold"]
 
-    def amplifier_pump(self, signal_id):
+    def amplitude(self, signal_id) -> float | str | None:
+        return self._data["signal_connections"][signal_id]["amplitude"]
+
+    def amplifier_pump(self, signal_id) -> tuple[str, int, dict[str, Any]] | None:
         return self._data["signal_connections"][signal_id]["amplifier_pump"]
 
     def section_pulses(self, section_id, signal_id):
         retval = self._section_pulses_raw(section_id, signal_id)
         for sp in retval:
             pulse_id = sp.pulse_id
             if pulse_id is not None:
```

## laboneq/compiler/experiment_access/json_dumper.py

```diff
@@ -177,14 +177,18 @@
         if port_delay is not None:
             signal_connection["port_delay"] = port_delay
 
         threshold = experiment_dao.threshold(signal_info.signal_id)
         if threshold is not None:
             signal_connection["threshold"] = threshold
 
+        amplitude = experiment_dao.amplitude(signal_info.signal_id)
+        if amplitude is not None:
+            signal_connection["amplitude"] = amplitude
+
         amplifier_pump = experiment_dao.amplifier_pump(signal_info.signal_id)
         if amplifier_pump is not None:
             signal_connection["amplifier_pump"] = amplifier_pump
 
         delay_signal = signal_info.delay_signal
         if delay_signal is not None:
             signal_connection["delay_signal"] = delay_signal
```

## laboneq/compiler/experiment_access/json_loader.py

```diff
@@ -194,14 +194,15 @@
                     "lo_frequency": lo_frequency,
                     "range": range,
                     "range_unit": range_unit,
                     "port_delay": port_delay,
                     "delay_signal": delay_signal,
                     "port_mode": None,
                     "threshold": None,
+                    "amplitude": None,
                     "amplifier_pump": None,
                 },
             )
 
     def _load_pulses(self, experiment):
         for pulse in experiment["pulses"]:
             samples = pulse.get("samples", None)
```

## laboneq/compiler/scheduler/match_schedule.py

```diff
@@ -1,15 +1,16 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from __future__ import annotations
 
+import logging
 import math
 from dataclasses import dataclass
-from typing import TYPE_CHECKING, Dict, Iterable, Iterator, List
+from typing import TYPE_CHECKING, Dict, Iterable, Iterator, List, Tuple
 
 from attrs import define
 from zhinst.utils.feedback_model import (
     FeedbackPath,
     PQSCMode,
     QAType,
     QCCSFeedbackModel,
@@ -20,18 +21,21 @@
 from laboneq.compiler import CompilerSettings
 from laboneq.compiler.common.compiler_settings import EXECUTETABLEENTRY_LATENCY
 from laboneq.compiler.common.event_type import EventType
 from laboneq.compiler.scheduler.case_schedule import CaseSchedule
 from laboneq.compiler.scheduler.section_schedule import SectionSchedule
 from laboneq.compiler.scheduler.utils import ceil_to_grid
 from laboneq.core.exceptions.laboneq_exception import LabOneQException
+from laboneq.core.utilities.compressed_formatter import CompressableLogEntry
 
 if TYPE_CHECKING:
     from laboneq.compiler.scheduler.schedule_data import ScheduleData
 
+_logger = logging.getLogger(__name__)
+
 # Temporary corrected timing model
 @dataclass
 class QCCSFeedbackModelPlus(QCCSFeedbackModel):
     additional_latency: int = 6
 
     def get_latency(self, length: int) -> int:
         return super().get_latency(length) + self.additional_latency
@@ -45,14 +49,26 @@
 def _get_total_rounded_delay_samples(
     port_delays, sample_frequency_hz, granularity_samples
 ):
     delay = sum(round((d or 0) * sample_frequency_hz) for d in port_delays)
     return (math.ceil(delay / granularity_samples + 0.5) - 1) * granularity_samples
 
 
+def _generate_warning(warnings: List[Tuple[str, str, float]]):
+    if not warnings:
+        return
+    n = len(warnings)
+    header = f"Due to feedback latency constraints, the timing of the following match section{'s'[:n^1]} with corresponding handle{'s'[:n^1]} were changed:"
+    messages = [
+        f"  - '{section}' with handle '{handle}', delayed by {1e9*delay:.2f} ns"
+        for section, handle, delay in warnings
+    ]
+    _logger.info(CompressableLogEntry(header, messages, max_messages=3))
+
+
 def _compute_start_with_latency(
     schedule_data: ScheduleData,
     start: int,
     local: bool,
     handle: str,
     section: str,
     signals: Iterable[str],
@@ -103,14 +119,20 @@
     acq_start = acquire_pulse.absolute_start * schedule_data.TINYSAMPLE
     acq_length = acquire_pulse.length * schedule_data.TINYSAMPLE
     qa_lead_time = qa_signal_obj.start_delay or 0.0
     qa_delay_signal = qa_signal_obj.delay_signal or 0.0
     qa_port_delay = qa_signal_obj.port_delay or 0.0
     qa_base_delay_signal = qa_signal_obj.base_delay_signal or 0.0
     qa_base_port_delay = qa_signal_obj.base_port_delay or 0.0
+
+    if math.isnan(qa_port_delay) or math.isnan(qa_base_port_delay):
+        raise LabOneQException(
+            "Feedback requires constant 'port_delay', but it is a sweep parameter."
+        )
+
     qa_total_port_delay = _get_total_rounded_delay_samples(
         (qa_base_port_delay, qa_port_delay),
         qa_sampling_rate,
         qa_device_type.sample_multiple,
     )
 
     acquire_end_in_samples = (
@@ -184,14 +206,24 @@
             ceil_to_grid(
                 latency_in_ts
                 - round((sg_lead_time + sg_delay_signal) / schedule_data.TINYSAMPLE),
                 grid,
             ),
         )
 
+    if earliest_execute_table_entry > start:
+        schedule_data.combined_warnings.setdefault(
+            "match_start_shifted", (_generate_warning, [])
+        )[1].append(
+            (
+                section,
+                handle,
+                (earliest_execute_table_entry - start) * schedule_data.TINYSAMPLE,
+            )
+        )
     return max(earliest_execute_table_entry, start)
 
 
 @define(kw_only=True, slots=True)
 class MatchSchedule(SectionSchedule):
     handle: str
     local: bool
```

## laboneq/compiler/scheduler/schedule_data.py

```diff
@@ -1,14 +1,14 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from __future__ import annotations
 
 from dataclasses import dataclass, field
-from typing import TYPE_CHECKING, Dict, List
+from typing import TYPE_CHECKING, Callable, Dict, List, Tuple
 
 if TYPE_CHECKING:
     from laboneq.compiler.common.compiler_settings import CompilerSettings
     from laboneq.compiler.common.signal_obj import SignalObj
     from laboneq.compiler.experiment_access.experiment_dao import ExperimentDAO
     from laboneq.compiler.scheduler.pulse_schedule import PulseSchedule
     from laboneq.compiler.scheduler.sampling_rate_tracker import SamplingRateTracker
@@ -17,11 +17,12 @@
 @dataclass
 class ScheduleData:
     experiment_dao: ExperimentDAO
     sampling_rate_tracker: SamplingRateTracker
     settings: CompilerSettings
     acquire_pulses: Dict[str, List[PulseSchedule]] = field(default_factory=dict)
     signal_objects: Dict[str, SignalObj] = field(default_factory=dict)
+    combined_warnings: Dict[str, Tuple[Callable, List]] = field(default_factory=dict)
     TINYSAMPLE: float = field(init=False)
 
     def __post_init__(self):
         self.TINYSAMPLE = self.settings.TINYSAMPLE
```

## laboneq/compiler/scheduler/scheduler.py

```diff
@@ -108,14 +108,19 @@
 
     @trace("scheduler.run()", {"version": "v2"})
     def run(self, nt_parameters=None):
         if nt_parameters is None:
             nt_parameters = {}
         self._root_schedule = self._schedule_root(nt_parameters)
         _logger.info("Schedule completed")
+        for _, (
+            warning_generator,
+            warning_data,
+        ) in self._schedule_data.combined_warnings.items():
+            warning_generator(warning_data)
 
     def generate_event_list(self, expand_loops: bool, max_events: int):
         event_list = self._start_events()
 
         if self._root_schedule is not None:
             id_tracker = itertools.count()
             event_list.extend(
```

## laboneq/compiler/workflow/compiler.py

```diff
@@ -1,10 +1,12 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
+from __future__ import annotations
+
 import copy
 import logging
 import math
 from collections import Counter
 from dataclasses import dataclass, field
 from typing import Any, Dict, List, Optional, Set, Tuple, Union
 
@@ -488,20 +490,20 @@
             precompensations,
             self._experiment_dao,
             self._clock_settings["use_2GHz_for_HDAWG"],
         )
         return precompensations
 
     def _generate_signal_objects(self):
-        signal_objects = {}
+        signal_objects: dict[str, SignalObj] = {}
 
         @dataclass
         class DelayInfo:
-            port_delay_gen: Optional[float] = None
-            delay_signal_gen: Optional[float] = None
+            port_delay_gen: float | None = None
+            delay_signal_gen: float | None = None
 
         delay_measure_acquire: Dict[AwgKey, DelayInfo] = {}
 
         for signal_id in self._experiment_dao.signals():
 
             signal_info = self._experiment_dao.signal_info(signal_id)
             delay_signal = signal_info.delay_signal
@@ -580,14 +582,17 @@
                 and oscillator_info.hardware
             ):
                 mixer_type = MixerType.UHFQA_ENVELOPE
             elif signal_type in ("single",):
                 mixer_type = None
 
             port_delay = self._experiment_dao.port_delay(signal_id)
+            if isinstance(port_delay, str):  # NT sweep param
+                port_delay = math.nan
+
             if signal_type != "integration":
                 delay_info = delay_measure_acquire.setdefault(awg.key, DelayInfo())
                 delay_info.port_delay_gen = port_delay
                 delay_info.delay_signal_gen = delay_signal
 
             signal_obj = SignalObj(
                 id=signal_id,
@@ -655,15 +660,21 @@
                 scheduler_port_delay += pc_port_delay
 
             base_channel = min(signal_info.channels)
 
             markers = self._experiment_dao.markers_on_signal(signal_id)
 
             triggers = self._experiment_dao.triggers_on_signal(signal_id)
-            if lo_frequency is not None:
+            if (
+                lo_frequency is not None
+                and not isinstance(lo_frequency, str)
+                and port_mode != "LF"
+            ):
+                # TODO(2K): This validation had to be implemented in the controller
+                # to support swept lo_frequency
                 try:
                     validate_local_oscillator_frequency(lo_frequency, device_type)
                 except ValueError as error:
                     raise LabOneQException(
                         f"Error on signal line '{signal_id}': {error}"
                     ) from error
 
@@ -673,14 +684,15 @@
                     "channel": channel,
                     "lo_frequency": lo_frequency,
                     "port_mode": port_mode,
                     "range": signal_range,
                     "range_unit": signal_range_unit,
                     "port_delay": port_delay,
                     "scheduler_port_delay": scheduler_port_delay,
+                    "amplitude": self._experiment_dao.amplitude(signal_id),
                 }
                 signal_is_modulated = signal_info.modulation
                 output_modulation_logic = {
                     (True, True): True,
                     (False, False): False,
                     (True, False): False,
                     (False, True): False,
@@ -953,14 +965,15 @@
                 lo_frequency=output["lo_frequency"],
                 port_mode=output["port_mode"],
                 output_range=output["range"],
                 output_range_unit=output["range_unit"],
                 port_delay=output["port_delay"],
                 scheduler_port_delay=output["scheduler_port_delay"],
                 marker_mode=output.get("marker_mode"),
+                amplitude=output["amplitude"],
             )
 
         for input in self.calc_inputs(self._code_generator.signal_delays()):
             _logger.debug("Adding input %s", input)
             recipe_generator.add_input(
                 input["device_id"],
                 input["channel"],
```

## laboneq/compiler/workflow/recipe_generator.py

```diff
@@ -196,14 +196,15 @@
         lo_frequency=None,
         port_mode=None,
         output_range=None,
         output_range_unit=None,
         port_delay=None,
         scheduler_port_delay=0.0,
         marker_mode=None,
+        amplitude=None,
     ):
         output = {"channel": channel, "enable": True}
         if offset is not None:
             output.update({"offset": offset})
         if diagonal is not None and off_diagonal is not None:
             output.update(
                 {"gains": {"diagonal": diagonal, "off_diagonal": off_diagonal}}
@@ -224,14 +225,16 @@
         if oscillator_frequency is not None:
             output["oscillator_frequency"] = oscillator_frequency
         if port_delay is not None:
             output["port_delay"] = port_delay
         output["scheduler_port_delay"] = scheduler_port_delay
         if marker_mode is not None:
             output["marker_mode"] = marker_mode
+        if amplitude is not None:
+            output["amplitude"] = amplitude
 
         initialization: dict = self._find_initialization(device_id)
         outputs: list = initialization.setdefault("outputs", [])
         outputs.append(output)
 
     def add_input(
         self,
```

## laboneq/contrib/example_helpers/plotting/plot_helpers.py

```diff
@@ -119,18 +119,42 @@
                     empty_array.fill(np.nan)
                     y2s.append(empty_array[0])
                     labels2.append(None)
 
             except Exception:
                 pass
 
+        if (
+            "qa" not in str(physical_channel_path.name)
+            and np.sum(my_snippet.trigger) != 0
+            and f"{physcial_channel} - Trigger".upper() not in titles
+        ):
+            try:
+                if my_snippet.time is not None:
+                    time_length = len(my_snippet.time)
+
+                    xs.append(my_snippet.time)
+
+                    y1s.append(my_snippet.trigger)
+                    labels1.append(f"{signal} Trigger")
+
+                    titles.append(f"{physcial_channel} - Trigger".upper())
+
+                    empty_array = np.empty((1, time_length))
+                    empty_array.fill(np.nan)
+                    y2s.append(empty_array[0])
+                    labels2.append(None)
+
+            except Exception:
+                pass
+
     fig, axes = plt.subplots(
         nrows=len(y1s),
         sharex=False,
-        figsize=(plot_width, len(mapped_signals) * plot_height),
+        figsize=(plot_width, len(y1s) * plot_height),
     )
 
     colors = plt.rcParams["axes.prop_cycle"]()
 
     if len(xs) > 1:
         for axs, x, y1, y2, label1, label2, title in zip(
             axes.flat, xs, y1s, y2s, labels1, labels2, titles
```

## laboneq/controller/controller.py

```diff
@@ -112,18 +112,14 @@
 
     def _allocate_resources(self):
         self._devices.free_allocations()
         osc_params = self._recipe_data.recipe.experiment.oscillator_params
         for osc_param in sorted(osc_params, key=lambda p: p.id):
             self._devices.find_by_uid(osc_param.device_id).allocate_osc(osc_param)
 
-        for initialization in self._recipe_data.recipe.experiment.initializations:
-            device = self._devices.find_by_uid(initialization.device_uid)
-            device.allocate_params(initialization)
-
     def _reset_to_idle_state(self):
         reset_nodes = []
         for _, device in self._devices.all:
             reset_nodes.extend(device.collect_reset_nodes())
         batch_set(reset_nodes)
 
     def _wait_for_conditions_to_start(self):
@@ -455,15 +451,15 @@
         self._devices.disconnect()
         self._last_connect_check_ts = None
         _logger.info("Successfully disconnected from all devices and servers.")
 
     def execute_compiled(
         self, compiled_experiment: CompiledExperiment, session: Session = None
     ):
-        self._recipe_data = pre_process_compiled(compiled_experiment)
+        self._recipe_data = pre_process_compiled(compiled_experiment, self._devices)
 
         self._session = session
         if session is None:
             self._results = None
         else:
             self._results = session._last_results
 
@@ -659,28 +655,31 @@
             count: int,
             uid: str,
             averaging_mode: AveragingMode,
             acquisition_type: AcquisitionType,
             enter: bool,
         ):
             if enter:
-                affected_devices: set[str] = set()
+                attribute_value_tracker = (
+                    self.controller._recipe_data.attribute_value_tracker
+                )
                 for param in self.sweep_params_tracker.updated_params():
-                    affected_devices.update(
-                        self.controller._recipe_data.param_to_device_map.get(param, [])
+                    attribute_value_tracker.update(
+                        param, self.sweep_params_tracker.get_param(param)
                     )
+                self.sweep_params_tracker.clear_for_next_step()
+
                 nt_sweep_nodes: list[DaqNodeAction] = []
-                for device_id in affected_devices:
-                    device = self.controller._devices.find_by_uid(device_id)
+                for device_uid, device in self.controller._devices.all:
                     nt_sweep_nodes.extend(
-                        device.collect_prepare_sweep_step_nodes_for_param(
-                            self.sweep_params_tracker
+                        device.collect_prepare_nt_step_nodes(
+                            attribute_value_tracker.device_view(device_uid),
+                            self.controller._recipe_data,
                         )
                     )
-                self.sweep_params_tracker.clear_for_next_step()
 
                 step_prepare_nodes = self.controller._prepare_rt_execution(
                     rt_section_uid=uid
                 )
 
                 batch_set([*self.user_set_nodes, *nt_sweep_nodes, *step_prepare_nodes])
                 self.user_set_nodes.clear()
```

## laboneq/controller/laboneq_logging.py

```diff
@@ -1,16 +1,19 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
+import functools
 import logging
 import logging.config
 import os
 
 import yaml
 
+from laboneq.core.utilities.compressed_formatter import CompressedFormatter
+
 _logger = logging.getLogger(__name__)
 _log_dir = os.path.join("laboneq_output", "log")
 _logging_initialized = False
 
 
 def set_log_dir(dir):
     global _log_dir
@@ -111,14 +114,18 @@
         if "handlers" in config:
             for handler in config["handlers"].values():
                 if "filename" in handler:
                     default_filename = handler["filename"]
                     if not os.path.isabs(default_filename):
                         handler["filename"] = os.path.join(logdir, default_filename)
         config_source = f"Default inline config in {__name__}"
+        for name, formatter in config["formatters"].items():
+            formatter["()"] = functools.partial(
+                CompressedFormatter, compress=name == "console_formatter"
+            )
 
     logging.config.dictConfig(config)
 
     performance_log_file = None
     if performance_log:
         performance_log_file = os.path.abspath(
             os.path.join(get_log_dir(), "controller_perf.log")
```

## laboneq/controller/recipe_1_4_0.py

```diff
@@ -122,14 +122,15 @@
             "precompensation",
             "lo_frequency",
             "port_mode",
             "port_delay",
             "scheduler_port_delay",
             "delay_signal",
             "marker_mode",
+            "amplitude",
         )
         ordered = True
 
     @dataclass
     class Data:
         channel: int
         enable: Optional[bool] = None
@@ -137,37 +138,39 @@
         oscillator: Optional[int] = None
         oscillator_frequency: Optional[int] = None
         offset: Optional[float] = None
         gains: Optional[Gains] = None
         range: Optional[float] = None
         range_unit: Optional[str] = None
         precompensation: Optional[Dict[str, Dict]] = None
-        lo_frequency: Optional[float] = None
+        lo_frequency: Optional[Any] = None
         port_mode: Optional[str] = None
-        port_delay: Optional[float] = None
+        port_delay: Optional[Any] = None
         scheduler_port_delay: float = 0.0
         delay_signal: Optional[float] = None
         marker_mode: Optional[str] = None
+        amplitude: Optional[Any] = None
 
     channel = fields.Integer()
     enable = fields.Boolean(required=False)
     modulation = fields.Boolean(required=False)
     oscillator = fields.Integer(required=False)
     oscillator_frequency = fields.Integer(required=False)
     offset = fields.Float(required=False)
     gains = fields.Nested(Gains, required=False)
     range = fields.Float(required=False)
     range_unit = fields.Str(required=False)
     precompensation = fields.Dict(required=False)
-    lo_frequency = fields.Float(required=False)
+    lo_frequency = fields.Raw(required=False)
     port_mode = fields.Str(required=False)
-    port_delay = fields.Float(required=False)
+    port_delay = fields.Raw(required=False)
     scheduler_port_delay = fields.Float(required=False)
     delay_signal = fields.Float(required=False)
     marker_mode = fields.Str(required=False)
+    amplitude = fields.Raw(required=False)
 
 
 class SignalTypeField(fields.Field):
     def _serialize(self, value, attr, obj, **kwargs):
         return value.name
 
     def _deserialize(self, value, attr, data, **kwargs):
```

## laboneq/controller/recipe_processor.py

```diff
@@ -6,14 +6,19 @@
 from collections import defaultdict
 from dataclasses import dataclass, field
 from typing import TYPE_CHECKING, Any, Dict, Iterator, List, Optional, Set, Tuple, Union
 
 import numpy as np
 from numpy import typing as npt
 
+from laboneq.controller.attribute_value_tracker import (
+    AttributeName,
+    AttributeValueTracker,
+    DeviceAttribute,
+)
 from laboneq.controller.util import LabOneQControllerException
 from laboneq.core.types.enums.acquisition_type import AcquisitionType
 from laboneq.core.types.enums.averaging_mode import AveragingMode
 from laboneq.executor.execution_from_experiment import ExecutionFactoryFromExperiment
 from laboneq.executor.executor import (
     ExecutorBase,
     LoopingMode,
@@ -24,14 +29,15 @@
 
 from .recipe_1_4_0 import IO
 from .recipe_1_4_0 import Experiment as RecipeExperiment
 from .recipe_1_4_0 import Initialization, Recipe
 from .recipe_enums import SignalType
 
 if TYPE_CHECKING:
+    from laboneq.controller.devices.device_collection import DeviceCollection
     from laboneq.core.types import CompiledExperiment
 
 
 @dataclass
 class HandleResultShape:
     base_shape: List[int]
     base_axis_name: List[Union[str, List[str]]]
@@ -123,15 +129,16 @@
     compiled: CompiledExperiment
     recipe: Recipe.Data
     execution: Sequence
     result_shapes: HandleResultShapes
     rt_execution_infos: RtExecutionInfos
     device_settings: DeviceSettings
     awg_configs: AwgConfigs
-    param_to_device_map: Dict[str, List[str]]
+    attribute_value_tracker: AttributeValueTracker
+    oscillator_ids: list[str]
 
     @property
     def initializations(self) -> Iterator[Initialization.Data]:
         for initialization in self.recipe.experiment.initializations:
             yield initialization
 
     def get_initialization_by_device_uid(self, device_uid: str) -> Initialization.Data:
@@ -461,55 +468,82 @@
                 awg_config.result_length = (
                     len(any_awg_signal_result_map) * mapping_repeats
                 )
 
     return awg_configs
 
 
-def _pre_process_params(
-    experiment: RecipeExperiment.Data,
-) -> Dict[str, Set[str]]:
-    param_to_device_map: Dict[str, Set[str]] = defaultdict(set)
-
-    oscillator_params = experiment.oscillator_params
-    for oscillator_param in oscillator_params:
-        param_to_device_map[oscillator_param.param].add(oscillator_param.device_id)
+def _pre_process_attributes(
+    experiment: RecipeExperiment.Data, devices: DeviceCollection
+) -> tuple[AttributeValueTracker, list[str]]:
+    attribute_value_tracker = AttributeValueTracker()
+    oscillator_ids: list[str] = []
+    oscillators_check: dict[str, str | float] = {}
+
+    for oscillator_param in experiment.oscillator_params:
+        value_or_param = oscillator_param.param or oscillator_param.frequency
+        if oscillator_param.id in oscillator_ids:
+            osc_index = oscillator_ids.index(oscillator_param.id)
+            if oscillators_check[oscillator_param.id] != value_or_param:
+                raise LabOneQControllerException(
+                    f"Conflicting specifications for the same oscillator id '{oscillator_param.id}' "
+                    f"in the recipe: '{oscillators_check[oscillator_param.id]}' != '{value_or_param}'"
+                )
+        else:
+            osc_index = len(oscillator_ids)
+            oscillator_ids.append(oscillator_param.id)
+            oscillators_check[oscillator_param.id] = value_or_param
+        attribute_value_tracker.add_attribute(
+            device_uid=oscillator_param.device_id,
+            attribute=DeviceAttribute(
+                name=AttributeName.OSCILLATOR_FREQ,
+                index=osc_index,
+                value_or_param=value_or_param,
+            ),
+        )
 
     for initialization in experiment.initializations:
-        ppchannels = initialization.ppchannels or {}
-        for settings in ppchannels.values():
-            for key in ["pump_freq", "pump_power", "probe_frequency", "probe_power"]:
-                if isinstance(settings[key], str):
-                    param_to_device_map[settings[key]].add(initialization.device_uid)
-    return param_to_device_map
+        device = devices.find_by_uid(initialization.device_uid)
+        for attribute in device.pre_process_attributes(initialization):
+            attribute_value_tracker.add_attribute(
+                device_uid=initialization.device_uid,
+                attribute=attribute,
+            )
 
+    return attribute_value_tracker, oscillator_ids
 
-def pre_process_compiled(compiled_experiment: CompiledExperiment) -> RecipeData:
+
+def pre_process_compiled(
+    compiled_experiment: CompiledExperiment, devices: DeviceCollection
+) -> RecipeData:
     recipe: Recipe.Data = Recipe().load(compiled_experiment.recipe)
 
     device_settings: DeviceSettings = defaultdict(DeviceRecipeData)
     for initialization in recipe.experiment.initializations:
         device_settings[initialization.device_uid] = DeviceRecipeData(
             iq_settings=_pre_process_iq_settings_hdawg(initialization)
         )
 
     execution = ExecutionFactoryFromExperiment().make(compiled_experiment.experiment)
     result_shapes, rt_execution_infos = _calculate_result_shapes(execution)
     awg_configs = _calculate_awg_configs(rt_execution_infos, recipe.experiment)
-    param_to_device_map = _pre_process_params(recipe.experiment)
+    attribute_value_tracker, oscillator_ids = _pre_process_attributes(
+        recipe.experiment, devices
+    )
 
     recipe_data = RecipeData(
         compiled=compiled_experiment,
         recipe=recipe,
         execution=execution,
         result_shapes=result_shapes,
         rt_execution_infos=rt_execution_infos,
         device_settings=device_settings,
         awg_configs=awg_configs,
-        param_to_device_map=param_to_device_map,
+        attribute_value_tracker=attribute_value_tracker,
+        oscillator_ids=oscillator_ids,
     )
 
     return recipe_data
 
 
 def get_wave(wave_name, waves: List[Dict[str, Any]]):
     wave = next(
```

## laboneq/controller/devices/device_collection.py

```diff
@@ -138,15 +138,15 @@
                 ]
             )
             response_waiter.add(
                 target=device.daq.node_monitor,
                 conditions={n.path: n.value for n in filter_responses(dev_nodes)},
             )
 
-        if len(set_nodes) is None:
+        if not set_nodes:
             return
 
         batch_set(set_nodes)
         timeout = 10
         if not response_waiter.wait_all(timeout=timeout):
             raise LabOneQControllerException(
                 f"Internal error: {config_name} for devices "
```

## laboneq/controller/devices/device_hdawg.py

```diff
@@ -5,14 +5,18 @@
 
 import logging
 from enum import IntEnum
 from typing import Any
 
 import numpy as np
 
+from laboneq.controller.attribute_value_tracker import (
+    AttributeName,
+    DeviceAttributesView,
+)
 from laboneq.controller.communication import (
     CachingStrategy,
     DaqNodeAction,
     DaqNodeSetAction,
 )
 from laboneq.controller.devices.device_zi import DeviceZI, delay_to_rounded_samples
 from laboneq.controller.devices.zi_node_monitor import (
@@ -262,31 +266,14 @@
                         f"sigouts/{output.channel}/range",
                         output.range,
                     )
                 )
             nodes.append((f"sigouts/{output.channel}/offset", output.offset))
             nodes.append((f"awgs/{awg_idx}/single", 1))
 
-            output_delay = output.scheduler_port_delay
-            output_delay += output.port_delay or 0.0
-
-            output_delay_rounded = (
-                delay_to_rounded_samples(
-                    channel=output.channel,
-                    dev_repr=self.dev_repr,
-                    delay=output_delay,
-                    sample_frequency_hz=self._sampling_rate,
-                    granularity_samples=DELAY_NODE_GRANULARITY_SAMPLES,
-                    max_node_delay_samples=DELAY_NODE_MAX_SAMPLES,
-                )
-                / self._sampling_rate
-            )
-
-            nodes.append((f"sigouts/{output.channel}/delay", output_delay_rounded))
-
             awg_ch = output.channel % 2
             iq_idx = output.channel // 2
             iq_gains_mx = device_recipe_data.iq_settings.get(iq_idx, None)
 
             if iq_gains_mx is None:
                 # Fall back to old behavior (suitable for single channel output)
                 diagonal_channel_index = awg_ch
@@ -416,29 +403,64 @@
             ch: osc.index for osc in self._allocated_oscs for ch in osc.channels
         }
         for ch, osc_idx in osc_selects.items():
             nodes.append((f"sines/{ch}/oscselect", osc_idx))
 
         return [DaqNodeSetAction(self._daq, f"/{self.serial}/{k}", v) for k, v in nodes]
 
+    def collect_prepare_nt_step_nodes(
+        self, attributes: DeviceAttributesView, recipe_data: RecipeData
+    ) -> list[DaqNodeAction]:
+        nodes_to_set = super().collect_prepare_nt_step_nodes(attributes, recipe_data)
+
+        for ch in range(self._channels):
+            [scheduler_port_delay, port_delay], updated = attributes.resolve(
+                keys=[
+                    (AttributeName.OUTPUT_SCHEDULER_PORT_DELAY, ch),
+                    (AttributeName.OUTPUT_PORT_DELAY, ch),
+                ]
+            )
+            if not updated or scheduler_port_delay is None:
+                continue
+
+            output_delay = scheduler_port_delay + (port_delay or 0.0)
+            output_delay_rounded = (
+                delay_to_rounded_samples(
+                    channel=ch,
+                    dev_repr=self.dev_repr,
+                    delay=output_delay,
+                    sample_frequency_hz=self._sampling_rate,
+                    granularity_samples=DELAY_NODE_GRANULARITY_SAMPLES,
+                    max_node_delay_samples=DELAY_NODE_MAX_SAMPLES,
+                )
+                / self._sampling_rate
+            )
+
+            nodes_to_set.append(
+                DaqNodeSetAction(
+                    daq=self.daq,
+                    path=f"/{self.serial}/sigouts/{ch}/delay",
+                    value=output_delay_rounded,
+                )
+            )
+
+        return nodes_to_set
+
     def wait_for_conditions_to_start(self):
         self._wait_for_node(
             f"/{self.serial}/system/clocks/sampleclock/status", 0, timeout=5
         )
 
     def collect_awg_before_upload_nodes(
         self, initialization: Initialization.Data, recipe_data: RecipeData
     ):
         device_specific_initialization_nodes = [
             DaqNodeSetAction(
                 self._daq, f"/{self.serial}/system/awg/oscillatorcontrol", 1
             ),
-            DaqNodeSetAction(
-                self._daq, f"/{self.serial}/raw/system/awg/runtimechecks/enable", 1
-            ),
         ]
 
         return device_specific_initialization_nodes
 
     def add_command_table_header(self, body: dict) -> dict:
         return {
             "$schema": "https://docs.zhinst.com/hdawg/commandtable/v1_0/schema",
```

## laboneq/controller/devices/device_shfppc.py

```diff
@@ -1,32 +1,39 @@
 # Copyright 2019 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from __future__ import annotations
 
-from collections import defaultdict
+from typing import Iterator
 
+from laboneq.controller.attribute_value_tracker import (
+    AttributeName,
+    DeviceAttribute,
+    DeviceAttributesView,
+)
 from laboneq.controller.communication import DaqNodeAction, DaqNodeSetAction
 from laboneq.controller.devices.device_zi import DeviceZI
 from laboneq.controller.recipe_1_4_0 import Initialization
-from laboneq.controller.recipe_processor import DeviceRecipeData
-from laboneq.controller.util import SweepParamsTracker
+from laboneq.controller.recipe_processor import DeviceRecipeData, RecipeData
 
 
 class DeviceSHFPPC(DeviceZI):
-    param_keys = ["pump_freq", "pump_power", "probe_frequency", "probe_power"]
+    attribute_keys = {
+        "pump_freq": AttributeName.PPC_PUMP_FREQ,
+        "pump_power": AttributeName.PPC_PUMP_POWER,
+        "probe_frequency": AttributeName.PPC_PROBE_FREQUENCY,
+        "probe_power": AttributeName.PPC_PROBE_POWER,
+    }
 
     def __init__(self, *args, **kwargs):
         super().__init__(*args, **kwargs)
         self.dev_type = "SHFPPC"
         self.dev_opts = []
         self._use_internal_clock = False
-        self._param_to_paths: dict[str, list[str]] = defaultdict(
-            list
-        )  # TODO(2K): Move to DeviceZI
+        self._channels = 4  # TODO(2K): Update from device
 
     def _key_to_path(self, key: str, ch: int):
         keys_to_paths = {
             "_on": f"/{self.serial}/ppchannels/{ch}/synthesizer/pump/on",
             "pump_freq": f"/{self.serial}/ppchannels/{ch}/synthesizer/pump/freq",
             "pump_power": f"/{self.serial}/ppchannels/{ch}/synthesizer/pump/power",
             "cancellation": f"/{self.serial}/ppchannels/{ch}/cancellation/on",
@@ -36,21 +43,26 @@
             "probe_power": f"/{self.serial}/ppchannels/{ch}/synthesizer/probe/power",
         }
         return keys_to_paths.get(key)
 
     def update_clock_source(self, force_internal: bool | None):
         self._use_internal_clock = force_internal is True
 
-    def allocate_params(self, initialization: Initialization.Data):
+    def pre_process_attributes(
+        self,
+        initialization: Initialization.Data,
+    ) -> Iterator[DeviceAttribute]:
+        yield from super().pre_process_attributes(initialization)
         ppchannels = initialization.ppchannels or {}
-        for ch, settings in ppchannels.items():
-            for key in DeviceSHFPPC.param_keys:
-                setting = settings.get(key)
-                if isinstance(setting, str):
-                    self._param_to_paths[setting].append(self._key_to_path(key, ch))
+        for channel, settings in ppchannels.items():
+            for key, attribute_name in DeviceSHFPPC.attribute_keys.items():
+                if key in settings:
+                    yield DeviceAttribute(
+                        name=attribute_name, index=channel, value_or_param=settings[key]
+                    )
 
     def check_errors(self):
         pass
 
     def collect_reset_nodes(self) -> list[DaqNodeAction]:
         return []
 
@@ -66,34 +78,29 @@
             return value
 
         for ch, settings in ppchannels.items():
             nodes_to_set.append(
                 DaqNodeSetAction(self._daq, self._key_to_path("_on", ch), 1)
             )
             for key, value in settings.items():
-                if (
-                    value is None
-                    or key in DeviceSHFPPC.param_keys
-                    and isinstance(value, str)
-                ):
+                if value is None or key in DeviceSHFPPC.attribute_keys:
                     # Skip not set values, or values that are bound to sweep params and will
                     # be set during the NT execution.
                     continue
                 nodes_to_set.append(
                     DaqNodeSetAction(
                         self._daq, self._key_to_path(key, ch), _convert(value)
                     )
                 )
         return nodes_to_set
 
-    def collect_prepare_sweep_step_nodes_for_param(
-        self, sweep_params_tracker: SweepParamsTracker
+    def collect_prepare_nt_step_nodes(
+        self, attributes: DeviceAttributesView, recipe_data: RecipeData
     ) -> list[DaqNodeAction]:
-        nodes_to_set: list[DaqNodeAction] = []
-        for param in sweep_params_tracker.updated_params():
-            for path in self._param_to_paths.get(param, []):
-                nodes_to_set.append(
-                    DaqNodeSetAction(
-                        self._daq, path, sweep_params_tracker.get_param(param)
-                    )
-                )
+        nodes_to_set = super().collect_prepare_nt_step_nodes(attributes, recipe_data)
+        for ch in range(self._channels):
+            for key, attr_name in DeviceSHFPPC.attribute_keys.items():
+                [value], updated = attributes.resolve(keys=[(attr_name, ch)])
+                if updated:
+                    path = self._key_to_path(key, ch)
+                    nodes_to_set.append(DaqNodeSetAction(self._daq, path, value))
         return nodes_to_set
```

## laboneq/controller/devices/device_shfqa.py

```diff
@@ -1,19 +1,24 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from __future__ import annotations
 
 import logging
 import time
-from typing import Any
+from typing import Any, Iterator
 
 import numpy as np
 from numpy import typing as npt
 
+from laboneq.controller.attribute_value_tracker import (
+    AttributeName,
+    DeviceAttribute,
+    DeviceAttributesView,
+)
 from laboneq.controller.communication import (
     CachingStrategy,
     DaqNodeAction,
     DaqNodeGetAction,
     DaqNodeSetAction,
 )
 from laboneq.controller.devices.device_zi import DeviceZI, delay_to_rounded_samples
@@ -442,14 +447,48 @@
                 AcquisitionType.DISCRIMINATION,
             ]:
                 conditions[
                     f"/{self.serial}/qachannels/{awg_index}/readout/result/enable"
                 ] = 0
         return conditions
 
+    def pre_process_attributes(
+        self,
+        initialization: Initialization.Data,
+    ) -> Iterator[DeviceAttribute]:
+        yield from super().pre_process_attributes(initialization)
+
+        for output in initialization.outputs or []:
+            if output.amplitude is not None:
+                yield DeviceAttribute(
+                    name=AttributeName.QA_OUT_AMPLITUDE,
+                    index=output.channel,
+                    value_or_param=output.amplitude,
+                )
+
+        center_frequencies = {}
+        ios = (initialization.outputs or []) + (initialization.inputs or [])
+        for idx, io in enumerate(ios):
+            if io.lo_frequency is not None:
+                if io.channel in center_frequencies:
+                    prev_io_idx = center_frequencies[io.channel]
+                    if ios[prev_io_idx].lo_frequency != io.lo_frequency:
+                        raise LabOneQControllerException(
+                            f"{self.dev_repr}: Local oscillator frequency mismatch between IOs "
+                            f"sharing channel {io.channel}: "
+                            f"{ios[prev_io_idx].lo_frequency} != {io.lo_frequency}"
+                        )
+                    continue
+                center_frequencies[io.channel] = idx
+                yield DeviceAttribute(
+                    name=AttributeName.QA_CENTER_FREQ,
+                    index=io.channel,
+                    value_or_param=io.lo_frequency,
+                )
+
     def collect_initialization_nodes(
         self, device_recipe_data: DeviceRecipeData, initialization: Initialization.Data
     ) -> list[DaqNodeSetAction]:
         _logger.debug("%s: Initializing device...", self.dev_repr)
 
         nodes_to_initialize_output: list[DaqNodeSetAction] = []
 
@@ -485,45 +524,127 @@
                 DaqNodeSetAction(
                     self._daq,
                     f"/{self.serial}/qachannels/{output.channel}/generator/single",
                     1,
                 )
             )
 
-            measurement_delay = output.scheduler_port_delay
-            measurement_delay += output.port_delay or 0.0
+        return nodes_to_initialize_output
 
-            measurement_delay_rounded = (
-                delay_to_rounded_samples(
-                    channel=output.channel,
-                    dev_repr=self.dev_repr,
-                    delay=measurement_delay,
-                    sample_frequency_hz=SAMPLE_FREQUENCY_HZ,
-                    granularity_samples=DELAY_NODE_GRANULARITY_SAMPLES,
-                    max_node_delay_samples=DELAY_NODE_MAX_SAMPLES,
-                )
-                / SAMPLE_FREQUENCY_HZ
-            )
+    def collect_prepare_nt_step_nodes(
+        self, attributes: DeviceAttributesView, recipe_data: RecipeData
+    ) -> list[DaqNodeAction]:
+        nodes_to_set = super().collect_prepare_nt_step_nodes(attributes, recipe_data)
 
-            nodes_to_initialize_output.append(
-                DaqNodeSetAction(
-                    self._daq,
-                    f"/{self.serial}/qachannels/{output.channel}/generator/delay",
-                    measurement_delay_rounded,
+        acquisition_type = RtExecutionInfo.get_acquisition_type(
+            recipe_data.rt_execution_infos
+        )
+
+        for ch in range(self._channels):
+            [synth_cf], synth_cf_updated = attributes.resolve(
+                keys=[(AttributeName.QA_CENTER_FREQ, ch)]
+            )
+            if synth_cf_updated:
+                nodes_to_set.append(
+                    DaqNodeSetAction(
+                        self._daq,
+                        f"/{self.serial}/qachannels/{ch}/centerfreq",
+                        synth_cf,
+                    )
                 )
+
+            [out_amp], out_amp_updated = attributes.resolve(
+                keys=[(AttributeName.QA_OUT_AMPLITUDE, ch)]
             )
-            nodes_to_initialize_output.append(
-                DaqNodeSetAction(
-                    self._daq,
-                    f"/{self.serial}/qachannels/{output.channel}/spectroscopy/envelope/delay",
-                    measurement_delay_rounded,
+            if out_amp_updated:
+                nodes_to_set.append(
+                    DaqNodeSetAction(
+                        self._daq,
+                        f"/{self.serial}/qachannels/{ch}/oscs/0/gain",
+                        out_amp,
+                    )
                 )
+
+            [
+                output_scheduler_port_delay,
+                output_port_delay,
+            ], output_updated = attributes.resolve(
+                keys=[
+                    (AttributeName.OUTPUT_SCHEDULER_PORT_DELAY, ch),
+                    (AttributeName.OUTPUT_PORT_DELAY, ch),
+                ]
             )
+            output_delay = (
+                0.0
+                if output_scheduler_port_delay is None
+                else output_scheduler_port_delay + (output_port_delay or 0.0)
+            )
+            set_output = output_updated and output_scheduler_port_delay is not None
+
+            [
+                input_scheduler_port_delay,
+                input_port_delay,
+            ], input_updated = attributes.resolve(
+                keys=[
+                    (AttributeName.INPUT_SCHEDULER_PORT_DELAY, ch),
+                    (AttributeName.INPUT_PORT_DELAY, ch),
+                ]
+            )
+            measurement_delay = (
+                0.0
+                if input_scheduler_port_delay is None
+                else input_scheduler_port_delay + (input_port_delay or 0.0)
+            )
+            set_input = input_updated and input_scheduler_port_delay is not None
 
-        return nodes_to_initialize_output
+            base_channel_path = f"/{self.serial}/qachannels/{ch}"
+            if acquisition_type == AcquisitionType.SPECTROSCOPY:
+                output_delay_path = f"{base_channel_path}/spectroscopy/envelope/delay"
+                meas_delay_path = f"{base_channel_path}/spectroscopy/delay"
+            else:
+                output_delay_path = f"{base_channel_path}/generator/delay"
+                meas_delay_path = f"{base_channel_path}/readout/integration/delay"
+                measurement_delay += output_delay
+                set_input = set_input or set_output
+
+            if set_output:
+                output_delay_rounded = (
+                    delay_to_rounded_samples(
+                        channel=ch,
+                        dev_repr=self.dev_repr,
+                        delay=output_delay,
+                        sample_frequency_hz=SAMPLE_FREQUENCY_HZ,
+                        granularity_samples=DELAY_NODE_GRANULARITY_SAMPLES,
+                        max_node_delay_samples=DELAY_NODE_MAX_SAMPLES,
+                    )
+                    / SAMPLE_FREQUENCY_HZ
+                )
+                nodes_to_set.append(
+                    DaqNodeSetAction(self._daq, output_delay_path, output_delay_rounded)
+                )
+
+            if set_input:
+                measurement_delay_rounded = (
+                    delay_to_rounded_samples(
+                        channel=ch,
+                        dev_repr=self.dev_repr,
+                        delay=measurement_delay,
+                        sample_frequency_hz=SAMPLE_FREQUENCY_HZ,
+                        granularity_samples=DELAY_NODE_GRANULARITY_SAMPLES,
+                        max_node_delay_samples=DELAY_NODE_MAX_SAMPLES,
+                    )
+                    / SAMPLE_FREQUENCY_HZ
+                )
+                nodes_to_set.append(
+                    DaqNodeSetAction(
+                        self._daq, meas_delay_path, measurement_delay_rounded
+                    )
+                )
+
+        return nodes_to_set
 
     def prepare_upload_binary_wave(
         self,
         filename: str,
         waveform: npt.ArrayLike,
         awg_index: int,
         wave_index: int,
@@ -611,42 +732,20 @@
         dev_output: IO.Data,
         measurement: Measurement.Data | None,
         device_uid: str,
         recipe_data: RecipeData,
     ):
         _logger.debug("%s: Setting measurement mode to 'Readout'.", self.dev_repr)
 
-        measurement_delay = dev_output.scheduler_port_delay
-        measurement_delay += dev_output.port_delay or 0.0
-        measurement_delay += dev_input.scheduler_port_delay
-        measurement_delay += dev_input.port_delay or 0.0
-
-        measurement_delay_rounded = (
-            delay_to_rounded_samples(
-                channel=dev_output.channel,
-                dev_repr=self.dev_repr,
-                delay=measurement_delay,
-                sample_frequency_hz=SAMPLE_FREQUENCY_HZ,
-                granularity_samples=DELAY_NODE_GRANULARITY_SAMPLES,
-                max_node_delay_samples=DELAY_NODE_MAX_SAMPLES,
-            )
-            / SAMPLE_FREQUENCY_HZ
-        )
-
         nodes_to_set_for_readout_mode = [
             DaqNodeSetAction(
                 self._daq,
                 f"/{self.serial}/qachannels/{measurement.channel}/readout/integration/length",
                 measurement.length,
             ),
-            DaqNodeSetAction(
-                self._daq,
-                f"/{self.serial}/qachannels/{measurement.channel}/readout/integration/delay",
-                measurement_delay_rounded,
-            ),
         ]
 
         max_len = 4096
         for (
             integrator_allocation
         ) in recipe_data.recipe.experiment.integrator_allocations:
             if (
@@ -695,42 +794,22 @@
         return nodes_to_set_for_readout_mode
 
     def _configure_spectroscopy_mode_nodes(
         self, dev_input: IO.Data, measurement: Measurement.Data | None
     ):
         _logger.debug("%s: Setting measurement mode to 'Spectroscopy'.", self.dev_repr)
 
-        measurement_delay = dev_input.scheduler_port_delay
-        measurement_delay += dev_input.port_delay or 0.0
-
-        measurement_delay_rounded = (
-            delay_to_rounded_samples(
-                channel=dev_input.channel,
-                dev_repr=self.dev_repr,
-                delay=measurement_delay,
-                sample_frequency_hz=SAMPLE_FREQUENCY_HZ,
-                granularity_samples=DELAY_NODE_GRANULARITY_SAMPLES,
-                max_node_delay_samples=DELAY_NODE_MAX_SAMPLES,
-            )
-            / SAMPLE_FREQUENCY_HZ
-        )
-
         nodes_to_set_for_spectroscopy_mode = [
             DaqNodeSetAction(
                 self._daq,
                 f"/{self.serial}/qachannels/{measurement.channel}/spectroscopy/trigger/channel",
                 32 + measurement.channel,
             ),
             DaqNodeSetAction(
                 self._daq,
-                f"/{self.serial}/qachannels/{measurement.channel}/spectroscopy/delay",
-                measurement_delay_rounded,
-            ),
-            DaqNodeSetAction(
-                self._daq,
                 f"/{self.serial}/qachannels/{measurement.channel}/spectroscopy/length",
                 measurement.length,
             ),
         ]
 
         return nodes_to_set_for_spectroscopy_mode
 
@@ -738,35 +817,14 @@
         self, initialization: Initialization.Data, recipe_data: RecipeData
     ):
         nodes_to_initialize_measurement = []
 
         acquisition_type = RtExecutionInfo.get_acquisition_type(
             recipe_data.rt_execution_infos
         )
-        center_frequencies = {}
-        ios = (initialization.outputs or []) + (initialization.inputs or [])
-        for idx, io in enumerate(ios):
-            if io.lo_frequency is not None:
-                if io.channel in center_frequencies:
-                    prev_io_idx = center_frequencies[io.channel]
-                    if ios[prev_io_idx].lo_frequency != io.lo_frequency:
-                        raise LabOneQControllerException(
-                            f"{self.dev_repr}: Local oscillator frequency mismatch between IOs "
-                            f"sharing channel {io.channel}: "
-                            f"{ios[prev_io_idx].lo_frequency} != {io.lo_frequency}"
-                        )
-                else:
-                    center_frequencies[io.channel] = idx
-                    nodes_to_initialize_measurement.append(
-                        DaqNodeSetAction(
-                            self._daq,
-                            f"/{self.serial}/qachannels/{io.channel}/centerfreq",
-                            io.lo_frequency,
-                        )
-                    )
 
         for measurement in initialization.measurements:
             nodes_to_initialize_measurement.append(
                 DaqNodeSetAction(
                     self._daq,
                     f"/{self.serial}/qachannels/{measurement.channel}/mode",
                     0 if acquisition_type == AcquisitionType.SPECTROSCOPY else 1,
```

## laboneq/controller/devices/device_shfsg.py

```diff
@@ -1,18 +1,23 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from __future__ import annotations
 
 import logging
-from typing import Any
+from typing import Any, Iterator
 
 import numpy
 from numpy import typing as npt
 
+from laboneq.controller.attribute_value_tracker import (
+    AttributeName,
+    DeviceAttribute,
+    DeviceAttributesView,
+)
 from laboneq.controller.communication import (
     CachingStrategy,
     DaqNodeAction,
     DaqNodeSetAction,
 )
 from laboneq.controller.devices.device_zi import DeviceZI
 from laboneq.controller.recipe_1_4_0 import IO, Initialization
@@ -189,23 +194,81 @@
         self, acquisition_type: AcquisitionType
     ) -> dict[str, Any]:
         conditions: dict[str, Any] = {}
         for awg_index in self._allocated_awgs:
             conditions[f"/{self.serial}/sgchannels/{awg_index}/awg/enable"] = 0
         return conditions
 
+    def _validate_initialization(self, initialization: Initialization.Data):
+        super()._validate_initialization(initialization)
+        outputs = initialization.outputs or []
+        for output in outputs:
+            if output.port_delay is not None:
+                if output.port_delay != 0:
+                    raise LabOneQControllerException(
+                        f"{self.dev_repr}'s output does not support port delay"
+                    )
+                _logger.info(
+                    "%s's output port delay should be set to None, not 0", self.dev_repr
+                )
+
+    def pre_process_attributes(
+        self,
+        initialization: Initialization.Data,
+    ) -> Iterator[DeviceAttribute]:
+        yield from super().pre_process_attributes(initialization)
+
+        center_frequencies: dict[int, IO.Data] = {}
+
+        def get_synth_idx(io: IO.Data):
+            if io.channel >= self._channels:
+                raise LabOneQControllerException(
+                    f"{self.dev_repr}: Attempt to configure channel {io.channel + 1} on a device "
+                    f"with {self._channels} channels. Verify your device setup."
+                )
+            synth_idx = self._output_to_synth_map[io.channel]
+            prev_io = center_frequencies.get(synth_idx)
+            if prev_io is None:
+                center_frequencies[synth_idx] = io
+            elif prev_io.lo_frequency != io.lo_frequency:
+                raise LabOneQControllerException(
+                    f"{self.dev_repr}: Local oscillator frequency mismatch between outputs "
+                    f"{prev_io.channel} and {io.channel} sharing synthesizer {synth_idx}: "
+                    f"{prev_io.lo_frequency} != {io.lo_frequency}"
+                )
+            return synth_idx
+
+        ios = initialization.outputs or []
+        for io in ios:
+            if io.lo_frequency is None:
+                raise LabOneQControllerException(
+                    f"{self.dev_repr}: Local oscillator for channel {io.channel} is required, "
+                    f"but is not provided."
+                )
+            if io.port_mode is None or io.port_mode == "RF":
+                yield DeviceAttribute(
+                    name=AttributeName.SG_SYNTH_CENTER_FREQ,
+                    index=get_synth_idx(io),
+                    value_or_param=io.lo_frequency,
+                )
+            else:
+                yield DeviceAttribute(
+                    name=AttributeName.SG_DIG_MIXER_CENTER_FREQ,
+                    index=io.channel,
+                    value_or_param=io.lo_frequency,
+                )
+
     def collect_initialization_nodes(
         self, device_recipe_data: DeviceRecipeData, initialization: Initialization.Data
     ) -> list[DaqNodeSetAction]:
         _logger.debug("%s: Initializing device...", self.dev_repr)
 
         nodes_to_initialize_output: list[DaqNodeSetAction] = []
 
         outputs = initialization.outputs or []
-
         for output in outputs:
             self._warn_for_unsupported_param(
                 output.offset is None or output.offset == 0,
                 "voltage_offsets",
                 output.channel,
             )
             self._warn_for_unsupported_param(
@@ -242,23 +305,14 @@
                 DaqNodeSetAction(
                     self._daq,
                     f"/{self.serial}/sgchannels/{output.channel}/awg/modulation/enable",
                     1 if output.modulation else 0,
                 )
             )
 
-            if output.port_delay is not None:
-                if output.port_delay != 0:
-                    raise LabOneQControllerException(
-                        f"{self.dev_repr}'s output does not support port delay"
-                    )
-                _logger.info(
-                    "%s's output port delay should be set to None, not 0", self.dev_repr
-                )
-
             if output.marker_mode is None or output.marker_mode == "TRIGGER":
                 nodes_to_initialize_output.append(
                     DaqNodeSetAction(
                         self.daq,
                         f"/{self.serial}/sgchannels/{output.channel}/marker/source",
                         0,
                     )
@@ -281,14 +335,24 @@
                 DaqNodeSetAction(
                     self.daq,
                     f"/{self.serial}/sgchannels/{output.channel}/trigger/delay",
                     0.0,
                 )
             )
 
+            nodes_to_initialize_output.append(
+                DaqNodeSetAction(
+                    self._daq,
+                    f"/{self.serial}/sgchannels/{output.channel}/output/rflfpath",
+                    1  # RF
+                    if output.port_mode is None or output.port_mode == "RF"
+                    else 0,  # LF
+                )
+            )
+
         osc_selects = {
             ch: osc.index for osc in self._allocated_oscs for ch in osc.channels
         }
         for ch, osc_idx in osc_selects.items():
             nodes_to_initialize_output.append(
                 DaqNodeSetAction(
                     self._daq,
@@ -308,14 +372,47 @@
                     self._daq,
                     f"/{self.serial}/sgchannels/{ch}/sines/{osc_idx}/phaseshift",
                     0,
                 )
             )
         return nodes_to_initialize_output
 
+    def collect_prepare_nt_step_nodes(
+        self, attributes: DeviceAttributesView, recipe_data: RecipeData
+    ) -> list[DaqNodeAction]:
+        nodes_to_set = super().collect_prepare_nt_step_nodes(attributes, recipe_data)
+
+        for synth_idx in set(self._output_to_synth_map):
+            [synth_cf], synth_cf_updated = attributes.resolve(
+                keys=[(AttributeName.SG_SYNTH_CENTER_FREQ, synth_idx)]
+            )
+            if synth_cf_updated:
+                nodes_to_set.append(
+                    DaqNodeSetAction(
+                        self._daq,
+                        f"/{self.serial}/synthesizers/{synth_idx}/centerfreq",
+                        synth_cf,
+                    )
+                )
+
+        for ch in range(self._channels):
+            [dig_mixer_cf], dig_mixer_cf_updated = attributes.resolve(
+                keys=[(AttributeName.SG_DIG_MIXER_CENTER_FREQ, ch)]
+            )
+            if dig_mixer_cf_updated:
+                nodes_to_set.append(
+                    DaqNodeSetAction(
+                        self._daq,
+                        f"/{self.serial}/sgchannels/{ch}/digitalmixer/centerfreq",
+                        dig_mixer_cf,
+                    )
+                )
+
+        return nodes_to_set
+
     def prepare_upload_binary_wave(
         self,
         filename: str,
         waveform: npt.ArrayLike,
         awg_index: int,
         wave_index: int,
         acquisition_type: AcquisitionType,
@@ -324,79 +421,14 @@
             self._daq,
             f"/{self.serial}/sgchannels/{awg_index}/awg/waveform/waves/{wave_index}",
             waveform,
             filename=filename,
             caching_strategy=CachingStrategy.NO_CACHE,
         )
 
-    def collect_awg_before_upload_nodes(
-        self, initialization: Initialization.Data, recipe_data: RecipeData
-    ):
-        nodes_to_initialize_measurement = []
-
-        center_frequencies: dict[int, IO.Data] = {}
-
-        def get_synth_idx(io: IO.Data):
-            if io.channel >= self._channels:
-                raise LabOneQControllerException(
-                    f"{self.dev_repr}: Attempt to configure channel {io.channel + 1} on a device "
-                    f"with {self._channels} channels. Verify your device setup."
-                )
-            synth_idx = self._output_to_synth_map[io.channel]
-            prev_io = center_frequencies.get(synth_idx)
-            if prev_io is None:
-                center_frequencies[synth_idx] = io
-            elif prev_io.lo_frequency != io.lo_frequency:
-                raise LabOneQControllerException(
-                    f"{self.dev_repr}: Local oscillator frequency mismatch between outputs "
-                    f"{prev_io.channel} and {io.channel} sharing synthesizer {synth_idx}: "
-                    f"{prev_io.lo_frequency} != {io.lo_frequency}"
-                )
-            return synth_idx
-
-        ios = initialization.outputs or []
-        for io in ios:
-            if io.lo_frequency is None:
-                raise LabOneQControllerException(
-                    f"{self.dev_repr}: Local oscillator for channel {io.channel} is required, "
-                    f"but is not provided."
-                )
-            if io.port_mode is None or io.port_mode == "RF":
-                nodes_to_initialize_measurement.append(
-                    DaqNodeSetAction(
-                        self._daq,
-                        f"/{self.serial}/sgchannels/{io.channel}/output/rflfpath",
-                        1,  # RF
-                    )
-                )
-                nodes_to_initialize_measurement.append(
-                    DaqNodeSetAction(
-                        self._daq,
-                        f"/{self.serial}/synthesizers/{get_synth_idx(io)}/centerfreq",
-                        io.lo_frequency,
-                    )
-                )
-            else:
-                nodes_to_initialize_measurement.append(
-                    DaqNodeSetAction(
-                        self._daq,
-                        f"/{self.serial}/sgchannels/{io.channel}/output/rflfpath",
-                        0,  # LF
-                    )
-                )
-                nodes_to_initialize_measurement.append(
-                    DaqNodeSetAction(
-                        self._daq,
-                        f"/{self.serial}/sgchannels/{io.channel}/digitalmixer/centerfreq",
-                        io.lo_frequency,
-                    )
-                )
-
-        return nodes_to_initialize_measurement
-
     def collect_trigger_configuration_nodes(
         self, initialization: Initialization.Data, recipe_data: RecipeData
     ) -> list[DaqNodeAction]:
         _logger.debug("Configuring triggers...")
         self._wait_for_awgs = True
         self._emit_trigger = False
```

## laboneq/controller/devices/device_uhfqa.py

```diff
@@ -4,14 +4,18 @@
 from __future__ import annotations
 
 import logging
 from typing import Any
 
 import numpy as np
 
+from laboneq.controller.attribute_value_tracker import (
+    AttributeName,
+    DeviceAttributesView,
+)
 from laboneq.controller.communication import (
     CachingStrategy,
     DaqNodeAction,
     DaqNodeGetAction,
     DaqNodeSetAction,
 )
 from laboneq.controller.devices.device_zi import DeviceZI, delay_to_rounded_samples
@@ -278,14 +282,27 @@
                 self.dev_repr,
                 label,
                 io.channel,
                 io.range,
                 range_list,
             )
 
+    def _validate_initialization(self, initialization: Initialization.Data):
+        super()._validate_initialization(initialization)
+        outputs = initialization.outputs or []
+        for output in outputs:
+            if output.port_delay is not None:
+                if output.port_delay != 0:
+                    raise LabOneQControllerException(
+                        f"{self.dev_repr}'s output does not support port delay"
+                    )
+                _logger.debug(
+                    "%s's output port delay should be set to None, not 0", self.dev_repr
+                )
+
     def collect_initialization_nodes(
         self, device_recipe_data: DeviceRecipeData, initialization: Initialization.Data
     ) -> list[DaqNodeAction]:
         _logger.debug("%s: Initializing device...", self.dev_repr)
 
         nodes_to_initialize_output: list[DaqNodeAction] = []
 
@@ -337,35 +354,61 @@
                 DaqNodeSetAction(
                     self._daq,
                     f"/{self.serial}/awgs/{awg_idx}/outputs/{output.channel}/mode",
                     1 if output.modulation else 0,
                 )
             )
 
-            if output.port_delay is not None:
-                if output.port_delay != 0:
-                    raise LabOneQControllerException(
-                        f"{self.dev_repr}'s output does not support port delay"
-                    )
-                _logger.debug(
-                    "%s's output port delay should be set to None, not 0", self.dev_repr
-                )
-
             if output.range is not None:
                 self._validate_range(output, is_out=True)
                 nodes_to_initialize_output.append(
                     DaqNodeSetAction(
                         self._daq,
                         f"/{self.serial}/sigouts/{output.channel}/range",
                         output.range,
                     )
                 )
 
         return nodes_to_initialize_output
 
+    def collect_prepare_nt_step_nodes(
+        self, attributes: DeviceAttributesView, recipe_data: RecipeData
+    ) -> list[DaqNodeAction]:
+        nodes_to_set = super().collect_prepare_nt_step_nodes(attributes, recipe_data)
+
+        for ch in range(self._channels):
+            [scheduler_port_delay, port_delay], updated = attributes.resolve(
+                keys=[
+                    (AttributeName.INPUT_SCHEDULER_PORT_DELAY, ch),
+                    (AttributeName.INPUT_PORT_DELAY, ch),
+                ]
+            )
+            if not updated or scheduler_port_delay is None:
+                continue
+
+            measurement_delay = scheduler_port_delay + (port_delay or 0.0)
+            measurement_delay_rounded = delay_to_rounded_samples(
+                channel=ch,
+                dev_repr=self.dev_repr,
+                delay=measurement_delay,
+                sample_frequency_hz=SAMPLE_FREQUENCY_HZ,
+                granularity_samples=DELAY_NODE_GRANULARITY_SAMPLES,
+                max_node_delay_samples=DELAY_NODE_MAX_SAMPLES,
+            )
+
+            nodes_to_set.append(
+                DaqNodeSetAction(
+                    self._daq,
+                    f"/{self.serial}/qas/0/delay",
+                    measurement_delay_rounded,
+                )
+            )
+
+        return nodes_to_set
+
     def _adjust_frequency(self, freq):
         # To make the phase correct on the UHFQA (q leading i channel by 90 degrees)
         # we need to flip the sign of the oscillator frequency
         return freq * -1.0
 
     def _configure_standard_mode_nodes(
         self,
@@ -532,36 +575,14 @@
                 DaqNodeSetAction(
                     self._daq,
                     f"/{self.serial}/qas/0/integration/length",
                     measurement.length,
                 )
             )
 
-            if inputs is None or len(inputs) == 0:
-                measurement_delay = 0.0
-            else:
-                dev_input = inputs[0]
-                measurement_delay = dev_input.scheduler_port_delay
-                measurement_delay += dev_input.port_delay or 0.0
-
-            measurement_delay_rounded = delay_to_rounded_samples(
-                channel=dev_input.channel,
-                dev_repr=self.dev_repr,
-                delay=measurement_delay,
-                sample_frequency_hz=SAMPLE_FREQUENCY_HZ,
-                granularity_samples=DELAY_NODE_GRANULARITY_SAMPLES,
-                max_node_delay_samples=DELAY_NODE_MAX_SAMPLES,
-            )
-
-            nodes_to_initialize_measurement.append(
-                DaqNodeSetAction(
-                    self._daq, f"/{self.serial}/qas/0/delay", measurement_delay_rounded
-                )
-            )
-
             nodes_to_initialize_measurement.append(
                 DaqNodeSetAction(
                     self._daq, f"/{self.serial}/qas/0/integration/trigger/channel", 7
                 )
             )
 
         for dev_input in inputs or []:
```

## laboneq/controller/devices/device_zi.py

```diff
@@ -11,23 +11,28 @@
 import re
 import time
 from abc import ABC
 from copy import deepcopy
 from dataclasses import dataclass
 from enum import Enum
 from math import floor
-from typing import TYPE_CHECKING, Any
+from typing import TYPE_CHECKING, Any, Iterator
 from weakref import ReferenceType, ref
 
 import numpy as np
 import zhinst.core
 import zhinst.utils
 from numpy import typing as npt
-from zhinst.core.errors import CoreError as LabOneCoreError  # pylint: disable=E0401
+from zhinst.core.errors import CoreError as LabOneCoreError
 
+from laboneq.controller.attribute_value_tracker import (  # pylint: disable=E0401
+    AttributeName,
+    DeviceAttribute,
+    DeviceAttributesView,
+)
 from laboneq.controller.communication import (
     CachingStrategy,
     DaqNodeAction,
     DaqNodeGetAction,
     DaqNodeSetAction,
     DaqWrapper,
 )
@@ -39,15 +44,15 @@
 )
 from laboneq.controller.recipe_processor import (
     AwgConfig,
     AwgKey,
     DeviceRecipeData,
     RecipeData,
 )
-from laboneq.controller.util import LabOneQControllerException, SweepParamsTracker
+from laboneq.controller.util import LabOneQControllerException
 from laboneq.core.types.enums.acquisition_type import AcquisitionType
 from laboneq.core.types.enums.averaging_mode import AveragingMode
 
 if TYPE_CHECKING:
     from laboneq.core.types import CompiledExperiment
 
 
@@ -253,14 +258,48 @@
     def is_follower(self):
         # Treat standalone devices as followers
         return len(self._uplinks) > 0 or self.is_standalone()
 
     def is_standalone(self):
         return len(self._uplinks) == 0 and len(self._downlinks) == 0
 
+    def _validate_initialization(self, initialization: Initialization.Data):
+        pass
+
+    def pre_process_attributes(
+        self,
+        initialization: Initialization.Data,
+    ) -> Iterator[DeviceAttribute]:
+        self._validate_initialization(initialization)
+        outputs = initialization.outputs or []
+        for output in outputs:
+            yield DeviceAttribute(
+                name=AttributeName.OUTPUT_SCHEDULER_PORT_DELAY,
+                index=output.channel,
+                value_or_param=output.scheduler_port_delay,
+            )
+            yield DeviceAttribute(
+                name=AttributeName.OUTPUT_PORT_DELAY,
+                index=output.channel,
+                value_or_param=output.port_delay,
+            )
+
+        inputs = initialization.inputs or []
+        for input in inputs:
+            yield DeviceAttribute(
+                name=AttributeName.INPUT_SCHEDULER_PORT_DELAY,
+                index=input.channel,
+                value_or_param=input.scheduler_port_delay,
+            )
+            yield DeviceAttribute(
+                name=AttributeName.INPUT_PORT_DELAY,
+                index=input.channel,
+                value_or_param=input.port_delay,
+            )
+
     def collect_initialization_nodes(
         self, device_recipe_data: DeviceRecipeData, initialization: Initialization.Data
     ) -> list[DaqNodeAction]:
         return []
 
     def collect_trigger_configuration_nodes(
         self, initialization: Initialization.Data, recipe_data: RecipeData
@@ -407,17 +446,14 @@
             if same_id_osc.frequency != osc_param.frequency:
                 raise LabOneQControllerException(
                     f"{self.dev_repr}: ambiguous frequency in recipe for oscillator "
                     f"'{osc_param.id}': {same_id_osc.frequency} != {osc_param.frequency}"
                 )
             same_id_osc.channels.add(osc_param.channel)
 
-    def allocate_params(self, initialization: Initialization.Data):
-        pass
-
     def configure_feedback(self, recipe_data: RecipeData) -> list[DaqNodeAction]:
         return []
 
     def configure_acquisition(
         self,
         awg_key: AwgKey,
         awg_config: AwgConfig,
@@ -611,30 +647,33 @@
                     f"Requested source: {source}, actual: {sourceactual}, status: {status}, "
                     f"expected frequency: {expected_freqs}, actual: {freq}"
                 )
 
     def _adjust_frequency(self, freq):
         return freq
 
-    def collect_prepare_sweep_step_nodes_for_param(
-        self, sweep_params_tracker: SweepParamsTracker
+    def collect_prepare_nt_step_nodes(
+        self, attributes: DeviceAttributesView, recipe_data: RecipeData
     ) -> list[DaqNodeAction]:
         nodes_to_set: list[DaqNodeAction] = []
         for osc in self._allocated_oscs:
-            if osc.param in sweep_params_tracker.updated_params():
-                freq_value = self._adjust_frequency(
-                    sweep_params_tracker.get_param(osc.param)
-                )
-                nodes_to_set.append(
-                    DaqNodeSetAction(
-                        self._daq,
-                        self._make_osc_path(next(iter(osc.channels)), osc.index),
-                        freq_value,
+            osc_index = recipe_data.oscillator_ids.index(osc.id)
+            [osc_freq], updated = attributes.resolve(
+                keys=[(AttributeName.OSCILLATOR_FREQ, osc_index)]
+            )
+            if updated:
+                osc_freq_adjusted = self._adjust_frequency(osc_freq)
+                for ch in osc.channels:
+                    nodes_to_set.append(
+                        DaqNodeSetAction(
+                            self._daq,
+                            self._make_osc_path(ch, osc.index),
+                            osc_freq_adjusted,
+                        )
                     )
-                )
         return nodes_to_set
 
     @staticmethod
     def _contains_only_zero_or_one(a):
         if a is None:
             return True
         return not np.any(a * (1 - a))
@@ -1015,15 +1054,15 @@
             # Currently is returns 0 for all nodes...
             check_errors(all_errors[error_node], self.dev_repr)
 
     def collect_reset_nodes(self) -> list[DaqNodeAction]:
         return [DaqNodeSetAction(self._daq, f"/{self.serial}/raw/error/clear", 1)]
 
 
-class ErrorLevels(Enum):
+class DeviceErrorSeverity(Enum):
     info = 0
     warning = 1
     error = 2
 
 
 def check_errors(errors, serial):
     collected_messages = []
@@ -1034,15 +1073,15 @@
         for message in error_vector["messages"]:
             if message["code"] == "AWGRUNTIMEERROR" and message["params"][0] == 1:
                 awg_core = int(message["attribs"][0])
                 program_counter = int(message["params"][1])
                 collected_messages.append(
                     f"Gap detected on AWG core {awg_core}, program counter {program_counter}"
                 )
-            if message["severity"] >= ErrorLevels.error.value:
+            if message["severity"] >= DeviceErrorSeverity.error.value:
                 collected_messages.append(message["message"])
     if len(collected_messages) > 0:
         all_messages = "\n".join(collected_messages)
         raise LabOneQControllerException(
             f"An error happened on device {serial} during the execution of the experiment. "
             f"Error messages:\n{all_messages}"
         )
```

## laboneq/dsl/calibration/amplifier_pump.py

```diff
@@ -1,14 +1,13 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from __future__ import annotations
 
 from dataclasses import dataclass, field
-from typing import Optional, Union
 
 from laboneq.dsl.parameter import Parameter
 
 amplifier_pump_id = 0
 
 
 def amplifier_pump_id_generator():
@@ -21,14 +20,14 @@
 @dataclass(init=True, repr=True, order=True)
 class AmplifierPump:
     """Data object containing settings for the Parametric Pump Controller."""
 
     #: Unique identifier. If left blank, a new unique ID will be generated.
     uid: str = field(default_factory=amplifier_pump_id_generator)
 
-    pump_freq: Optional[Union[float, Parameter]] = None
-    pump_power: Optional[Union[float, Parameter]] = None
+    pump_freq: float | Parameter | None = None
+    pump_power: float | Parameter | None = None
     cancellation: bool = True
     alc_engaged: bool = True
     use_probe: bool = False
-    probe_frequency: Optional[Union[float, Parameter]] = None
-    probe_power: Optional[Union[float, Parameter]] = None
+    probe_frequency: float | Parameter | None = None
+    probe_power: float | Parameter | None = None
```

## laboneq/dsl/calibration/oscillator.py

```diff
@@ -1,14 +1,15 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from __future__ import annotations
 
+import warnings
 from dataclasses import dataclass, field
-from typing import TYPE_CHECKING, Union
+from typing import TYPE_CHECKING
 
 from laboneq.dsl.enums import CarrierType, ModulationType
 
 if TYPE_CHECKING:
     from laboneq.dsl import Parameter
 
 oscillator_id = 0
@@ -21,25 +22,38 @@
     return retval
 
 
 @dataclass(init=True, repr=True, order=True)
 class Oscillator:
     """
     This oscillator class represents an oscillator on a `PhysicalChannel`.
-    All pulses played on any signal line attached to this physcical channel will be modulated with the oscillator assigned to that channel.
+    All pulses played on any signal line attached to this physical channel will be modulated with the oscillator assigned to that channel.
 
     Args:
         frequency (float): The frequency in units of Hz
         modulation_type (ModulationType): The modulation type (`ModulationType.SOFTWARE` or `ModulationType.HARDWARE`).
             When choosing a HARDWARE oscillator, a digital oscillator on the instrument will be used to modulate the output signal,
             while the choice SOFTWARE will lead to waveform being modulated in software before upload to the instruments.
             The default `ModulationType.AUTO` currently falls back to `ModulationType.Software`.
-        carrier_type (CarrierType): The carrier type, defaults to radio frequency (`CarrierType.RF`)
+        carrier_type (CarrierType): Deprecated: The carrier type, defaults to radio frequency (`CarrierType.RF`)
+
+            .. deprecated:: 2.7
+
+                Argument has no functionality.
     """
 
     uid: str = field(default_factory=oscillator_uid_generator)
-    frequency: Union[float, Parameter] = field(default=None)
+    frequency: float | Parameter | None = field(default=None)
     modulation_type: ModulationType = field(default=ModulationType.AUTO)
-    carrier_type: CarrierType = field(default=CarrierType.RF)
+    carrier_type: CarrierType = field(default=None)
+
+    def __post_init__(self):
+        if self.carrier_type is not None:
+            warnings.warn(
+                "`Oscillator` argument `carrier_type` will be removed in the future versions. It has no functionality.",
+                FutureWarning,
+            )
+        else:
+            self.carrier_type = CarrierType.RF
 
     def __hash__(self):
         return hash(self.uid)
```

## laboneq/dsl/calibration/signal_calibration.py

```diff
@@ -1,61 +1,63 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
+from __future__ import annotations
+
 from dataclasses import dataclass
-from typing import Optional, Union
 
 from laboneq.core.types.enums import PortMode
 from laboneq.dsl.calibration.amplifier_pump import AmplifierPump
 from laboneq.dsl.calibration.mixer_calibration import MixerCalibration
 from laboneq.dsl.calibration.observable import Observable
 from laboneq.dsl.calibration.oscillator import Oscillator
 from laboneq.dsl.calibration.precompensation import Precompensation
+from laboneq.dsl.parameter import Parameter
 
 
 @dataclass(init=False, order=True)
 class SignalCalibration(Observable):
     """Dataclass containing all calibration parameters
     and settings related to a :class:`~.LogicalSignal`.
     """
 
     #: The oscillator assigned to the :class:`~.LogicalSignal`
     #: - determines the frequency and type of modulation for any pulses played back on this line.
-    oscillator: Optional[Oscillator]
+    oscillator: Oscillator | None
     #: The local oscillator assigned to the :class:`~.LogicalSignal`
     #: - sets the center frequency of the playback - only relevant on SHFSG, SHFQA and SHFQC
-    local_oscillator: Optional[Oscillator]
+    local_oscillator: Oscillator | None
     #: Settings to enable the optional mixer calibration correction
     #: - only applies to IQ signals on HDAWG
-    mixer_calibration: Optional[MixerCalibration]
+    mixer_calibration: MixerCalibration | None
     #: Settings to enable signal distortion precomensation
     #: - only applies to HDAWG instruments
-    precompensation: Optional[Precompensation]
+    precompensation: Precompensation | None
     #: An optional delay of all output on this signal.
     #: Works by setting delay nodes on the instruments, and will not be visible in the pulse sheet.
     #: Not currently available on SHFSG output channels.
-    port_delay: Optional[float]
+    port_delay: float | Parameter | None
     #: Allows to switch between amplified high-frequency mode (PortMode.RF)
     #: and direct low_frequency mode (PortMode.LF) on SHFSG output channels.
-    port_mode: Optional[PortMode]
+    port_mode: PortMode | None
     #: Defines an additional global delay on this signal line.
     #: Will be mapped to the waveforms and sequencer code emitted for this logical signal,
     #: and thus visible in the pulse sheet viewer.
-    delay_signal: Optional[float]
+    delay_signal: float | None
     #: Allows to set a constant voltage offset on individual rf lines on the HDAWG.
-    voltage_offset: Optional[float]
+    voltage_offset: float | None
     #: The output or input range setting for the logical signal
-    range: Union[int, float, None]
+    range: int | float | None
     #: The state discrimination threshold
     #: - only relevant for acquisition type signals on UHFQA and SHFQA/SHFQC
-    threshold: Optional[float]
+    threshold: float | None
     #: (Not Implemented) Amplitude multiplying all waveforms played on a signal line
-    amplitude: Optional[float]
-    #: (Not Implemented) Parametric Pump Controller settings
-    amplifier_pump: Optional[AmplifierPump]
+    amplitude: float | Parameter | None
+    #: Parametric Pump Controller settings
+    amplifier_pump: AmplifierPump | None
 
     def __init__(
         self,
         amplitude=None,
         delay_signal=None,
         local_oscillator=None,
         voltage_offset=None,
@@ -92,15 +94,15 @@
             )
 
     @property
     def mixer_calibration(self) -> MixerCalibration:
         return self._mixer_calibration
 
     @mixer_calibration.setter
-    def mixer_calibration(self, value: Optional[MixerCalibration]):
+    def mixer_calibration(self, value: MixerCalibration | None):
         if value is self._mixer_calibration:
             return
 
         if self._mixer_calibration is not None:
             self._mixer_calibration.has_changed().disconnect(
                 self._mixer_calibration_changed_callback
             )
@@ -116,15 +118,15 @@
         self.has_changed().fire("mixer_calibration", calibration)
 
     @property
     def precompensation(self) -> Precompensation:
         return self._precompensation
 
     @precompensation.setter
-    def precompensation(self, value: Optional[Precompensation]):
+    def precompensation(self, value: Precompensation | None):
         if value is self._precompensation:
             return
 
         if self._precompensation is not None:
             self._precompensation.has_changed().disconnect(
                 self._precompensation_changed_callback
             )
```

## laboneq/dsl/device/io_units/physical_channel.py

```diff
@@ -20,14 +20,15 @@
     "local_oscillator",
     "port_delay",
     "port_mode",
     "range",
     "voltage_offset",
     "mixer_calibration",
     "precompensation",
+    "amplitude",
 )
 
 
 @dataclass(init=False, repr=False, order=True)
 class PhysicalChannel(Calibratable):
     #: Unique identifier. Typically of the form
     # ``<device uid>/<channel name>``.
```

## laboneq/dsl/experiment/experiment.py

```diff
@@ -834,15 +834,15 @@
             visitor(section)
             self.accept_section_visitor(visitor, section.sections)
 
     def match_local(
         self,
         handle: str,
         uid: str = None,
-        play_after: str | List[str] | type(None) = None,
+        play_after: str | list[str] | None = None,
     ):
         """Define a section which switches between different child sections based
         on a QA measurement on an SHFQC.
 
         Match needs to open a scope in the following way::
 
             with exp.match_local(...):
@@ -862,15 +862,15 @@
             self, uid=uid, handle=handle, play_after=play_after, local=True
         )
 
     def match_global(
         self,
         handle: str,
         uid: str = None,
-        play_after: str | List[str] | type(None) = None,
+        play_after: str | list[str] | None = None,
     ):
         """Define a section which switches between different child sections based
         on a QA measurement via the PQSC.
 
         Match needs to open a scope in the following way::
 
             with exp.match_global(...):
@@ -916,15 +916,15 @@
         def __exit__(self, exc_type, exc_val, exc_tb):
             self.exp._pop_and_add_section()
 
     def match(
         self,
         handle: str,
         uid: str = None,
-        play_after: str | List[str] | type(None) = None,
+        play_after: str | list[str] | None = None,
     ):
         """Define a section which switches between different child sections based
         on a QA measurement.
 
         The feedback path (local, or global, via PQSC) is chosen automatically.
 
         Match needs to open a scope in the following way::
```

## laboneq/dsl/serialization/serializer.py

```diff
@@ -99,15 +99,15 @@
             "laboneq.dsl.calibration.oscillator",
             "laboneq.dsl.calibration.signal_calibration",
             "laboneq.dsl.result.results",
             "laboneq.dsl.parameter",
             "laboneq.dsl.calibration",
             "laboneq.dsl.device",
             "laboneq.dsl.device.qubits",
-            "laboneq.dsl.device.quops",
+            "laboneq.dsl.device.quantum_operations",
             "laboneq.dsl.device.server",
             "laboneq.dsl.device.servers.data_server",
             "laboneq.core.types.enums",
             "laboneq.core.types.compiled_experiment",
             "laboneq.dsl.device.io_units.logical_signal",
             "laboneq.dsl.device.io_units.physical_channel",
             "laboneq.dsl.device.instruments",
```

## laboneq/openqasm3/expression.py

```diff
@@ -5,15 +5,15 @@
 
 import math
 import operator
 from typing import Iterable, Optional, Type
 
 from openqasm3 import ast
 
-from .namespace import ClassicalRef, Namespace, QubitRef
+from .namespace import ClassicalRef, NamespaceNest, QubitRef
 from .openqasm_error import OpenQasmException
 
 binary_ops = {
     "+": operator.add,
     "-": operator.sub,
     "*": operator.mul,
     "/": operator.truediv,
@@ -46,15 +46,15 @@
 
     if duration.unit == ast.TimeUnit.dt:
         raise OpenQasmException("Backend-dependent duration not supported")
     return val * scale[duration.unit]
 
 
 def _eval_expression(
-    expression: ast.Expression | ast.DiscreteSet | None, namespace: Namespace
+    expression: ast.Expression | ast.DiscreteSet | None, namespace: NamespaceNest
 ):
     if expression is None:
         return None
     if isinstance(
         expression,
         (
             ast.IntegerLiteral,
@@ -151,30 +151,35 @@
         "Failed to evaluate expression", getattr(expression, "span", None)
     )
 
 
 def eval_expression(
     expression: Optional[ast.Expression],
     *,
-    namespace: Namespace = None,
+    namespace: NamespaceNest = None,
     type: Type = None,
 ):
     if namespace is None:
-        namespace = Namespace()
-    retval = _eval_expression(expression, namespace)
+        namespace = NamespaceNest()
+    try:
+        retval = _eval_expression(expression, namespace)
+    except OpenQasmException:
+        raise
+    except Exception as e:
+        raise OpenQasmException(str(e), mark=expression.span) from e
 
     if type is not None and not isinstance(retval, type):
         raise OpenQasmException(
             f"Expected expression of type {type}, got {type(retval)}", expression.span
         )
     return retval
 
 
 def eval_lvalue(
-    node, namespace: Namespace
+    node, namespace: NamespaceNest
 ) -> ClassicalRef | QubitRef | list[ClassicalRef] | list[QubitRef]:
     if isinstance(node, ast.Identifier):
         if node.name in constants:
             raise OpenQasmException("Cannot alias a constant", node.span)
         try:
             return namespace.lookup(node.name)
         except KeyError as e:
```

## laboneq/openqasm3/gate_store.py

```diff
@@ -9,16 +9,19 @@
 
 
 class GateStore:
     def __init__(self):
         self.gates: Dict[Tuple[str, Tuple[str, ...]], Callable[..., Section]] = {}
         self.gate_map: Dict[str, str] = {}
 
-    def lookup_gate(self, name: str, qubits: Tuple[str, ...], args=()) -> Section:
-        return self.gates[(self.gate_map.get(name, name), qubits)](*args)
+    def lookup_gate(
+        self, name: str, qubits: Tuple[str, ...], args=(), kwargs=None
+    ) -> Section:
+        kwargs = kwargs or {}
+        return self.gates[(self.gate_map.get(name, name), qubits)](*args, **kwargs)
 
     def map_gate(self, qasm_name: str, l1q_name: str):
         """Define mapping from qasm gate name to L1Q gate name."""
         self.gate_map[qasm_name] = l1q_name
 
     def register_gate_section(self, name, qubits, section_factory):
         """Register a LabOne Q section factory as a gate."""
```

## laboneq/openqasm3/namespace.py

```diff
@@ -19,29 +19,31 @@
     """A reference to a classical value"""
 
     value: Any
     canonical_name: str
 
 
 class Namespace:
-    def __init__(self, parent: Optional = None):
-        self.parent = parent
-        self.local_scope = {}
+    def __init__(self, toplevel: Optional[bool] = True):
+        self.toplevel = toplevel
+        self.local_scope: dict[str, Any] = {}
 
     def declare_qubit(self, name: str) -> QubitRef:
-        if self.parent is not None:
+        if self.toplevel is False:
             raise OpenQasmException("Qubit declaration is illegal in this scope")
 
         if name not in self.local_scope:
             self.local_scope[name] = QubitRef(name)
         else:
             raise OpenQasmException(f"Name '{name}' already exists")
         return self.local_scope[name]
 
-    def declare_classical_value(self, name: str, value: Any) -> ClassicalRef:
+    def declare_classical_value(
+        self, name: str, value: Any
+    ) -> ClassicalRef | list[ClassicalRef]:
         # For now, classical values are not resources which we 'allocate'.
         # Instead we treat them as references (to Python objects).
         return self.declare_reference(name, value)
 
     def declare_reference(
         self, name: str, value: Any = None
     ) -> ClassicalRef | list[ClassicalRef]:
@@ -51,16 +53,35 @@
                 self.local_scope[name] = value
             else:
                 self.local_scope[name] = ClassicalRef(value, name)
         else:
             raise OpenQasmException(f"Name '{name}' already exists")
         return self.local_scope[name]
 
+
+class NamespaceNest:
+    """A stack of namespaces, with the the current namespace on top.
+
+    The attribute `current` can be used to add variables to the deepest nesting.
+    """
+
+    def __init__(self):
+        self._nesting = [Namespace(toplevel=True)]
+
+    def open(self) -> None:
+        self._nesting.append(Namespace(toplevel=False))
+
+    def close(self) -> None:
+        self._nesting.pop()
+
+    @property
+    def current(self) -> Namespace:
+        return self._nesting[-1]
+
     def lookup(
         self, name: str
-    ) -> QubitRef | ClassicalRef | list[ClassicalRef] | list[QubitRef]:
-        if name in self.local_scope:
-            return self.local_scope[name]
-        elif self.parent is not None:
-            return self.parent.lookup(name)
+    ) -> QubitRef | ClassicalRef | list[QubitRef] | list[ClassicalRef]:
+        for namespace in reversed(self._nesting):
+            if name in namespace.local_scope:
+                return namespace.local_scope[name]
         else:
             raise KeyError(name)
```

## laboneq/openqasm3/openqasm3_importer.py

```diff
@@ -1,37 +1,38 @@
 # Copyright 2023 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
-from __future__ import annotations
+from __future__ import annotations  # noqa: I001
 
 import operator
-from collections import deque
 from contextlib import contextmanager
-from typing import Optional, TextIO, Union
+from typing import Any, Optional, TextIO, Union
 
 import openpulse
-import openpulse.ast as ast
+from openpulse import ast
 
 import openqasm3.visitor
 from laboneq.dsl.experiment import Section
 from laboneq.dsl.experiment.utils import id_generator
 from laboneq.openqasm3.expression import eval_expression, eval_lvalue
 from laboneq.openqasm3.gate_store import GateStore
-from laboneq.openqasm3.namespace import Namespace, QubitRef
+from laboneq.openqasm3.namespace import ClassicalRef, NamespaceNest, QubitRef
 from laboneq.openqasm3.openqasm_error import OpenQasmException
-from laboneq.openqasm3.signal_store import SignalStore
+from laboneq.openqasm3.signal_store import SignalLineType, SignalStore
 
 ALLOWED_NODE_TYPES = {
     # quantum logic
     ast.Box,
     ast.DelayInstruction,
     ast.QuantumBarrier,
     ast.QuantumGate,
     ast.QuantumReset,
     ast.QubitDeclaration,
+    ast.QuantumMeasurementStatement,
+    ast.QuantumMeasurement,
     # auxiliary
     ast.AliasStatement,
     ast.ClassicalDeclaration,
     ast.Concatenation,
     ast.DiscreteSet,
     ast.Identifier,
     ast.Include,
@@ -59,72 +60,73 @@
     ast.FloatType,
     ast.BoolType,
     ast.DurationType,
     ast.BitType,
 }
 
 
-class AllowedNodeTypesVisitor(openqasm3.visitor.QASMVisitor):
-    def generic_visit(self, node: ast.QASMNode, context=None):
+class MeasurementResult:
+    pass
+
+
+class _AllowedNodeTypesVisitor(openqasm3.visitor.QASMVisitor):
+    def generic_visit(self, node: ast.QASMNode, context: Optional[Any] = None) -> None:
         if type(node) not in ALLOWED_NODE_TYPES:
-            raise OpenQasmException(
-                f"Node type {type(node)} not yet supported", mark=node.span
-            )
+            msg = f"Node type {type(node)} not yet supported"
+            raise OpenQasmException(msg, mark=node.span)
         super().generic_visit(node, context)
 
 
 class OpenQasm3Importer:
     def __init__(
         self, gate_store: GateStore, signal_store: Optional[SignalStore] = None
     ):
         self.gate_store = gate_store
         self.signal_store = (
             signal_store if signal_store is not None else SignalStore({})
         )
-        self.scoped_variables = deque([Namespace()])
+        self.scope = NamespaceNest()
 
     def __call__(
         self,
         text: Optional[str] = None,
         file: Optional[TextIO] = None,
         filename: Optional[str] = None,
         stream: Optional[TextIO] = None,
     ) -> Section:
         if [arg is not None for arg in [text, file, filename, stream]].count(True) != 1:
-            raise ValueError(
-                "Must specify exactly one of text, file, filename, or stream"
-            )
+            msg = "Must specify exactly one of text, file, filename, or stream"
+            raise ValueError(msg)
         if filename:
             with open(filename, "r") as f:
                 return self._import_text(f.read())
         elif file:
             return self._import_text(file.read())
         elif stream:
             return self._import_text(stream.read())
         else:
             return self._import_text(text)
 
     def _import_text(self, text) -> Section:
         tree = openpulse.parse(text)
         assert isinstance(tree, ast.Program)
-        AllowedNodeTypesVisitor().visit(tree, None)
+        _AllowedNodeTypesVisitor().visit(tree, None)
         try:
             root = self.transpile(tree, uid_hint="root")
         except OpenQasmException as e:
             e.source = text
             raise
         self.signal_store.leftover_raise()
         return root
 
     @contextmanager
     def _new_scope(self):
-        parent_namespace = self.scoped_variables[-1]
-        self.scoped_variables.append(Namespace(parent=parent_namespace))
+        self.scope.open()
         yield
-        self.scoped_variables.pop()
+        self.scope.close()
 
     def transpile(self, parent: Union[ast.Program, ast.Box], uid_hint="") -> Section:
         sect = Section(uid=id_generator(uid_hint))
 
         try:
             body = parent.statements
         except AttributeError:
@@ -149,214 +151,246 @@
                     subsect = self._handle_barrier(child)
                 elif isinstance(child, ast.QuantumReset):
                     subsect = self._handle_quantum_reset(child)
                 elif isinstance(child, ast.DelayInstruction):
                     subsect = self._handle_delay_instruction(child)
                 elif isinstance(child, ast.ClassicalAssignment):
                     self._handle_assignment(child)
+                elif isinstance(child, ast.QuantumMeasurementStatement):
+                    subsect = self._handle_measurement(child)
                 else:
-                    raise OpenQasmException(
-                        f"Statement type {type(child)} not supported",
-                        mark=child.span,
-                    )
-                if subsect is not None:
-                    sect.add(subsect)
+                    msg = f"Statement type {type(child)} not supported"
+                    raise OpenQasmException(msg, mark=child.span)
             except OpenQasmException:
                 raise
             except Exception as e:
+                msg = "Failed to process statement"
                 mark = child.span
-                raise OpenQasmException("Failed to process statement", mark) from e
+                raise OpenQasmException(msg, mark) from e
+            if subsect is not None:
+                sect.add(subsect)
 
         return sect
 
     def _handle_qubit_declaration(self, statement: ast.QubitDeclaration):
         name = statement.qubit.name
         try:
             if statement.size is not None:
                 try:
                     size = eval_expression(
-                        statement.size, namespace=self.scoped_variables[-1], type=int
+                        statement.size, namespace=self.scope, type=int
                     )
                 except Exception:
-                    raise OpenQasmException(
-                        "Qubit declaration size must evaluate to an integer.",
-                        mark=statement.span,
-                    )
+                    msg = "Qubit declaration size must evaluate to an integer."
+                    raise OpenQasmException(msg, mark=statement.span)
 
                 # declare the individual qubits...
                 qubits = [
-                    self.scoped_variables[-1].declare_qubit(f"{name}[{i}]")
+                    self.scope.current.declare_qubit(f"{name}[{i}]")
                     for i in range(size)
                 ]
                 # ... as well as a list aliasing them
-                self.scoped_variables[-1].declare_reference(name, qubits)
+                self.scope.current.declare_reference(name, qubits)
             else:
-                self.scoped_variables[-1].declare_qubit(name)
+                self.scope.current.declare_qubit(name)
         except ValueError as e:
             raise OpenQasmException(str(e), mark=statement.span) from e
         except OpenQasmException as e:
             e.mark = statement.span
             raise
 
     def _handle_classical_declaration(self, statement: ast.ClassicalDeclaration):
         name = statement.identifier.name
         if isinstance(statement.type, ast.BitType):
-            value = eval_expression(
-                statement.init_expression, namespace=self.scoped_variables[-1], type=int
-            )
+            if statement.init_expression is not None:
+                value = eval_expression(
+                    statement.init_expression,
+                    namespace=self.scope,
+                    type=int,
+                )
+            else:
+                value = None
             size = statement.type.size
             if size is not None:
-                size = eval_expression(
-                    size, namespace=self.scoped_variables[-1], type=int
-                )
+                size = eval_expression(size, namespace=self.scope, type=int)
 
                 # declare the individual bits...
                 bits = [
-                    self.scoped_variables[-1].declare_classical_value(
-                        f"{name}[{i}]", value=bool((value >> i) & 1)
+                    self.scope.current.declare_classical_value(
+                        f"{name}[{i}]",
+                        value=bool((value >> i) & 1) if value is not None else None,
                     )
                     for i in range(size)
                 ]
                 # ... as well as a list aliasing them
-                self.scoped_variables[-1].declare_reference(name, bits)
+                self.scope.current.declare_reference(name, bits)
             else:
-                self.scoped_variables[-1].declare_classical_value(name, value)
+                self.scope.current.declare_classical_value(name, value)
         else:
-            value = eval_expression(
-                statement.init_expression, namespace=self.scoped_variables[-1]
-            )
-            self.scoped_variables[-1].declare_classical_value(name, value)
+            value = eval_expression(statement.init_expression, namespace=self.scope)
+            self.scope.current.declare_classical_value(name, value)
 
     def _handle_alias_statement(self, statement: ast.AliasStatement):
         if not isinstance(statement.target, ast.Identifier):
-            raise OpenQasmException(
-                "Alias target must be an identifier.", mark=statement.span
-            )
+            msg = "Alias target must be an identifier."
+            raise OpenQasmException(msg, mark=statement.span)
         name = statement.target.name
 
         try:
-            value = eval_lvalue(statement.value, namespace=self.scoped_variables[-1])
+            value = eval_lvalue(statement.value, namespace=self.scope)
         except OpenQasmException:
             raise
         except Exception as e:
-            raise OpenQasmException(
-                "Invalid alias value", mark=statement.value.span
-            ) from e
+            msg = "Invalid alias value"
+            raise OpenQasmException(msg, mark=statement.value.span) from e
         try:
-            self.scoped_variables[-1].declare_reference(name, value)
+            self.scope.current.declare_reference(name, value)
         except OpenQasmException as e:
             e.mark = statement.span
             raise
 
     def _handle_quantum_gate(self, statement: ast.QuantumGate):
         args = tuple(eval_expression(arg) for arg in statement.arguments)
         if statement.modifiers or statement.duration:
-            raise OpenQasmException(
-                "Gate modifiers and duration not yet supported.",
-                mark=statement.span,
-            )
+            msg = "Gate modifiers and duration not yet supported."
+            raise OpenQasmException(msg, mark=statement.span)
         if not isinstance(statement.name, ast.Identifier):
-            raise OpenQasmException(
-                "Gate name must be an identifier.", mark=statement.span
-            )
+            msg = "Gate name must be an identifier."
+            raise OpenQasmException(msg, mark=statement.span)
         name = statement.name.name
         qubit_names = []
         for q in statement.qubits:
-            qubit = eval_expression(q, namespace=self.scoped_variables[-1])
+            qubit = eval_expression(q, namespace=self.scope)
             try:
                 qubit_names.append(qubit.canonical_name)
             except AttributeError as e:
-                raise OpenQasmException(
-                    f"Qubit expected, got '{type(qubit).__name__}'", mark=q.span
-                ) from e
+                msg = f"Qubit expected, got '{type(qubit).__name__}'"
+                raise OpenQasmException(msg, mark=q.span) from e
         qubit_names = tuple(qubit_names)
         try:
             return self.gate_store.lookup_gate(name, qubit_names, args=args)
         except KeyError as e:
-            raise OpenQasmException(
-                f"Gate '{name}' for qubit(s) {qubit_names} not found.",
-                mark=statement.span,
-            ) from e
+            msg = f"Gate '{name}' for qubit(s) {qubit_names} not found."
+            raise OpenQasmException(msg, mark=statement.span) from e
 
     def _handle_box(self, statement: ast.Box):
         if statement.duration:
             raise ValueError("Box duration not yet supported.")
         with self._new_scope():
             return self.transpile(statement, uid_hint="box")
 
     def _handle_barrier(self, statement: ast.QuantumBarrier):
         sect = Section(uid=id_generator("barrier"), length=0)
         reserved_qubits = [
-            eval_expression(qubit, namespace=self.scoped_variables[-1]).canonical_name
+            eval_expression(qubit, namespace=self.scope).canonical_name
             for qubit in statement.qubits
         ]
         reserved_signals = set()
         if not reserved_qubits:  # get all signals
             for each_qubit_signals in self.signal_store.user_map.values():
                 for signal in each_qubit_signals:
                     reserved_signals.add(signal.exp_signal)
         for qubit in reserved_qubits:  # get only selected signals
             for signal in self.signal_store.user_map[qubit]:
                 reserved_signals.add(signal.exp_signal)
         for exp_signal in reserved_signals:
             sect.reserve(exp_signal)
         return sect
 
-    def _handle_include(self, statement: ast.Include):
+    def _handle_include(self, statement: ast.Include) -> None:
         if statement.filename != "stdgates.inc":
-            raise OpenQasmException(
-                f"Only 'stdgates.inc' is supported for include, found '{statement.filename}'.",
-                mark=statement.span,
-            )
+            msg = f"Only 'stdgates.inc' is supported for include, found '{statement.filename}'."
+            raise OpenQasmException(msg, mark=statement.span)
 
     def _handle_quantum_reset(self, statement: ast.QuantumReset):
         # Although ``qubits`` is plural, only a single qubit is allowed.
         qubit_name = eval_expression(
-            statement.qubits, namespace=self.scoped_variables[-1]
+            statement.qubits, namespace=self.scope
         ).canonical_name
         try:
             return self.gate_store.lookup_gate("reset", (qubit_name,))
         except KeyError as e:
-            raise OpenQasmException(
-                f"Reset gate for qubit '{qubit_name}' not found.",
-                mark=statement.span,
-            ) from e
+            msg = f"Reset gate for qubit '{qubit_name}' not found."
+            raise OpenQasmException(msg, mark=statement.span) from e
 
     def _handle_delay_instruction(self, statement: ast.DelayInstruction):
         qubits = statement.qubits
-        duration = eval_expression(
-            statement.duration, namespace=self.scoped_variables[-1], type=float
-        )
+        duration = eval_expression(statement.duration, namespace=self.scope, type=float)
         qubit_names = [
-            eval_expression(qubit, namespace=self.scoped_variables[-1]).canonical_name
+            eval_expression(qubit, namespace=self.scope).canonical_name
             for qubit in qubits
         ]
         qubits_str = "_".join(qubit_names)
         delay_section = Section(
             uid=id_generator(f"{qubits_str}_delay_{duration * 1e9:.0f}ns")
         )
         for qubit in qubit_names:
-            # todo: TBD only delaying drive signal?
-            delay_section.delay(signal=f"{qubit}_drive", time=duration)
+            for signal in self.signal_store.user_map[qubit]:
+                if signal.signal_type != SignalLineType.DRIVE:
+                    continue
+                delay_section.delay(signal.exp_signal, time=duration)
         return delay_section
 
     def _handle_assignment(self, statement: ast.ClassicalAssignment):
-        lvalue = eval_lvalue(statement.lvalue, self.scoped_variables[-1])
+        lvalue = eval_lvalue(statement.lvalue, namespace=self.scope)
         if isinstance(lvalue, QubitRef):
-            raise OpenQasmException(f"Cannot assign to qubit '{lvalue.canonical_name}'")
+            msg = f"Cannot assign to qubit '{lvalue.canonical_name}'"
+            raise OpenQasmException(msg)
         if isinstance(lvalue, list):
             raise OpenQasmException("Cannot assign to arrays")
         ops = {
             "=": lambda a, b: b,
             "*=": operator.mul,
             "/=": operator.truediv,
             "+=": operator.add,
             "-=": operator.sub,
         }
         try:
             op = ops[statement.op.name]
         except KeyError as e:
-            raise OpenQasmException(
-                "Unsupported assignment operator", mark=statement.span
-            ) from e
-        rvalue = eval_expression(statement.rvalue, namespace=self.scoped_variables[-1])
+            msg = "Unsupported assignment operator"
+            raise OpenQasmException(msg, mark=statement.span) from e
+        rvalue = eval_expression(statement.rvalue, namespace=self.scope)
         lvalue.value = op(lvalue.value, rvalue)
+
+    def _handle_measurement(self, statement: ast.QuantumMeasurementStatement):
+        qubits = eval_expression(statement.measure.qubit, namespace=self.scope)
+        bits = statement.target
+        if bits is None:
+            raise OpenQasmException(
+                "Measurement must be assigned to a classical bit", mark=statement.span
+            )
+        bits = eval_lvalue(statement.target, namespace=self.scope)
+        if isinstance(qubits, list):
+            err_msg = None
+            if not isinstance(bits, list):
+                err_msg = "Both bits and qubits must be either scalar or registers."
+            if not len(bits) == len(qubits):
+                err_msg = "Bit and qubit registers must be same length"
+            if err_msg is not None:
+                raise OpenQasmException(err_msg, statement.span)
+        else:
+            bits = [bits]
+            qubits = [qubits]
+
+        assert all(isinstance(q, QubitRef) for q in qubits)
+        assert all(isinstance(b, ClassicalRef) for b in bits)
+
+        # Build the section
+        s = Section(uid=id_generator("measurement"))
+        for q, b in zip(qubits, bits):
+            handle_name = b.canonical_name
+            qubit_name = q.canonical_name
+            try:
+                gate_section = self.gate_store.lookup_gate(
+                    "measure", (qubit_name,), kwargs={"handle": handle_name}
+                )
+            except KeyError as e:
+                raise OpenQasmException(
+                    f"No measurement operation defined for qubit '{qubit_name}'",
+                    mark=statement.span,
+                ) from e
+            s.add(gate_section)
+
+            # Set the bit to a special value to disallow compile time arithmetic
+            b.value = MeasurementResult()
+        return s
```

## laboneq/openqasm3/signal_store.py

```diff
@@ -7,44 +7,45 @@
 from typing import Dict, List, Tuple
 
 
 class SignalLineType(Enum):
     """An enum for the different signal line types."""
 
     MEASURE = "measure"
+    CONTROL = "flux"
     ACQUIRE = "acquire"
     DRIVE = "drive"
 
 
 @dataclass
 class Signal:
     signal_type: SignalLineType
     exp_signal: str
 
 
 class SignalStore:
     def __init__(self, exp_map):
-        self.exp_map: Dict[str, str] = deepcopy(exp_map)
+        self._exp_map: Dict[str, str] = deepcopy(exp_map)
         self.user_map: Dict[str, List[Signal]] = {}
 
     def leftover_raise(self):
         """Raise an exception if not all experiment signals have been used up."""
-        if self.exp_map:
-            raise ValueError(f"Unassigned experiment signals: {self.exp_map.keys()}")
+        if self._exp_map:
+            raise ValueError(f"Unassigned experiment signals: {self._exp_map.keys()}")
 
     def register_signal_group(
         self,
         qubit: str,
         signals: List[Tuple[SignalLineType, str]],
     ):
         """Register the LabOne Q logical signal group belonging to a QASM qubit."""
         for pair in signals:
             suggested_signal = pair[1]
             try:
-                self.exp_map.pop(suggested_signal)
+                self._exp_map.pop(suggested_signal)
             except KeyError as e:
                 raise ValueError(
                     f"Invalid signal: '{suggested_signal}' not found in experiment signals or already used.",
                 ) from e
         self.user_map[qubit] = [
             Signal(signal_type, exp_signal) for (signal_type, exp_signal) in signals
         ]
```

## Comparing `laboneq/dsl/device/quops.py` & `laboneq/dsl/device/quantum_operations.py`

 * *Files 10% similar despite different names*

```diff
@@ -13,28 +13,39 @@
 QuantumElementTuple = Tuple[QuantumElement, ...]
 
 
 class QuantumOperation:
     """A class for quantum operations."""
 
     def __init__(
-        self, uid: Optional[str] = None, lookup: Optional[Dict[str, Section]] = None
+        self,
+        uid: Optional[str] = None,
+        operation_map: Optional[
+            Dict[Union[QuantumElement, QuantumElementTuple], Section]
+        ] = None,
     ) -> None:
         """
-        Initializes a new QuantumOperation object.
+        Initialize a new QuantumOperation object.
 
         Args:
             uid: A unique identifier for the quantum operation.
-            lookup: A dictionary of sections associated with the uids of quantum elements.
+            lookup: A dictionary of sections associated with quantum elements.
         """
         if uid is None:
             self.uid = uuid.uuid4().hex
         else:
             self.uid = uid
-        self.lookup = {} if lookup is None else lookup
+        self.operation_map = (
+            {}
+            if operation_map is None
+            else {
+                k if isinstance(k, str) else self._get_uids(k): v
+                for k, v in operation_map.items()
+            }
+        )
 
     def _get_uids(self, elements: Union[QuantumElement, QuantumElementTuple]) -> str:
         if isinstance(elements, QuantumElement):
             return elements.uid
         else:
             return "/".join(elem.uid for elem in elements)
 
@@ -45,19 +56,19 @@
     ):
         """Add a section to the quantum operation.
 
         Args:
             elements: The quantum element(s) to which the section is associated.
             section: The section to add to the quantum operation.
         """
-        self.lookup[self._get_uids(elements)] = section
+        self.operation_map[self._get_uids(elements)] = section
 
     def __call__(self, elements: QuantumElementTuple):
         try:
-            section = self.lookup[self._get_uids(elements)]
+            section = self.operation_map[self._get_uids(elements)]
         except KeyError:
             raise ValueError("No section defined for the given quantum elements")
         return section
 
     @classmethod
     def load(cls, filename: Union[str, bytes, "PathLike"]) -> "QuantumOperation":
         """
@@ -76,21 +87,23 @@
         Args:
             filename: The name of the JSON file to save the QuantumOperation object.
         """
         Serializer.to_json_file(self, filename)
 
     @staticmethod
     def from_dict(tuneup: Dict[Union[QuantumElement, QuantumElementTuple], Section]):
-        """Creates a QuantumOperation object from a dictionary.
+        """Create a QuantumOperation object from a dictionary.
 
         Args:
             tuneup: A dictionary of quantum elements and sections.
         """
         op = QuantumOperation()
         for elements, section in tuneup.items():
             op.add_operation(elements, section)
         return op
 
     def __eq__(self, __value: object) -> bool:
         if isinstance(__value, QuantumOperation):
-            return self.lookup == __value.lookup and self.uid == __value.uid
+            return (
+                self.operation_map == __value.operation_map and self.uid == __value.uid
+            )
         return False
```

## Comparing `laboneq-2.6.0.dist-info/LICENSE` & `laboneq-2.7.0.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `laboneq-2.6.0.dist-info/METADATA` & `laboneq-2.7.0.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: laboneq
-Version: 2.6.0
+Version: 2.7.0
 Summary: Zurich Instruments LabOne Q software framework for quantum computing control
 Author-email: Zurich Instruments Development Team <info@zhinst.com>
 License: Apache 2.0
 Project-URL: Homepage, https://github.com/zhinst/laboneq
 Keywords: quantum,sdk,zhinst
 Classifier: Environment :: Console
 Classifier: Intended Audience :: Developers
```

## Comparing `laboneq-2.6.0.dist-info/RECORD` & `laboneq-2.7.0.dist-info/RECORD`

 * *Files 5% similar despite different names*

```diff
@@ -1,85 +1,85 @@
-laboneq/VERSION.txt,sha256=4zzPZSfduHstyJSxfdhGIGxdGDNHENJT9_Nm8sRAP-A,5
-laboneq/__init__.py,sha256=xb0bbmhv6-zquNTknTRURgHIU1VG11TJVgz5svWkvzI,306
+laboneq/VERSION.txt,sha256=-XIIQTG4wuupM59byVz22FGD6xsa-HxyPxLEhUL4REU,5
+laboneq/__init__.py,sha256=OrHAykevakOnwEAHajG2qdB1PxEirEowKhDX2V5cHKA,239
 laboneq/_token.py,sha256=D2wS1TbZ6-CzF73l5kd6Wilcm18IPyymygB6VakHyRc,2829
 laboneq/_utils.py,sha256=4TRw9Hv192vqcPwcPDBsqXcdAGhIOvH_D24mZdyfZok,928
 laboneq/_version.py,sha256=zaxeCShR641vx5bH27_dVdirv71bA2i9ciFcH4A2krE,238
-laboneq/simple.py,sha256=LfAlXPh-d8Z3n5LwwzhQCYlvAObkj1RIkqjR9V9MOcE,1525
+laboneq/simple.py,sha256=aaLhD2w9pE3e89JUJVdiezHUuwsh4q2U5qx6bFTfJc0,1538
 laboneq/_observability/__init__.py,sha256=rcsPn8d52W6G9ZGkI8TPrEtwSJ2WbQN_Urc2DiIaUDg,184
 laboneq/_observability/tracing/__init__.py,sha256=rEFK2BFplAYa8ZHwQpiaVKv9EaSDrUWKHBplg-AmzGE,538
 laboneq/_observability/tracing/_noop_tracer.py,sha256=z7yhOOaTwCbWTQVQJ3i0SPCYsvd2wdbngf7ygoPJVCE,893
 laboneq/_observability/tracing/_tracer.py,sha256=vqgWJiy17tpzSMIOFXgkXHg9oQotbM8Jd-cWjNyVvk0,2309
 laboneq/compiler/__init__.py,sha256=PQOZ0TyWFSH0U7NJZnaYtO62iQW7DGgEV5KQD0lyKVw,444
 laboneq/compiler/fastlogging.py,sha256=SCJykQ5V_qvRPvWkkDZOqFexmazzhW-fbP2jkglOUkA,204
 laboneq/compiler/qccs-schema_2_5_0.json,sha256=YauxP1Z39AGXi5lUB7eKRLsRxsllayxNlzeyHQBGOSY,22524
 laboneq/compiler/remote.py,sha256=Fyb1RaWU-JBudPSv3LN56yQhYndduOchiai2brTE1WA,666
 laboneq/compiler/code_generator/__init__.py,sha256=s8ihwbuWxGpCAMjnsBXQ0kdoXGqT-B8doSsk850gQA0,654
 laboneq/compiler/code_generator/analyze_events.py,sha256=xA7nDePKXzxQHeR4m95cOmN0CBTR6KY5T3mccT7bBM8,18645
 laboneq/compiler/code_generator/analyze_playback.py,sha256=dcRfLFAltlXyGbQIGtb_YAl-8sdkx4GLAYf37a837pE,26665
-laboneq/compiler/code_generator/code_generator.py,sha256=Gtok3LuvDbwTiXI_FL56tewR55ld7mFu31JfPi_VsaI,71375
+laboneq/compiler/code_generator/code_generator.py,sha256=kEqAX0xdjbmMffH6JkoCnIFeyKnhJxhyAYIJO_uOTvI,72652
 laboneq/compiler/code_generator/command_table_tracker.py,sha256=jXD4Ep8SMIgS_DNqgdfnGujma-oRhRZcvFcIa-AkAXc,4026
 laboneq/compiler/code_generator/compressor.py,sha256=sIbtla_ju0NM1FL1oWGV7SMyxpZoNKwMzHKvbyb3Ut8,2880
 laboneq/compiler/code_generator/feedback_register_allocator.py,sha256=iXuwHFa9g5YQriNqLHXoHIzkBanyR8XnD9C0mw6sPQU,1414
 laboneq/compiler/code_generator/interval_calculator.py,sha256=7dyk02iUdPHyzS4DU6JvkTKn36yWpUE2lhvUynY0aYQ,10355
 laboneq/compiler/code_generator/measurement_calculator.py,sha256=w15OoQt0yXR4k3V2nvJT2CoNGtrPDeCiPoQazk5TZFc,17825
-laboneq/compiler/code_generator/sampled_event_handler.py,sha256=yBaaIp7PH6vTVTkDAFqnt65iO_d9hSnI00_XJMl6JTU,30333
+laboneq/compiler/code_generator/sampled_event_handler.py,sha256=f5GlIAKgVDSST-nS7MpR93im0LvlbjpOYPOlZa0tLzA,30380
 laboneq/compiler/code_generator/seq_c_generator.py,sha256=oZ4-TzXQmrfYToNnRe-GPQa0A9ctlE4y2JsWj2yf918,19239
 laboneq/compiler/code_generator/seqc_tracker.py,sha256=bZPvLecbCXYH02TlTL7KkhOv6NXoMHOmS_kLZE9WzO8,6333
-laboneq/compiler/code_generator/signatures.py,sha256=2Ez4Tw_IbmQ2pwkpVMoWKsAuyy6h0mpRIWVUNVMb6-E,7741
+laboneq/compiler/code_generator/signatures.py,sha256=A36tVPg7xJkTNPtvc0cF8KSCYYHVtfphyQqjqpQN0xs,9915
 laboneq/compiler/code_generator/utils.py,sha256=KJtRJg6wE8FPALrG4B8H7GRZa_7WqOrXroWW8kgSdBA,3500
-laboneq/compiler/code_generator/wave_compressor.py,sha256=AUIDhuBIh-h6VahdjnWehAlEvQjVPvik4-punkWxjSo,3737
+laboneq/compiler/code_generator/wave_compressor.py,sha256=BoCX_EAg6TN8VnTMPJIcP4JWX8QzhZnl4EMYw1m-yh8,7697
 laboneq/compiler/code_generator/wave_index_tracker.py,sha256=700LQq60nX9Btcn9bj2SDn674qRmsxy_Nz6yy0qx1Y0,1476
 laboneq/compiler/common/__init__.py,sha256=FVNdflrImH-vSDDkoz05G5rNUUDB7mf4sgoOZHttkBQ,77
 laboneq/compiler/common/awg_info.py,sha256=djhjq5t8JruHRi9hKk4rtBVH4KfMWRkuamcypmhP6WA,1093
 laboneq/compiler/common/awg_sampled_event.py,sha256=Sz21qx__YTdkpeBAhpfyVgT4ED1zUR4OiIn6GTnNVvw,1926
 laboneq/compiler/common/awg_signal_type.py,sha256=aXiZ_K-yaG1pPPUMh5IpOXn2rQJngQnTzwqP1LExtT8,480
 laboneq/compiler/common/compiler_settings.py,sha256=1Rr42CsHTmKtykUgOQuu0H56jCV4cGHAgoMb0nVuPFM,4015
 laboneq/compiler/common/device_type.py,sha256=QK48fFIH9-bcO25j6l4d-WrG1kpyapoTEZvHLzzsffI,6058
-laboneq/compiler/common/event_type.py,sha256=VJiiMUTbZHTetjnBPEPyoSVREczPAjTTxA7d7GbjN9M,1532
+laboneq/compiler/common/event_type.py,sha256=uFnpVFeUU9m-dEBgNzmo3Sj8SSoLwFOj9i_Wk37Kk2M,1624
 laboneq/compiler/common/play_wave_type.py,sha256=9olrAuZqSSq-3fDpUCwbH2IC2F1mYaZ64H_NG0J6eXM,229
 laboneq/compiler/common/pulse_parameters.py,sha256=zhIljy4MHaBGSFYR-28ksDetM39C5p006e8flU21ZWE,580
 laboneq/compiler/common/signal_obj.py,sha256=UBrf78oTS_MyH3YaPZudNqDvFJzoY5_Fw-MJIUcOXVA,2594
 laboneq/compiler/common/trigger_mode.py,sha256=PfV_HskFUlk99bsngdjYz-b137e2qA6e1TNqA0Bjvbs,400
 laboneq/compiler/experiment_access/__init__.py,sha256=mb9ULouZiKIforKo2d458L6pvf0LmV4PXhmKhPBUj7g,154
 laboneq/compiler/experiment_access/acquire_info.py,sha256=bQrMObuyxABUpGTc0ubuUvOs15KzKJzos1dPw4B_PYs,222
 laboneq/compiler/experiment_access/device_info.py,sha256=HQBj1WpSt8TwHX5G_kE-1m5ulJ06-j_hdIIVamxHQDI,349
-laboneq/compiler/experiment_access/dsl_loader.py,sha256=Hl6QwehHkBDHPCxhscpsMlFoWk7gvXvjIhsfyHmH6rI,44928
-laboneq/compiler/experiment_access/experiment_dao.py,sha256=ejzxEOBua2ztVe35tlZXe7SGcX2k-wVy0xKP-Tj2Bmc,16509
-laboneq/compiler/experiment_access/json_dumper.py,sha256=Yds37AhZV8nre6u_a50bVmkYrJCQF6WIqIs2MzB2m48,14106
-laboneq/compiler/experiment_access/json_loader.py,sha256=iyPOMYATaqjSxSCabHqsKGBbtEf5ttclYAH0Ajpfvqc,21004
+laboneq/compiler/experiment_access/dsl_loader.py,sha256=_IIG-VcRcTpUILehAFyRoin4Qpq9eVnOHvY8nvvYMVc,45262
+laboneq/compiler/experiment_access/experiment_dao.py,sha256=Gn_2_3ZMCG8TLnA0Zv0rMD6NAvWXwUxE5eXBWCndKo4,16767
+laboneq/compiler/experiment_access/json_dumper.py,sha256=YNDUHHachBzw0-4FmCRQzMTeR5ys61xPaRgpvQoeQfg,14264
+laboneq/compiler/experiment_access/json_loader.py,sha256=4tK59zHBocRlaXcyBHQYjtMFJivsM9IHWfJ-P1txyVI,21043
 laboneq/compiler/experiment_access/loader_base.py,sha256=FEFxOs-_tS8ZMbLRAeaY7jDkFV6EmJvgxoKirI7kFo8,6182
 laboneq/compiler/experiment_access/marker.py,sha256=2Okj9Q_Ukk02B-Z7_WDM6nHN-nuXw3qFjUNaw8LUMsI,270
 laboneq/compiler/experiment_access/oscillator_info.py,sha256=VvEyOttSTDd7-oxpbim4xmPJUwYEzjrsDXup9xLwI0k,286
 laboneq/compiler/experiment_access/param_ref.py,sha256=wqyyzAiSIEu2GVeNdZc-MtvdhdSDp1Quch8qBVIPppw,197
 laboneq/compiler/experiment_access/pulse_def.py,sha256=wC192cXc_oxtxj-xJS2tY2dHkDr_CAYrtIkcp45gj6E,1311
 laboneq/compiler/experiment_access/section_info.py,sha256=vRIw7KvrlNhXjh8ynUjGUer_DVJPxdo9FGBdDMWVuUY,851
 laboneq/compiler/experiment_access/section_signal_pulse.py,sha256=ZGgbvNW3v-qIgyvcW34Lk31hyhFeNb_UjE6uIUXd8os,1069
 laboneq/compiler/experiment_access/signal_info.py,sha256=HLkN-Kq2vZrh5tg92RA3ZSSYaiRXXQecw01-NtXGR_Q,387
 laboneq/compiler/scheduler/__init__.py,sha256=FVNdflrImH-vSDDkoz05G5rNUUDB7mf4sgoOZHttkBQ,77
 laboneq/compiler/scheduler/case_schedule.py,sha256=HwzkOLBBYQip5bDBxNApQnGITb5cgyLVsYezwhxCdCQ,3265
 laboneq/compiler/scheduler/interval_schedule.py,sha256=tp4CauVPr-hOXxtzvUQYZrmXcqJBY7UqQDPlDDo1S_0,7439
 laboneq/compiler/scheduler/loop_iteration_schedule.py,sha256=5RKVr5tmtYqcGx8DY_kichm2rjeHtXbMrthFzwzFE9U,3327
 laboneq/compiler/scheduler/loop_schedule.py,sha256=RUFiK0sMisFwB1NVL1fAphcxKGMjB1f0ZpMPAf5-_fk,8576
-laboneq/compiler/scheduler/match_schedule.py,sha256=-laj65-4ozlLSc4AqTOXCaUA5hRhOZ06YMwAA4MRueM,9267
+laboneq/compiler/scheduler/match_schedule.py,sha256=MAvUzVbiMd5Zn9IWF4krOmoNElI5fE6MrF33hA6bk-Q,10452
 laboneq/compiler/scheduler/oscillator_schedule.py,sha256=Iykf3E3wT7xXuH-hVk9_MwTHM7eWQFmhR3JzzQTd1eM,2248
 laboneq/compiler/scheduler/phase_reset_schedule.py,sha256=yLyoKe5S57LGcPMcgFxsBDyKjPROgCUdASTSPU-fQog,1761
 laboneq/compiler/scheduler/preorder_map.py,sha256=luqooLzAEbK2b0j8TIDcHsE3riHA_GFyhcSRerHUFUk,1808
 laboneq/compiler/scheduler/pulse_phase.py,sha256=poXl-PKFIO7X_xN3Qjqo-NWC-svaom3dWjetfKEsw8c,3821
 laboneq/compiler/scheduler/pulse_schedule.py,sha256=im2DdPgi2Q4pQq4Q-YnApyZyi04888iSOq03BRrzNds,6958
 laboneq/compiler/scheduler/reserve_schedule.py,sha256=WM-fLfdDnViVwB5U0TrrkiDKB0s3DSw3yUFLC5vyvQU,621
 laboneq/compiler/scheduler/root_schedule.py,sha256=2ErHbKUaD8f6xp42UdoCSaQ5AeZc5n4PNHaluspKRcE,1367
 laboneq/compiler/scheduler/sampling_rate_tracker.py,sha256=taR4AdTTaYNXfaEgM5hZNhL2VbcGnJCkx9gt4xAJg9E,1949
-laboneq/compiler/scheduler/schedule_data.py,sha256=FmMZQ2U_rsJyr3KQ2vYxAAexhS5crQp2kQBnHCpc2jg,1012
-laboneq/compiler/scheduler/scheduler.py,sha256=0Og-Ihgy1d5h17md12yBznP52MRIjPaIZXcug8hN5Ak,40949
+laboneq/compiler/scheduler/schedule_data.py,sha256=f1m_AVtgmeOJ5nYgFw91OeCWauqB28MyewEovnNHkdw,1115
+laboneq/compiler/scheduler/scheduler.py,sha256=niev6cb8MQtcS4LuOd6icsZ-QUpI9U_GUiLGj1XTZk4,41127
 laboneq/compiler/scheduler/section_schedule.py,sha256=UruX04LNrMUUAUoJ3RooT3zSquPW5Atfa18ds6n8sWw,13191
 laboneq/compiler/scheduler/utils.py,sha256=buFGd2oxNFr3hfGc8fx_dyMCbxTwimiSOuxCqeqSDRk,757
 laboneq/compiler/workflow/__init__.py,sha256=FVNdflrImH-vSDDkoz05G5rNUUDB7mf4sgoOZHttkBQ,77
-laboneq/compiler/workflow/compiler.py,sha256=JC-DzUfEzGCB-XD7_yMpk4uGJ5Ay-G7pwj-MctSpiJU,50498
+laboneq/compiler/workflow/compiler.py,sha256=5ArB-ijAEEqmpMm6FAX0wUdaBrr5L8lUWs3seosGZzA,51030
 laboneq/compiler/workflow/precompensation_helpers.py,sha256=dpRw6dGJcsDAv0uI48cfzso75IYHNVfP1NUkRhD-giI,12424
-laboneq/compiler/workflow/recipe_generator.py,sha256=ysiYXRS4JuKOnOsPldw1PClEasvG9oY-ieGet3M2qDQ,12420
+laboneq/compiler/workflow/recipe_generator.py,sha256=lekirVjI87CDhXcWCfOwJpsSgek91DJGf9G2WyjEeh8,12522
 laboneq/contrib/__init__.py,sha256=7Yt1BeCJ-am29jPA5s55Otv83hbYF3ZZum1MZabcNMk,77
 laboneq/contrib/bloch_simulator_pulse_plotter/__init__.py,sha256=7Yt1BeCJ-am29jPA5s55Otv83hbYF3ZZum1MZabcNMk,77
 laboneq/contrib/bloch_simulator_pulse_plotter/inspector/__init__.py,sha256=7Yt1BeCJ-am29jPA5s55Otv83hbYF3ZZum1MZabcNMk,77
 laboneq/contrib/bloch_simulator_pulse_plotter/inspector/update_inspect.py,sha256=dII-ZVAa3HumwKfHYGiARVBDCjaqJhGFy55XAjOPiaM,4511
 laboneq/contrib/bloch_simulator_pulse_plotter/plotter/__init__.py,sha256=7Yt1BeCJ-am29jPA5s55Otv83hbYF3ZZum1MZabcNMk,77
 laboneq/contrib/bloch_simulator_pulse_plotter/plotter/plot_funs.py,sha256=3RjtFb3sxYokBP92COK53gCmBrCk9ubs8_xOb75fem4,3379
 laboneq/contrib/bloch_simulator_pulse_plotter/pulse_simulator/__init__.py,sha256=7Yt1BeCJ-am29jPA5s55Otv83hbYF3ZZum1MZabcNMk,77
@@ -96,40 +96,41 @@
 laboneq/contrib/example_helpers/descriptors/hdawg_uhfqa_pqsc.py,sha256=CzjRnXjw4v_WMtSvY5xZbmLztyEHfAQlzMbgvZ8cAmE,956
 laboneq/contrib/example_helpers/descriptors/shfqc.py,sha256=Vu_W7gf5XigJBTq3QZV8u-mAVXt560OFbuIiNCX_G10,1887
 laboneq/contrib/example_helpers/descriptors/shfsg.py,sha256=aWkqMMBq90JCPAj0-uZadDEMziln_OsqxZSFBJpsf-E,1639
 laboneq/contrib/example_helpers/descriptors/shfsg_shfqa_hdawg_pqsc.py,sha256=ztHPSen0jfWqWzifanf-TmyXZ7P_R5-ssKXfOD_ASzo,2472
 laboneq/contrib/example_helpers/descriptors/shfsg_shfqa_pqsc.py,sha256=cH9gx4th7Gh_oC72Fs0U3XQL1DUW3ownAv3BYsJ4PnA,2160
 laboneq/contrib/example_helpers/descriptors/shfsg_shfqa_shfqc_hdawg_pqsc.py,sha256=PIPiyvyyMv9wwcKBf81xFhF1Pflol2WrS5fkfb21EKU,2708
 laboneq/contrib/example_helpers/plotting/__init__.py,sha256=7Yt1BeCJ-am29jPA5s55Otv83hbYF3ZZum1MZabcNMk,77
-laboneq/contrib/example_helpers/plotting/plot_helpers.py,sha256=wACi_GadX6ldAALY6PK5isFE9FWsGDVAJYPa6B7BCJY,10340
+laboneq/contrib/example_helpers/plotting/plot_helpers.py,sha256=xvozYqVwDGKR6xnHaYBLxN4m5Hu3XqEi9In9vAIfJ5Q,11127
 laboneq/controller/__init__.py,sha256=gPuU9BwcRA-VFMRLtIzd9Y-KvLQhYv0czaGuo-uimjc,308
+laboneq/controller/attribute_value_tracker.py,sha256=Q-PznOOJHYue9gCwxM8bktkZse4FSGJcNrJINBqjItM,3380
 laboneq/controller/cache.py,sha256=sI4qtTQurYPWzMp7iW1oKwQp_GVftQX9isDkTNZ-bDE,1479
 laboneq/controller/communication.py,sha256=K-9sn7UABcGb9hGLM_8tLYtKWbNeSvUqcoubnBUTcvk,13604
-laboneq/controller/controller.py,sha256=oLZJaQQ1wHFfk8jMmoxIVRjEclqKgFvz_vLsYZRtN3k,34132
-laboneq/controller/laboneq_logging.py,sha256=XB51Z2RYeiozXPlRdeuWVFQGe8eXDbCOIp_nuOT3DTI,4600
+laboneq/controller/controller.py,sha256=SW_AQlq9In4iYVmyC6e1oD4yIa5a6P0ZHivzoMM-mEo,34028
+laboneq/controller/laboneq_logging.py,sha256=9S7qvoF2MzOvw-BQLpHi7sLSe0v-xoAo0P0I_mbCPLU,4892
 laboneq/controller/protected_session.py,sha256=v4T5NsQxE57E22hJltIumOnLAoBms0D7ZTtUYjGHGGM,337
-laboneq/controller/recipe_1_4_0.py,sha256=3UueBUAD5Eyij0T2Q4F0-_gvr-8OD7wgWmTAL7xjHV0,15088
+laboneq/controller/recipe_1_4_0.py,sha256=8T6XdPHMw0KBMP7Hx1c1z88dH82ms-PqiDTX5a-InBc,15188
 laboneq/controller/recipe_enums.py,sha256=uNjZPJci2KCleSh2zNYTOkUEfBpBK0spOU16GvaWj6Y,638
-laboneq/controller/recipe_processor.py,sha256=L2MBGJoaYFLLFqI53vuETuuzP6FHOfHMb6nJI7CatTA,19876
+laboneq/controller/recipe_processor.py,sha256=HJf4INxd56JHtP3sahnc1k7a2NtENn_hjemZCDOKeWs,21249
 laboneq/controller/results.py,sha256=b9Oy_F0GqSzHulNSWqt6ltUzXpYZ4JmC0BVIE176Qzc,1917
 laboneq/controller/toolkit_adapter.py,sha256=moZzwjnRUUbyT-7JL31EBtBh39VD3USx1SRolFS8v-g,1594
 laboneq/controller/util.py,sha256=fi5_nCRrmORASGaFlge4TN6gXAWZIiS0pinr9-DVjnA,1178
 laboneq/controller/versioning.py,sha256=IcmXytxA6OtbudyM2aK8gCgWLcuLbweru5wIafolpnU,281
 laboneq/controller/devices/__init__.py,sha256=FVNdflrImH-vSDDkoz05G5rNUUDB7mf4sgoOZHttkBQ,77
-laboneq/controller/devices/device_collection.py,sha256=OFIBllNQnuWNz31EelrkkOvGL6v4l47ZZsXM6V0uR1U,15400
+laboneq/controller/devices/device_collection.py,sha256=3NAj2v2Htyaofh-qoOQOsSMJPzFnb1y6z0PwVV48P7g,15391
 laboneq/controller/devices/device_factory.py,sha256=CQmdrldqyhI7wCFw2aObszp9g3XhPaJZv9Y8U_VAdMY,1275
-laboneq/controller/devices/device_hdawg.py,sha256=L6pV-wtfYWoxnyPzMa1jW_KszUIWiDqyU6rNIWMRn5M,23794
+laboneq/controller/devices/device_hdawg.py,sha256=9aSNOUIakFdAkEGSH4i5pZur4tL8FJ4iS1oCKkC9Y_w,24523
 laboneq/controller/devices/device_nonqc.py,sha256=m1rpD0XgwgNChmIkzdOBFiyg4bbPWY-1b0ysrMLqLNs,491
 laboneq/controller/devices/device_pqsc.py,sha256=FkH6ZaKqQDoX_WmROL1czc_dTU5DP0nU6IkqShA30fo,8115
 laboneq/controller/devices/device_setup_dao.py,sha256=daW-WJHaqCuxxNF3Wtnzr0_ebL2X9cYo-WHTv_U0Bas,4137
-laboneq/controller/devices/device_shfppc.py,sha256=NeGDmCxney0boI-7QHblA3VQCUpULFdkUIqt2l9oJqM,4013
-laboneq/controller/devices/device_shfqa.py,sha256=y0xFpvK_cszqje3uoNYzY7lLDxlJ4NnGVQwg6iT-hus,40727
-laboneq/controller/devices/device_shfsg.py,sha256=KTOAkTEslNQ4GanZI9Frh-bFcSwkQPckus-zejKk230,20509
-laboneq/controller/devices/device_uhfqa.py,sha256=vhoEyLZnOZVcyx5kSkYA3hYfeCSdpB7n35uctAVDdWc,28857
-laboneq/controller/devices/device_zi.py,sha256=ump_Phk0NOtJ8RpbDXAi32shSgiI04h7b7UnJp4x_NY,36238
+laboneq/controller/devices/device_shfppc.py,sha256=hUEGLYpFt4JHhmaR1NQvljlxU-8YxopEEnlKpm6Fg4Q,4344
+laboneq/controller/devices/device_shfqa.py,sha256=OsiHvUQ1EsiW5eMOQfGjq8kwjcCSGfvWMmDlxmR5v6c,42895
+laboneq/controller/devices/device_shfsg.py,sha256=1ThT7CgWXZkaH7O8PtXmPoIxQgNL2fBKX5d8Lju8FXw,21719
+laboneq/controller/devices/device_uhfqa.py,sha256=u1II0KmVXAnoWh7TLUhL139CkI8F9mdl5MRHJIdAa44,29618
+laboneq/controller/devices/device_zi.py,sha256=8aBRy3IMbTBl8bhWs5YEvDyowNwtsIzFhb5pTyVUPU8,37660
 laboneq/controller/devices/zi_emulator.py,sha256=Y2uZuFe020_fmG8fG_dyFk6HlUpK36fxwG6hrBMr4Lk,29590
 laboneq/controller/devices/zi_node_monitor.py,sha256=2N2Q79sP-USY9-ovk5DHOXiO6Sov9QSzBGqdsyAPnuA,10358
 laboneq/core/__init__.py,sha256=nx0-aqsC4hdoO7jIj0Ut7yNTQbe5dme7jodU9wkd4N4,97
 laboneq/core/path.py,sha256=ZDMafOg44r5I3T-sW-iY6j7xrjYMbx12UsLoqbhg3Vw,2015
 laboneq/core/validators.py,sha256=pmtl8RdlBr-49CkxJseW1VrDtJU2gqLVBWSZdLrRpWc,1338
 laboneq/core/exceptions/__init__.py,sha256=8ZaME3lWkRJ7BZw1qVWGbt91jaklPd67iyIZ-zXoBpE,126
 laboneq/core/exceptions/laboneq_exception.py,sha256=bWRVbnLJiBszdNeEglRFp-z1Q3bb-irTIzf2vgTaBK0,123
@@ -150,97 +151,98 @@
 laboneq/core/types/enums/mixer_type.py,sha256=iXF4i8-ovwBfJkppv4iB98ZmeV6bvpsZTRPr-emjwPM,316
 laboneq/core/types/enums/modulation_type.py,sha256=S7wsc5w0UiiGkgrI9uIbY2ICpn8G1syuE19h57OJtvk,200
 laboneq/core/types/enums/port_mode.py,sha256=1CdF7cSNb15P8ZgY54iPIOdwZuuDHwlC1HaJfSxchFk,152
 laboneq/core/types/enums/reference_clock_source.py,sha256=hN1gZKxh_ElHZOq3zl0nHyJaaKoCgixTc0fKcCKUy7E,188
 laboneq/core/types/enums/repetition_mode.py,sha256=hRnj_stjpVRDGTCHoN7q5kPffAm6OoTX9BWcoerl3A8,198
 laboneq/core/types/enums/section_alignment.py,sha256=nYuTh1r0PL35aQoLUgeOGTnZoAb6XhGPgVY4a70UMgc,170
 laboneq/core/utilities/__init__.py,sha256=FVNdflrImH-vSDDkoz05G5rNUUDB7mf4sgoOZHttkBQ,77
+laboneq/core/utilities/compressed_formatter.py,sha256=PsOA_xZVu0cX4uAk33ax5ZPjCEJ1Dv2UspvjGCj6Si8,1813
 laboneq/core/utilities/pulse_sampler.py,sha256=eKdg1IcTwjoVmp7mKSSAu6eV80mYPgHaMUUr9AIWkZ4,8039
 laboneq/core/utilities/replace_pulse.py,sha256=LEWhHoF3s8klVXSaVO26gkthLuyJE_A5NRcZW8WGTx4,9808
 laboneq/dsl/__init__.py,sha256=gsR9dv88edpbJLrwc_X2jj147IfVWpnTT10td01fPkY,178
 laboneq/dsl/laboneq_facade.py,sha256=xfeHLO9ywCpClZ1Jl_I_Z_IC5wDpr2tckFsJhPuy8PY,2929
 laboneq/dsl/parameter.py,sha256=AbR78048B3-jyYvq_A5rmBqaeg4v0C601f9EGFJzRN0,2552
 laboneq/dsl/session.py,sha256=P-mOhpv3-u5stl3oeRSjTn97b4Nm4M42gxw24HYzsT4,25670
 laboneq/dsl/utils.py,sha256=v0qlt2XA2CXiGK3Rpi_PC45YZGeQriRz-ShovaTXMBE,2296
 laboneq/dsl/calibration/__init__.py,sha256=3becZcLdza9jTczHmfBgbbaH238UfP9uPakbhe5kwto,529
-laboneq/dsl/calibration/amplifier_pump.py,sha256=A4QI8YE-lRGaUv_yE6q7Osn3JfFSEuO-PzHyeowtaD0,1017
+laboneq/dsl/calibration/amplifier_pump.py,sha256=H1L-uYlCL3sXTMXIbBFcWS9ln1mFiz5lCr6NnLUKODk,946
 laboneq/dsl/calibration/calibratable.py,sha256=DEx55rhplLTxoaf8-bGnmZqyO4eZdIyMptiLAGKEp7M,545
 laboneq/dsl/calibration/calibration.py,sha256=3t6v9XjyhsT8ZtZM5kIRIgfUy99OWk85JvcMFtDc-Ok,2313
 laboneq/dsl/calibration/calibration_item.py,sha256=JlPu54zS2NfivokgD4ICOhrw5e3Rhs5DO7pB0iDazpY,111
 laboneq/dsl/calibration/mixer_calibration.py,sha256=_ivXcsDgELxaC8zZ7E5caMhE-HZYSuuDyR5odaVImKw,992
 laboneq/dsl/calibration/observable.py,sha256=5zf7HE7e4MnrnHcgwAWMKkejOiVTZs4UCtlRiVn8OVw,3403
-laboneq/dsl/calibration/oscillator.py,sha256=H2_32nckXQLraVZzq15Y-NLMB9U3BJp3lQW1QI3QxLs,1716
+laboneq/dsl/calibration/oscillator.py,sha256=3e_X5v9PSCOwLcr7nb-zUWj1OGjqIvsfxZWMFB_VDKE,2134
 laboneq/dsl/calibration/precompensation.py,sha256=N-GduIP4AVdKfxDH2rQ3zbYEarKx1rYrxO2Egb70Q9A,2650
-laboneq/dsl/calibration/signal_calibration.py,sha256=_SpbINwf-0i8vr_-r0smIL5v0cmN1cyLNZAw5n3E0GA,5607
+laboneq/dsl/calibration/signal_calibration.py,sha256=798sV3mEz0ssBI4GYjNoNTIAuzBTf2rknvdMZBohQR0,5614
 laboneq/dsl/calibration/units.py,sha256=9W7YXV75G2VgNGSNserL_rsnEdjQugCuzg1gQmkvutU,553
 laboneq/dsl/device/__init__.py,sha256=uqx0Rho0xQ0vHzcP4no8R0OfjkK2ZdPllpVsZoAuH6Y,363
 laboneq/dsl/device/_device_setup_generator.py,sha256=sA2j1IKi3pId3yg5Ct4sp_tvkd4aZ7o8FX7fDdpKIgg,45826
 laboneq/dsl/device/connection.py,sha256=e_uMDO-7YrMKJkZEbizlTQZITsXU1--ceOYOZ0m40Xc,601
 laboneq/dsl/device/device_setup.py,sha256=hDYGDooO-rFxHsC7i1HD5kyzPvXzNSjrXBWkCTg0dMk,13663
 laboneq/dsl/device/device_setup_helper.py,sha256=KRaya8xtzjqzdn1SZ_NMCU7p_V-76Aj_S0evSzuey7c,2551
 laboneq/dsl/device/instrument.py,sha256=XjaPAcpKdPQx1z-QpAFwHLFERoK65-Rgb7SjIyW_zy8,1362
 laboneq/dsl/device/logical_signal_group.py,sha256=i12USV4K1ij8y_3SOYStnZE_z3Bo6G0-f03RtuBjO-w,1893
 laboneq/dsl/device/physical_channel_group.py,sha256=1u4c9TyfC5WZWkgQGTpDcbIc6hXcgKuNdE8AJcxbaRk,1729
 laboneq/dsl/device/ports.py,sha256=-jVPCUfRq1e2PHpPBrcHuUQcrrfv7kylzDUF9rZWTnQ,538
+laboneq/dsl/device/quantum_operations.py,sha256=cjiOhMFZT87b88P2pXK1MZSLvLT78oOVFs7PFvMAgZk,3422
 laboneq/dsl/device/qubits.py,sha256=zjEg3HIPvRU8giDSqI9i1vOISPtQSEPEKLez-CyoauA,4557
-laboneq/dsl/device/quops.py,sha256=V7XsyXTUqHH5s5Q2QeqF2GKko2roQxSm89cdZ4k2FCc,3104
 laboneq/dsl/device/server.py,sha256=JOM2xKKWMwFWYPcAjoCoFIuF_4ZC73_fMiZXUhNSZPk,215
 laboneq/dsl/device/instruments/__init__.py,sha256=sl302P7-HQO6Y8NXCcN2-r5mfbGastN7Ugs6PfRA1wg,328
 laboneq/dsl/device/instruments/hdawg.py,sha256=xLmo7LJhGC61PDkv_ZYn37VD0bnRxC1Ag54ET_KRLE4,1778
 laboneq/dsl/device/instruments/nonqc.py,sha256=j6jLNrFifaKe1QDcQJcTVWMdQR7eBI345V7S-iWqhts,466
 laboneq/dsl/device/instruments/pqsc.py,sha256=JQrg31Gj6HRjUOYjDyG5m2A9ngrQOFcX0mHw_2BwsGk,948
 laboneq/dsl/device/instruments/shfppc.py,sha256=E_-2fesNBJ0E-qrrwSA5MK1TdL0Daht9OX2U0BeBtkg,927
 laboneq/dsl/device/instruments/shfqa.py,sha256=C6yaZvxr1xZwUegOILTNC8_B7a28O_GqsIYag-dCvYo,2248
 laboneq/dsl/device/instruments/shfsg.py,sha256=MCJkySVlx7ls33IPHrf2ZmKBRuBXQDPGwVw7o_JXfmk,1659
 laboneq/dsl/device/instruments/uhfqa.py,sha256=sHidPdFcZHTOXXSFJFcCD__K90IkEogpZPiai5dt8Us,2312
 laboneq/dsl/device/instruments/zi_standard_instrument.py,sha256=IcDKOIMU_Yi9niyZlq9aw1xKXVLGd2VO0mO9qRW8lDI,888
 laboneq/dsl/device/io_units/__init__.py,sha256=UOI3L_V5_3lji95HUdB3KvWoAQkja0pR8bGBshRnRr4,187
 laboneq/dsl/device/io_units/logical_signal.py,sha256=Q1TH8nwOfUJFI6XnnnHtUMXEDNrTsv_BEyJZvfwH8wQ,12750
-laboneq/dsl/device/io_units/physical_channel.py,sha256=ruwynMdZx1fDgXeE_WOSHdeQrJWdmyNrRDmvcn7UgJ0,3811
+laboneq/dsl/device/io_units/physical_channel.py,sha256=xQBy_FTGq6nXRK0NsFpn1ZicGm1U0ywcyr2DoROpdXc,3828
 laboneq/dsl/device/servers/__init__.py,sha256=ZeYikalTjZXb_HDjfdGe6YHUuZAlDv0qqHZ0d1JLOE8,114
 laboneq/dsl/device/servers/data_server.py,sha256=URgMXwwmzNAPF3PrQBTE11dU7QLxGaJa0tIdi8F2BiQ,704
 laboneq/dsl/enums/__init__.py,sha256=GeDXWBzskaPr4MxVoeJp6kj-X5kVZA1yrbUw7wcV2F0,718
 laboneq/dsl/experiment/__init__.py,sha256=N159QRiB6rNL_RH6vzZwYqi4B91GTlX-JmmysAoQgMM,508
 laboneq/dsl/experiment/acquire.py,sha256=g4Pvm6T0qu8tH8LRTHhCZ1wb2K4Drc1rawNeNTRkS_E,972
 laboneq/dsl/experiment/call.py,sha256=eATarAz81C0QC5Ih-Uuh9PrS0g4rEF_vbQsrav_-I6Q,814
 laboneq/dsl/experiment/delay.py,sha256=98P3AePai3fqH1csDnWSxUN3EGJchuysX_2qnkCF2-Y,780
-laboneq/dsl/experiment/experiment.py,sha256=pr5g9l1DEHEWSrqVCwqiIoENt-hbwQXcChywV9e4ppg,39779
+laboneq/dsl/experiment/experiment.py,sha256=0xtihbOCTLtTD2eC7ZoQuMC2Xx9uZm0l32v2DNFy-oY,39761
 laboneq/dsl/experiment/experiment_signal.py,sha256=eHDHAu7Hv9xTSF-f9-YsJ1suZmZfaevS9anyLaBiOPY,8216
 laboneq/dsl/experiment/operation.py,sha256=kJPLIjNTFf_lJkVsOmASPi7GZVJ9CCZySdA2YDCmswU,401
 laboneq/dsl/experiment/play_pulse.py,sha256=yGd_-jzkuOK_i4A65mfoPfeG1IRKK8ZaDQE-E627Idw,1647
 laboneq/dsl/experiment/pulse.py,sha256=cdmMmMo1yGygx_5EkyemW6xO-8-FuIErugjN1PHiKrE,3953
 laboneq/dsl/experiment/pulse_library.py,sha256=kmvFKXNGXIVCnjFMsFqAdiUM5bk8u-grY4ZeuKWHJ8M,8194
 laboneq/dsl/experiment/reserve.py,sha256=tn1YEkW6E7BbBuG4SKveCmiAXrsYm2IeMUI2iDnwazs,890
 laboneq/dsl/experiment/section.py,sha256=0gg3PscVUPEoTEhYaE4bsX8qsTvxgXQ4RyKb_gop5q8,11431
 laboneq/dsl/experiment/set.py,sha256=4hEgxT9iYWNgDEEAFDS4D1GlgTsInRK3regArR4cnaU,640
 laboneq/dsl/experiment/utils.py,sha256=TiO1tKG5F8Zqx1lUz1rUPc3lNVE6UMPnniuLNoyMql8,323
 laboneq/dsl/result/__init__.py,sha256=XAUfjo82SDzPK0s8ZZSJPTVRIF8b4smFBWhI5rwqBAQ,151
 laboneq/dsl/result/acquired_result.py,sha256=yNCpd1C8BnKeWbMCJHSVFOQzcYoy00-eLdLwjAEcFQk,1766
 laboneq/dsl/result/results.py,sha256=79EozB9G1ExCYAY8dFjEQdpDL82G5tJGKTdMH1XWRn8,7240
 laboneq/dsl/serialization/__init__.py,sha256=XVKLzoqNC9_psuftSgRNbbNmrcvTeJmWW5bIa-bmwRU,113
-laboneq/dsl/serialization/serializer.py,sha256=vInxTlXMw-K_RavNnJckdmbpJxppEnVJ2cwgJCKFuzc,5379
+laboneq/dsl/serialization/serializer.py,sha256=I4HJ5Qm2GBOxgEm_k7-e1-xd8vEz4m15CCpI4eP38fA,5392
 laboneq/executor/__init__.py,sha256=FVNdflrImH-vSDDkoz05G5rNUUDB7mf4sgoOZHttkBQ,77
 laboneq/executor/execution_from_experiment.py,sha256=eE1lzSHYQqZZqlM2TAyjm0ibP3ifeeNTIOazin9z96M,3819
 laboneq/executor/executor.py,sha256=xvJwDB-9hlPjD4dTPqfxN2uNVB_2o8ZoKLNWPQBgpQc,8152
 laboneq/openqasm3/__init__.py,sha256=zIfFQa39Ko4nUcnnLBmRilnUVJ9eeg022QoLpodiv2o,145
-laboneq/openqasm3/expression.py,sha256=j22P0GOjizCvOZ-G87xX4qIYxnZiJxRUF9_UytCnuS0,8730
-laboneq/openqasm3/gate_store.py,sha256=33P_tN8UVV9VpHzcpP2HVbYFuWXlYs_BEe9VyWUEsxg,1604
-laboneq/openqasm3/namespace.py,sha256=xpMmnQZ-ap-y7wECmdPAd3u9waHV6eYaGFYmwwENJtY,2060
-laboneq/openqasm3/openqasm3_importer.py,sha256=AmITRhrw1PpVYLAImbTWCY_ruA2PkrA7TOlm9oaGsnI,13702
+laboneq/openqasm3/expression.py,sha256=DKk9nMo1cABcEb4kPJ3dOAKlsafr5O-rNh5TfbUHGkw,8903
+laboneq/openqasm3/gate_store.py,sha256=rF8qUBL6avuZYcGKAYVU85Xb3wwCFN69qYJEtwtZbTg,1671
+laboneq/openqasm3/namespace.py,sha256=c_rpWEw9MZALiu1ulKntBOaSSXQudd8HieQ2r-fU3qs,2593
+laboneq/openqasm3/openqasm3_importer.py,sha256=nkSJucZWi_qOVWUoy6H8VJLZg2yBDukSJS1GhDhynMU,15459
 laboneq/openqasm3/openqasm_error.py,sha256=rgkp6fT1tNrhVX8eCV-q1PLJUfGxkmT4gXEErJcSB-8,1732
 laboneq/openqasm3/reset_gate_factory.py,sha256=WnWPrS0E0NXXy1pbSryMw8KgswOoGm7IW71vhynXhKA,4850
-laboneq/openqasm3/signal_store.py,sha256=mR5qYGiTtOGNGfTevQyLCW5Pwy2rgHiL1oLen1zXgLo,1492
+laboneq/openqasm3/signal_store.py,sha256=SJ3lvM5iWGi2HS7t64E2TbIsBZGS5JHdhJN0gX6bE8w,1517
 laboneq/pulse_sheet_viewer/__init__.py,sha256=F_gdqvR3iTbFH2-iGtGWPp2v2XpMu0c4SXEPEIJyQb0,127
 laboneq/pulse_sheet_viewer/event_graph_viewer.py,sha256=hKBUzFzimfz9YAFUYNYwrhwMscXHa-4M3BNa6id6SHE,2059
 laboneq/pulse_sheet_viewer/interactive_psv.py,sha256=D7pEX9C8mP9EZofE5L3aAAkX3lNFaEoHwBc_l2AHyec,2692
 laboneq/pulse_sheet_viewer/pulse_sheet_viewer.py,sha256=_O53T2cm8KWDhbUKoONuRb_9JOKyKvOqEMtQgrwlQPI,3288
 laboneq/pulse_sheet_viewer/pulse_sheet_viewer_template.html,sha256=TsX3r0W8qf_PKAw1pYreXQEcexRfzgL_FmbvOAFh06s,1443040
 laboneq/simulator/__init__.py,sha256=BuPOsR4Dwi6tSLAsG0lBeHzpOZFnCsNn93ohr-v9mZ8,152
 laboneq/simulator/output_simulator.py,sha256=OjbHVNNkrYITwZaJ58HaqAeM-ETeLP4y_ifA0aQXrGE,5904
 laboneq/simulator/seqc_parser.py,sha256=gVR7AEtmuJH2QDGnzA4LRkZPgr3iBorwWMk-CJ3cPGQ,40863
 laboneq/simulator/wave_scroller.py,sha256=P9YjG9w_td2SrZfQohIVcRe4Gf9MBI_-RgA615de99g,12500
-laboneq-2.6.0.dist-info/AUTHORS,sha256=Uu7pMg_oQJSHTrzjG8G3ApfutLIKqdOdjmtf5VZQILs,22
-laboneq-2.6.0.dist-info/LICENSE,sha256=z8d0m5b2O9McPEK1xHG_dWgUBT6EfBDz6wA0F7xSPTA,11358
-laboneq-2.6.0.dist-info/METADATA,sha256=zyGQqVdAX3KFnJtDUEU2QogqYqCPWvOHfGZUJt5hOk8,3188
-laboneq-2.6.0.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-laboneq-2.6.0.dist-info/top_level.txt,sha256=oZ0o6Elw6GJcR44azoSi8l6opKF-v5Ks1MLYbqpXJGA,8
-laboneq-2.6.0.dist-info/RECORD,,
+laboneq-2.7.0.dist-info/AUTHORS,sha256=Uu7pMg_oQJSHTrzjG8G3ApfutLIKqdOdjmtf5VZQILs,22
+laboneq-2.7.0.dist-info/LICENSE,sha256=z8d0m5b2O9McPEK1xHG_dWgUBT6EfBDz6wA0F7xSPTA,11358
+laboneq-2.7.0.dist-info/METADATA,sha256=PVXSv6mKgMP3JttTjgvdt6OdpNuUnaD3ZQ45AWurQHA,3188
+laboneq-2.7.0.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+laboneq-2.7.0.dist-info/top_level.txt,sha256=oZ0o6Elw6GJcR44azoSi8l6opKF-v5Ks1MLYbqpXJGA,8
+laboneq-2.7.0.dist-info/RECORD,,
```

